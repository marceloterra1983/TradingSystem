{
  "metadata": {
    "generatedAt": "2025-11-12T00:11:35.376Z",
    "version": "1.0.0",
    "source": "governance:metrics"
  },
  "totals": {
    "artifacts": 22,
    "published": 16,
    "evidence": 7
  },
  "coverage": {
    "healthyPercentage": 100,
    "meetsHealthyTarget": true,
    "owners": [
      {
        "key": "Governance",
        "count": 6
      },
      {
        "key": "SecurityEngineering",
        "count": 5
      },
      {
        "key": "DocsOps",
        "count": 4
      },
      {
        "key": "DevOps",
        "count": 3
      },
      {
        "key": "Architecture",
        "count": 2
      },
      {
        "key": "FrontendEngineering",
        "count": 1
      },
      {
        "key": "PlatformEngineering",
        "count": 1
      }
    ],
    "policiesByOwner": [
      {
        "key": "SecurityEngineering",
        "count": 2
      },
      {
        "key": "DocsOps",
        "count": 1
      },
      {
        "key": "FrontendEngineering",
        "count": 1
      },
      {
        "key": "PlatformEngineering",
        "count": 1
      }
    ]
  },
  "freshness": {
    "distribution": {
      "healthy": 22,
      "warning": 0,
      "overdue": 0
    },
    "overdue": [],
    "upcoming": [
      {
        "id": "evidence.metrics-dashboard",
        "title": "Metrics Dashboard - Documentation Health",
        "owner": "DocsOps",
        "dueDate": "2025-11-28",
        "daysUntilDue": 16
      },
      {
        "id": "evidence.secrets-security-audit-2025-11",
        "title": "Auditoria de Seguran√ßa de Segredos - Novembro 2025",
        "owner": "SecurityEngineering",
        "dueDate": "2025-12-07",
        "daysUntilDue": 25
      },
      {
        "id": "strategy.governance-action-plan",
        "title": "Plano de A√ß√£o - Melhoria de Governan√ßa (EXECUTIVO)",
        "owner": "Governance",
        "dueDate": "2025-12-08",
        "daysUntilDue": 26
      },
      {
        "id": "strategy.governance-summary",
        "title": "Governan√ßa TradingSystem - Sum√°rio Executivo",
        "owner": "Governance",
        "dueDate": "2025-12-08",
        "daysUntilDue": 26
      },
      {
        "id": "policies.generated-docs-freshness-policy",
        "title": "Generated Documentation Freshness Policy",
        "owner": "DocsOps",
        "dueDate": "2025-12-09",
        "daysUntilDue": 27
      },
      {
        "id": "strategy.technical-debt-tracker",
        "title": "Technical Debt Tracker - TradingSystem",
        "owner": "Architecture",
        "dueDate": "2026-01-30",
        "daysUntilDue": 79
      },
      {
        "id": "controls.tp-capital-network-validation",
        "title": "Checklist de Valida√ß√£o de Networking e Vari√°veis do TP-Capital",
        "owner": "DevOps",
        "dueDate": "2026-02-03",
        "daysUntilDue": 83
      },
      {
        "id": "policies.container-infrastructure-policy",
        "title": "Pol√≠tica de Infraestrutura de Containers, Redes e Comunica√ß√£o",
        "owner": "PlatformEngineering",
        "dueDate": "2026-02-03",
        "daysUntilDue": 83
      }
    ],
    "categoryBreakdown": [
      {
        "category": "controls",
        "count": 4
      },
      {
        "category": "evidence",
        "count": 7
      },
      {
        "category": "policies",
        "count": 5
      },
      {
        "category": "standards",
        "count": 1
      },
      {
        "category": "strategy",
        "count": 5
      }
    ]
  },
  "reviewTracking": {
    "records": [
      {
        "File Path": "governance/policies/secrets-env-policy.md",
        "Category": "policies",
        "Owner": "SecurityEngineering",
        "Reviewer": "DocsOps",
        "Status": "Done",
        "Issues Count": "0",
        "Priority": "High",
        "Sign-off Date": "2025-11-05",
        "Notes": "Aligned with STD-010 and latest audits",
        "GovernanceStatus": "Done",
        "LastAuditDate": "2025-11-05",
        "EvidenceLink": "governance/evidence/audits/secrets-audit-2025-11.json"
      },
      {
        "File Path": "governance/policies/container-infrastructure-policy.md",
        "Category": "policies",
        "Owner": "PlatformEngineering",
        "Reviewer": "DevOps",
        "Status": "Done",
        "Issues Count": "0",
        "Priority": "High",
        "Sign-off Date": "2025-11-05",
        "Notes": "Zero-trust networking baseline",
        "GovernanceStatus": "Done",
        "LastAuditDate": "2025-11-05",
        "EvidenceLink": ""
      },
      {
        "File Path": "governance/standards/secrets-standard.md",
        "Category": "standards",
        "Owner": "SecurityEngineering",
        "Reviewer": "DevOps",
        "Status": "Done",
        "Issues Count": "0",
        "Priority": "High",
        "Sign-off Date": "2025-11-05",
        "Notes": "Validated with governance:check",
        "GovernanceStatus": "Done",
        "LastAuditDate": "2025-11-05",
        "EvidenceLink": ""
      },
      {
        "File Path": "governance/controls/secrets-rotation-sop.md",
        "Category": "controls",
        "Owner": "SecurityEngineering",
        "Reviewer": "SRE",
        "Status": "Done",
        "Issues Count": "0",
        "Priority": "Medium",
        "Sign-off Date": "2025-11-05",
        "Notes": "Quarterly rotation drill logged",
        "GovernanceStatus": "Done",
        "LastAuditDate": "2025-11-05",
        "EvidenceLink": "governance/evidence/audits/secrets-rotation-2025-11-05.json"
      },
      {
        "File Path": "governance/controls/TP-CAPITAL-NETWORK-VALIDATION.md",
        "Category": "controls",
        "Owner": "DevOps",
        "Reviewer": "DocsOps",
        "Status": "Done",
        "Issues Count": "0",
        "Priority": "High",
        "Sign-off Date": "2025-11-05",
        "Notes": "Checklist e automa√ß√£o validadas com evid√™ncia gerada",
        "GovernanceStatus": "Done",
        "LastAuditDate": "2025-11-05",
        "EvidenceLink": "governance/evidence/audits/tp-capital-network-2025-11-05.json"
      },
      {
        "File Path": "governance/automation/governance-metrics.mjs",
        "Category": "automation",
        "Owner": "DocsOps",
        "Reviewer": "PlatformEngineering",
        "Status": "Done",
        "Issues Count": "0",
        "Priority": "Medium",
        "Sign-off Date": "2025-11-05",
        "Notes": "Dashboard feed refreshed with coverage SLA",
        "GovernanceStatus": "Done",
        "LastAuditDate": "2025-11-05",
        "EvidenceLink": "reports/governance/latest.json"
      }
    ],
    "statusCounts": {
      "Done": 6
    },
    "governanceStatusCounts": {
      "Done": 6
    }
  },
  "artifacts": [
    {
      "id": "controls.docusaurus-deployment-sop",
      "title": "SOP - Deployment Seguro do Docusaurus",
      "description": "Procedimento operacional para deployment seguro do Documentation Hub com valida√ß√µes pr√©-deploy e rollback.",
      "owner": "DocsOps",
      "category": "controls",
      "type": "sop",
      "tags": [
        "sop",
        "docusaurus",
        "deployment",
        "documentation"
      ],
      "lastReviewed": "2025-11-05",
      "reviewCycleDays": 180,
      "publishSlug": "/governance/controls/docusaurus-deployment-sop",
      "previewPath": "/governance/docs/controls/docusaurus-deployment-sop.md",
      "previewContent": "# Docusaurus Deployment - Standard Operating Procedure (SOP)\n\n**Control ID:** SOP-DOCS-001\n**Version:** 1.0.0\n**Last Updated:** 2025-11-07\n**Owner:** DevOps Team\n**Reviewers:** AI Agents, Documentation Team\n\n---\n\n## üéØ Purpose\n\nThis SOP prevents the **500 Internal Server Error** that occurs when the Docusaurus container starts without a valid build, causing NGINX redirect loops.\n\n## üö® Critical Rule for AI Agents\n\n**ALWAYS check and rebuild Docusaurus before restarting the docs-hub container!**\n\n```bash\n# RED FLAG: Never do this alone!\ndocker compose -f tools/compose/docker-compose.docs.yml restart\n\n# ‚úÖ CORRECT: Always rebuild docs first\ncd docs && npm run docs:build && cd .. && docker compose -f tools/compose/docker-compose.docs.yml up -d --build\n```\n\n---\n\n## üìã Problem Definition\n\n### Root Cause\n\nThe `docs-hub` container mounts `docs/build/` as a volume:\n\n```yaml\nvolumes:\n  - ../../docs/build:/usr/share/nginx/html:ro\n```\n\nIf `docs/build/` is **empty or outdated**, NGINX cannot serve files, causing:\n- `/next/` ‚Üí redirect to `/index.html` ‚Üí not found ‚Üí redirect to `/index.html` ‚Üí **infinite loop**\n- HTTP 500 Internal Server Error\n\n### NGINX Error Log Pattern\n\n```\n[error] rewrite or internal redirection cycle while internally redirecting to \"/index.html\"\n```\n\n---\n\n## üîç Detection Methods\n\n### 1. Visual Detection (User Reports)\n\n**Symptoms:**\n- User sees \"500 Internal Server Error\" page\n- URL shows `http://localhost:3404/next/` or any path\n- Browser console shows `ERR_CONNECTION_REFUSED`\n\n### 2. Automated Detection (Health Check)\n\n```bash\n# Quick health check\ncurl -f http://localhost:3404/health || echo \"‚ùå Docs service unhealthy\"\n\n# Detailed check with container logs\ndocker logs docs-hub --tail 20 | grep -i \"error\"\n```\n\n### 3. Pre-deployment Validation\n\n```bash\n# Verify build exists\nif [ ! -f \"docs/build/index.html\" ]; then\n  echo \"‚ùå ERROR: Docusaurus build not found!\"\n  exit 1\nfi\n\n# Verify build is recent (less than 1 hour old)\nif [ $(find docs/build/index.html -mmin +60 2>/dev/null | wc -l) -gt 0 ]; then\n  echo \"‚ö†Ô∏è  WARNING: Docusaurus build is older than 1 hour\"\nfi\n```\n\n---\n\n## ‚úÖ Standard Operating Procedures\n\n### SOP 1: Initial Deployment\n\n**When:** First time deploying documentation\n\n```bash\n#!/bin/bash\n# File: scripts/docs/initial-deploy.sh\n\nset -euo pipefail\n\necho \"üìö Docusaurus Initial Deployment\"\n\n# 1. Install dependencies\ncd docs\nnpm ci\n\n# 2. Build Docusaurus\necho \"üî® Building Docusaurus...\"\nnpm run docs:build\n\n# 3. Verify build\nif [ ! -f \"build/index.html\" ]; then\n  echo \"‚ùå Build failed - index.html not found\"\n  exit 1\nfi\n\n# 4. Start container\ncd ..\ndocker compose -f tools/compose/docker-compose.docs.yml up -d --build\n\n# 5. Wait for health check\necho \"‚è≥ Waiting for service to be healthy...\"\ntimeout 60 bash -c 'until curl -sf http://localhost:3404/health > /dev/null; do sleep 2; done'\n\necho \"‚úÖ Docusaurus deployed successfully!\"\necho \"üåê Access at: http://localhost:3404\"\n```\n\n### SOP 2: Content Update Deployment\n\n**When:** Documentation content changed\n\n```bash\n#!/bin/bash\n# File: scripts/docs/update-deploy.sh\n\nset -euo pipefail\n\necho \"üìù Updating Docusaurus content\"\n\n# 1. Rebuild Docusaurus\ncd docs\nnpm run docs:build\n\n# 2. Verify build succeeded\nif [ ! -f \"build/index.html\" ]; then\n  echo \"‚ùå Build failed\"\n  exit 1\nfi\n\n# 3. Restart container (volume will pick up new files)\ncd ..\ndocker compose -f tools/compose/docker-compose.docs.yml restart documentation\n\n# 4. Verify service is healthy\nsleep 5\ncurl -f http://localhost:3404/health || {\n  echo \"‚ùå Service unhealthy after restart\"\n  docker logs docs-hub --tail 50\n  exit 1\n}\n\necho \"‚úÖ Documentation updated successfully!\"\n```\n\n### SOP 3: Emergency Recovery\n\n**When:** Service is showing 500 errors\n\n```bash\n#!/bin/bash\n# File: scripts/docs/emergency-recovery.sh\n\nset -euo pipefail\n\necho \"üö® Emergency Docusaurus Recovery\"\n\n# 1. Check if build exists\nif [ ! -f \"docs/build/index.html\" ]; then\n  echo \"‚ùå Build missing - running full rebuild\"\n  cd docs\n  npm ci\n  npm run docs:build\n  cd ..\nfi\n\n# 2. Force rebuild container with clean state\necho \"üîÑ Rebuilding container...\"\ndocker compose -f tools/compose/docker-compose.docs.yml down\ndocker compose -f tools/compose/docker-compose.docs.yml up -d --build --force-recreate\n\n# 3. Verify recovery\necho \"‚è≥ Verifying recovery...\"\nsleep 10\n\nif curl -sf http://localhost:3404/health > /dev/null; then\n  echo \"‚úÖ Recovery successful!\"\nelse\n  echo \"‚ùå Recovery failed - check logs:\"\n  docker logs docs-hub --tail 100\n  exit 1\nfi\n```\n\n---\n\n## ü§ñ AI Agent Instructions\n\n### Red Flags (Immediate Action Required)\n\nIf you encounter ANY of these patterns, **STOP and follow recovery procedure**:\n\n```\n‚ùå User: \"Docusaurus showing 500 error\"\n‚ùå User: \"Documentation not loading\"\n‚ùå User: \"Getting Internal Server Error on docs\"\n‚ùå Logs: \"rewrite or internal redirection cycle\"\n‚ùå Health check fails: curl http://localhost:3404/health\n```\n\n### Automated Recovery Workflow\n\n```markdown\n## Step 1: Diagnose\n- Check if docs/build/index.html exists\n- Check docker logs: `docker logs docs-hub --tail 20`\n- Verify volume mount: `docker inspect docs-hub | jq '.[0].Mounts'`\n\n## Step 2: Rebuild Docusaurus\ncd docs && npm run docs:build\n\n## Step 3: Restart Container\ndocker compose -f tools/compose/docker-compose.docs.yml up -d --build --force-recreate\n\n## Step 4: Verify\ncurl -f http://localhost:3404/health\ncurl -I http://localhost:3404/ | grep \"200 OK\"\n\n## Step 5: Document\nCreate incident report in outputs/ if this was a production issue\n```\n\n### Prevention Checklist\n\nBefore modifying documentation or restarting containers:\n\n- [ ] ‚úÖ Verify `docs/build/index.html` exists\n- [ ] ‚úÖ Run `npm run docs:build` if content changed\n- [ ] ‚úÖ Check build timestamp is recent\n- [ ] ‚úÖ Test health endpoint after restart\n- [ ] ‚úÖ Check NGINX logs for redirect errors\n\n---\n\n## üîß Automated Validation Scripts\n\n### Pre-commit Hook\n\n**File:** `.git/hooks/pre-commit`\n\n```bash\n#!/bin/bash\n# Validate Docusaurus build before commit\n\nif git diff --cached --name-only | grep -q \"^docs/content/\"; then\n  echo \"üìö Documentation files changed - validating build...\"\n\n  cd docs\n  if ! npm run docs:build > /dev/null 2>&1; then\n    echo \"‚ùå Docusaurus build failed!\"\n    echo \"Run: cd docs && npm run docs:build\"\n    exit 1\n  fi\n\n  echo \"‚úÖ Docusaurus build valid\"\nfi\n```\n\n### CI/CD Validation\n\n**File:** `.github/workflows/docs-validation.yml`\n\n```yaml\nname: Docs Validation\n\non:\n  pull_request:\n    paths:\n      - 'docs/content/**'\n      - 'docs/src/**'\n      - 'docs/docusaurus.config.js'\n\njobs:\n  validate-build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n          cache: 'npm'\n          cache-dependency-path: docs/package-lock.json\n\n      - name: Install dependencies\n        working-directory: docs\n        run: npm ci\n\n      - name: Build Docusaurus\n        working-directory: docs\n        run: npm run docs:build\n\n      - name: Verify build output\n        run: |\n          if [ ! -f \"docs/build/index.html\" ]; then\n            echo \"‚ùå Build failed - index.html not found\"\n            exit 1\n          fi\n\n          # Check build size (should be > 100KB)\n          SIZE=$(du -sb docs/build | cut -f1)\n          if [ $SIZE -lt 102400 ]; then\n            echo \"‚ùå Build suspiciously small: $SIZE bytes\"\n            exit 1\n          fi\n\n          echo \"‚úÖ Build valid: $SIZE bytes\"\n\n      - name: Test NGINX config\n        run: |\n          docker run --rm -v $(pwd)/tools/compose/documentation/nginx.conf:/etc/nginx/nginx.conf:ro nginx:alpine nginx -t\n```\n\n### Health Check Enhancement\n\n**File:** `tools/compose/documentation/healthcheck.sh`\n\n```bash\n#!/bin/sh\n# Enhanced health check for docs-hub container\n\nset -e\n\n# 1. Basic HTTP health\nif ! curl -sf http://localhost/health > /dev/null; then\n  echo \"‚ùå Health endpoint failed\"\n  exit 1\nfi\n\n# 2. Verify index.html exists and is served\nif ! curl -sf http://localhost/ | grep -q \"docusaurus\"; then\n  echo \"‚ùå Homepage not serving correctly\"\n  exit 1\nfi\n\n# 3. Check for redirect loops in logs\nif grep -q \"rewrite or internal redirection cycle\" /var/log/nginx/error.log 2>/dev/null; then\n  echo \"‚ùå Redirect loop detected\"\n  exit 1\nfi\n\necho \"‚úÖ All health checks passed\"\nexit 0\n```\n\nUpdate `docker-compose.docs.yml`:\n\n```yaml\nhealthcheck:\n  test: [\"CMD\", \"/healthcheck.sh\"]\n  interval: 30s\n  timeout: 10s\n  start_period: 15s\n  retries: 3\n```\n\n---\n\n## üìä Monitoring & Alerts\n\n### Prometheus Metrics\n\nAdd to NGINX config:\n\n```nginx\nlocation /metrics {\n    stub_status on;\n    access_log off;\n}\n```\n\n### Grafana Dashboard Queries\n\n```promql\n# Detect redirect loops\nrate(nginx_http_requests_total{status=\"500\"}[5m]) > 0.1\n\n# Alert on unhealthy docs service\nup{job=\"docs-hub\"} == 0\n```\n\n---\n\n## üìù Incident Response Template\n\n**File:** `outputs/DOCUSAURUS-500-INCIDENT-TEMPLATE.md`\n\n```markdown\n# Docusaurus 500 Error - Incident Report\n\n**Date:** YYYY-MM-DD HH:MM\n**Reported By:** [User/System]\n**Severity:** P1 (Service Down)\n\n## Symptoms\n- [ ] 500 Internal Server Error on http://localhost:3404\n- [ ] NGINX redirect loop in logs\n- [ ] Empty /usr/share/nginx/html/ directory\n\n## Root Cause\n- [ ] Missing Docusaurus build\n- [ ] Outdated build files\n- [ ] Volume mount issue\n- [ ] NGINX config error\n\n## Resolution Steps Taken\n1. Verified build: `ls -la docs/build/index.html`\n2. Rebuilt Docusaurus: `cd docs && npm run docs:build`\n3. Restarted container: `docker compose up -d --build`\n4. Verified health: `curl http://localhost:3404/health`\n\n## Prevention\n- Updated SOP: [Link]\n- Added validation: [Script path]\n- Documented in: governance/controls/docusaurus-deployment-sop.md\n\n## Timeline\n- HH:MM - Issue detected\n- HH:MM - Root cause identified\n- HH:MM - Fix applied\n- HH:MM - Service restored\n```\n\n---\n\n## üéì Training & Knowledge Transfer\n\n### For Developers\n\n**Read these docs in order:**\n1. This SOP (docusaurus-deployment-sop.md)\n2. [Docusaurus README](../../docs/README.md)\n3. [Docker Compose Guide\n\n[... content truncated ...]"
    },
    {
      "id": "controls.governance-json-sanitization-sop",
      "title": "SOP - Sanitiza√ß√£o de JSON de Governan√ßa",
      "description": "Procedimento para sanitiza√ß√£o de conte√∫do de arquivos antes de embedding em payloads JSON.",
      "owner": "DocsOps",
      "category": "controls",
      "type": "sop",
      "tags": [
        "sop",
        "json",
        "sanitization",
        "automation"
      ],
      "lastReviewed": "2025-11-05",
      "reviewCycleDays": 180,
      "publishSlug": "/governance/controls/governance-json-sanitization-sop",
      "previewPath": "/governance/docs/controls/governance-json-sanitization-sop.md",
      "previewContent": "# Governance JSON Sanitization - Standard Operating Procedure (SOP)\n\n**Control ID:** SOP-GOV-002\n**Version:** 1.0.0\n**Last Updated:** 2025-11-07\n**Owner:** DevOps Team\n**Reviewers:** AI Agents, Documentation Team, Frontend Team\n\n---\n\n## üéØ Purpose\n\nThis SOP prevents **JSON parsing errors** in the Governance Hub frontend caused by control characters or malformed content in `frontend/dashboard/public/data/governance/latest.json`.\n\n## üö® Critical Rule for AI Agents\n\n**ALWAYS sanitize file content before embedding in JSON payloads!**\n\n```javascript\n// ‚ùå WRONG: Direct file content in JSON\nconst content = await fs.readFile(filePath, 'utf-8');\nconst json = JSON.stringify({ previewContent: content }); // Can break!\n\n// ‚úÖ CORRECT: Sanitize before JSON serialization\nconst content = await fs.readFile(filePath, 'utf-8');\nconst sanitized = sanitizeForJson(content);\nconst json = JSON.stringify({ previewContent: sanitized }); // Safe!\n```\n\n---\n\n## üìã Problem Definition\n\n### Root Cause\n\nThe governance metrics script (`governance/automation/governance-metrics.mjs`) reads markdown files and embeds their content in JSON:\n\n```javascript\nasync function readArtifactSource(relPath) {\n  const content = await fs.readFile(absolutePath, 'utf-8');\n  return content; // ‚ùå Raw content can contain control characters\n}\n```\n\n**Problem**: Markdown files may contain:\n- Control characters (0x00-0x1F, 0x7F) from copy-paste or editor quirks\n- Literal `\\n` sequences that should be escaped\n- Very large content (>1MB) causing performance issues\n\n**Result**:\n```\nBad control character in string literal in JSON at position 321342 (line 675 column 1309)\n```\n\n### NGINX Error Pattern (If Deployed)\n\n```\n[error] JSON parsing failed in dashboard frontend\n```\n\n---\n\n## üîç Detection Methods\n\n### 1. Visual Detection (User Reports)\n\n**Symptoms:**\n- Governance Hub shows \"Snapshot indispon√≠vel\"\n- Error message: \"Bad control character in string literal in JSON\"\n- Dashboard displays \"0 Documentos rastreados\"\n- Browser console shows JSON parsing error\n\n### 2. Automated Detection (Validation Script)\n\n```bash\n# Quick validation\nbash scripts/governance/validate-governance-json.sh\n\n# Detailed check with Node.js\nnode -e \"\ntry {\n  const fs = require('fs');\n  const content = fs.readFileSync('frontend/dashboard/public/data/governance/latest.json', 'utf8');\n  JSON.parse(content);\n  console.log('‚úÖ JSON is valid');\n} catch (err) {\n  console.log('‚ùå Error:', err.message);\n  process.exit(1);\n}\n\"\n```\n\n### 3. Pre-deployment Validation\n\n```bash\n# Verify JSON is valid before committing\nif ! node -e \"JSON.parse(require('fs').readFileSync('frontend/dashboard/public/data/governance/latest.json'))\"; then\n  echo \"‚ùå ERROR: Governance JSON is invalid!\"\n  exit 1\nfi\n```\n\n---\n\n## ‚úÖ Standard Operating Procedures\n\n### SOP 1: Initial Setup\n\n**When:** First time deploying governance dashboard\n\n```bash\n#!/bin/bash\n# File: scripts/governance/initial-deploy.sh\n\nset -euo pipefail\n\necho \"üìä Governance Dashboard Initial Deployment\"\n\n# 1. Generate governance snapshot\ncd governance/automation\nnode governance-metrics.mjs\n\n# 2. Validate JSON\ncd ../..\nbash scripts/governance/validate-governance-json.sh\n\n# 3. Start dashboard\ncd frontend/dashboard\nnpm run dev\n\necho \"‚úÖ Governance dashboard deployed!\"\necho \"üåê Access at: http://localhost:9080/#/governance\"\n```\n\n### SOP 2: Content Update Deployment\n\n**When:** Governance artifacts changed\n\n```bash\n#!/bin/bash\n# File: scripts/governance/update-deploy.sh\n\nset -euo pipefail\n\necho \"üìù Updating governance snapshot\"\n\n# 1. Regenerate snapshot with sanitization\nnode governance/automation/governance-metrics.mjs\n\n# 2. Validate JSON\nbash scripts/governance/validate-governance-json.sh\n\n# 3. Restart dashboard (if running)\nif curl -sf http://localhost:9080/health > /dev/null 2>&1; then\n  echo \"‚úÖ Dashboard running - changes will be picked up\"\nelse\n  echo \"‚ö†Ô∏è  Dashboard not running - start with: npm run dev\"\nfi\n\necho \"‚úÖ Governance snapshot updated!\"\n```\n\n### SOP 3: Emergency Recovery\n\n**When:** Frontend shows JSON parsing error\n\n```bash\n#!/bin/bash\n# File: scripts/governance/emergency-recovery.sh\n\nset -euo pipefail\n\necho \"üö® Governance JSON Emergency Recovery\"\n\n# 1. Backup corrupted file\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\ncp frontend/dashboard/public/data/governance/latest.json \\\n   frontend/dashboard/public/data/governance/backup_${TIMESTAMP}.json\n\n# 2. Regenerate with sanitization\nnode governance/automation/governance-metrics.mjs\n\n# 3. Validate\nbash scripts/governance/validate-governance-json.sh || {\n  echo \"‚ùå Validation failed after regeneration\"\n  exit 1\n}\n\necho \"‚úÖ Recovery successful!\"\n```\n\n---\n\n## ü§ñ AI Agent Instructions\n\n### Red Flags (Immediate Action Required)\n\nIf you encounter **ANY** of these patterns, **STOP and follow recovery procedure**:\n\n```\n‚ùå User: \"Governance Hub showing JSON error\"\n‚ùå User: \"Snapshot indispon√≠vel\"\n‚ùå User: \"Bad control character in string literal\"\n‚ùå Browser Console: \"JSON.parse: bad control character\"\n‚ùå Error mentions: position 321342 or similar\n```\n\n### Automated Recovery Workflow\n\n```markdown\n## Step 1: Diagnose\n- Check if latest.json exists\n- Validate JSON syntax: `node -e \"JSON.parse(...)\"`\n- Check file size (should be < 2MB)\n\n## Step 2: Regenerate Snapshot\nnode governance/automation/governance-metrics.mjs\n\n## Step 3: Validate\nbash scripts/governance/validate-governance-json.sh\n\n## Step 4: Verify Frontend\n- Clear browser cache (Ctrl+Shift+R)\n- Navigate to http://localhost:9080/#/governance\n- Confirm snapshot loads\n\n## Step 5: Document\nCreate incident report in outputs/ if this was a production issue\n```\n\n### Prevention Checklist\n\nBefore modifying governance artifacts or regenerating snapshot:\n\n- [ ] ‚úÖ Ensure `sanitizeForJson()` function is present in metrics script\n- [ ] ‚úÖ Run validation after generation\n- [ ] ‚úÖ Check file size is reasonable (< 2MB)\n- [ ] ‚úÖ Test in browser before committing\n- [ ] ‚úÖ Scan for control characters\n\n---\n\n## üîß Automated Validation Scripts\n\n### Pre-commit Hook\n\n**File:** `.git/hooks/pre-commit`\n\n```bash\n#!/bin/bash\n# Validate governance JSON before commit\n\nif git diff --cached --name-only | grep -q \"frontend/dashboard/public/data/governance/latest.json\"; then\n  echo \"üìä Governance JSON changed - validating...\"\n\n  if ! bash scripts/governance/validate-governance-json.sh > /dev/null 2>&1; then\n    echo \"‚ùå Governance JSON validation failed!\"\n    echo \"Run: bash scripts/governance/validate-governance-json.sh\"\n    exit 1\n  fi\n\n  echo \"‚úÖ Governance JSON is valid\"\nfi\n```\n\n### CI/CD Validation\n\n**File:** `.github/workflows/governance-validation.yml`\n\n```yaml\nname: Governance Validation\n\non:\n  pull_request:\n    paths:\n      - 'governance/**'\n      - 'frontend/dashboard/public/data/governance/**'\n\njobs:\n  validate-json:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n\n      - name: Regenerate governance snapshot\n        run: node governance/automation/governance-metrics.mjs\n\n      - name: Validate JSON\n        run: bash scripts/governance/validate-governance-json.sh\n\n      - name: Check file size\n        run: |\n          SIZE=$(stat -c%s frontend/dashboard/public/data/governance/latest.json)\n          if [ $SIZE -gt 5242880 ]; then # 5MB\n            echo \"‚ùå JSON file too large: $SIZE bytes\"\n            exit 1\n          fi\n          echo \"‚úÖ File size OK: $SIZE bytes\"\n```\n\n### Automated Sanitization\n\n**File:** `governance/automation/governance-metrics.mjs` (already implemented)\n\n```javascript\n/**\n * Sanitizes text content for safe JSON embedding.\n * Removes control characters and limits length to prevent JSON parsing errors.\n */\nfunction sanitizeForJson(content) {\n  if (!content) return null;\n\n  // Remove control characters (keep only \\n, \\t, \\r)\n  let sanitized = content.replace(/[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]/g, '');\n\n  // Limit length to 10,000 chars per artifact\n  if (sanitized.length > 10000) {\n    sanitized = sanitized.substring(0, 10000) + '\\n\\n[... content truncated ...]';\n  }\n\n  return sanitized;\n}\n```\n\n---\n\n## üìä Monitoring & Alerts\n\n### Health Check Endpoint\n\nAdd to Service Launcher or Dashboard backend:\n\n```javascript\napp.get('/api/governance/health', async (req, res) => {\n  try {\n    const content = await fs.readFile(\n      'frontend/dashboard/public/data/governance/latest.json',\n      'utf-8'\n    );\n    JSON.parse(content); // Validate JSON\n    res.json({ status: 'healthy', size: content.length });\n  } catch (error) {\n    res.status(500).json({ status: 'unhealthy', error: error.message });\n  }\n});\n```\n\n### Prometheus Metrics\n\n```promql\n# Alert on governance JSON errors\ngovernance_json_parse_errors_total > 0\n\n# Alert on file size\ngovernance_json_size_bytes > 5242880\n```\n\n---\n\n## üìù Incident Response Template\n\n**File:** `outputs/GOVERNANCE-JSON-INCIDENT-TEMPLATE.md`\n\n```markdown\n# Governance JSON Error - Incident Report\n\n**Date:** YYYY-MM-DD HH:MM\n**Reported By:** [User/System]\n**Severity:** P1 (Dashboard Feature Down)\n\n## Symptoms\n- [ ] \"Snapshot indispon√≠vel\" message in Governance Hub\n- [ ] \"Bad control character\" JSON parsing error\n- [ ] Browser console shows JSON.parse error\n- [ ] Dashboard displays \"0 Documentos rastreados\"\n\n## Root Cause\n- [ ] Control characters in artifact preview content\n- [ ] Missing sanitization in metrics generation\n- [ ] Corrupted governance artifact file\n- [ ] File size exceeded limits\n\n## Resolution Steps Taken\n1. Verified JSON invalid: `node -e \"JSON.parse(...)\"`\n2. Regenerated snapshot: `node governance/automation/governance-metrics.mjs`\n3. Validated output: `bash scripts/governance/validate-governance-json.sh`\n4. Tested in browser: http://localhost:9080/#/governance\n\n## Prevention\n- Added sanitization function: `sanitizeForJson()`\n- Created validation script: `scripts/governance/validate-governance-json.sh`\n- Documented in: governance/controls/governance-json-sanitization-sop.md\n\n## Timeline\n- HH:MM - Issue detected\n- HH:MM - Root cause identified (contro\n\n[... content truncated ...]"
    },
    {
      "id": "controls.secrets-rotation-sop",
      "title": "SOP - Rota√ß√£o de Segredos e Vari√°veis de Ambiente",
      "description": "Procedimento passo-a-passo para rota√ß√£o segura de segredos (API keys, tokens, senhas) em todos os ambientes do TradingSystem.",
      "owner": "SecurityEngineering",
      "category": "controls",
      "type": "sop",
      "tags": [
        "sop",
        "runbook",
        "secrets",
        "incident-response"
      ],
      "lastReviewed": "2025-11-05",
      "reviewCycleDays": 180,
      "publishSlug": "/governance/controls/secrets-rotation-sop",
      "previewPath": "/governance/docs/controls/secrets-rotation-sop.md",
      "previewContent": "---\ntitle: \"SOP - Rota√ß√£o de Segredos e Vari√°veis de Ambiente\"\nid: SOP-SEC-001\nowner: SecurityEngineering\nlastReviewed: \"2025-11-05\"\nreviewCycleDays: 180\nstatus: active\nrelatedPolicies:\n  - POL-0002\nrelatedStandards:\n  - STD-010\ntags:\n  - sop\n  - runbook\n  - secrets\n  - incident-response\n---\n\n# SOP - Rota√ß√£o de Segredos e Vari√°veis de Ambiente\n\n**ID:** SOP-SEC-001  \n**Owner:** SecurityEngineering  \n**Status:** Active  \n**Last Reviewed:** 2025-11-05\n\n## 1. Objetivo\n\nFornecer procedimento **passo-a-passo** para rota√ß√£o segura de segredos (API keys, tokens, senhas) em todos os ambientes do TradingSystem, garantindo zero downtime e rastreabilidade completa.\n\n## 2. Escopo\n\n- **Segredos Cobertos:**\n  - Senhas de banco de dados (TimescaleDB, QuestDB, PostgreSQL)\n  - Tokens de API externa (Telegram Bot, Evolution API, Firecrawl)\n  - JWT Secrets (autentica√ß√£o interna)\n  - Credenciais ProfitDLL (Nelogica)\n  - Age encryption keys\n\n- **Ambientes:**\n  - Desenvolvimento Local\n  - CI/CD (GitHub Actions)\n  - Staging/Homologa√ß√£o\n  - Produ√ß√£o (Windows + Docker/WSL)\n\n## 3. Frequ√™ncia de Rota√ß√£o\n\n| Tipo de Segredo | Frequ√™ncia Planejada | Rota√ß√£o de Emerg√™ncia |\n|-----------------|----------------------|------------------------|\n| **Senhas de DB** | 180 dias | Imediatamente |\n| **Tokens de API** | 90 dias | Imediatamente |\n| **JWT Secrets** | 90 dias | Imediatamente |\n| **ProfitDLL Credentials** | 180 dias | Imediatamente |\n| **Age Private Keys** | Anualmente | Imediatamente |\n\n**Triggers de Emerg√™ncia:**\n- Exposi√ß√£o acidental em commit/log\n- Suspeita de comprometimento\n- Sa√≠da de colaborador com acesso\n- Auditoria de seguran√ßa identificou vulnerabilidade\n\n## 4. Pr√©-Requisitos\n\n### 4.1 Ferramentas Necess√°rias\n\n```bash\n# Node.js/npm (automa√ß√£o)\nnode --version  # >=18.0.0\nnpm --version\n\n# SOPS + age (criptografia)\nage --version\nsops --version\n\n# Docker (descriptografia em containers)\ndocker --version\n\n# PowerShell (Windows nativo)\npwsh --version  # >=7.0\n```\n\n### 4.2 Permiss√µes Necess√°rias\n\n- **GitHub:** Admin access to repository secrets\n- **Azure/AWS:** IAM roles for OIDC token exchange\n- **Windows:** Administrator rights (setx /M)\n- **Docker:** Access to production volumes/secrets\n\n### 4.3 Backups Atuais\n\n**ANTES de iniciar rota√ß√£o, garantir:**\n```bash\n# 1. Backup do .env atual (descriptografado)\ncp .env .env.backup.$(date +%Y%m%d-%H%M%S)\n\n# 2. Backup dos secrets criptografados\ncp config/secrets.enc.yaml config/secrets.enc.yaml.backup.$(date +%Y%m%d)\n\n# 3. Documentar valores antigos (HASH, n√£o plaintext)\necho \"OLD_JWT_SECRET_HASH=$(echo -n $JWT_SECRET | sha256sum)\" >> rotation.log\n```\n\n## 5. Procedimento de Rota√ß√£o\n\n### 5.1 Rota√ß√£o de Senha de Banco de Dados\n\n#### Fase 1: Gerar Nova Senha\n\n```bash\n# Gerar senha forte (32 chars, alfanum√©rico + s√≠mbolos)\nNEW_DB_PASSWORD=$(openssl rand -base64 32 | tr -d \"=+/\" | cut -c1-32)\necho \"Nova senha gerada (N√ÉO logar plaintext em produ√ß√£o): ${NEW_DB_PASSWORD:0:4}***\"\n```\n\n#### Fase 2: Atualizar Banco de Dados\n\n**PostgreSQL/TimescaleDB:**\n```sql\n-- Conectar como superuser\npsql -U postgres -h localhost\n\n-- Alterar senha do usu√°rio da aplica√ß√£o\nALTER USER workspace_user WITH PASSWORD 'NEW_DB_PASSWORD';\n\n-- Verificar\n\\du workspace_user\n```\n\n**QuestDB:**\n```bash\n# Atualizar arquivo de configura√ß√£o\necho \"pg.user.password=NEW_DB_PASSWORD\" >> /var/lib/questdb/conf/server.conf\n\n# Reiniciar QuestDB (Docker)\ndocker compose -f tools/compose/docker-compose.data.yml restart questdb\n```\n\n#### Fase 3: Atualizar Aplica√ß√£o\n\n**Desenvolvimento Local:**\n```bash\n# Editar .env (N√ÉO versionar)\nsed -i \"s|WORKSPACE__DB__PRIMARY__URL=postgresql://.*|WORKSPACE__DB__PRIMARY__URL=postgresql://workspace_user:${NEW_DB_PASSWORD}@localhost:5432/workspace|\" .env\n```\n\n**Staging/Production (SOPS):**\n```bash\n# 1. Descriptografar secrets\nage -d -i ~/.age/key.txt config/secrets.enc.yaml > config/secrets.yaml\n\n# 2. Editar valor\nyq eval \".database.password = \\\"${NEW_DB_PASSWORD}\\\"\" -i config/secrets.yaml\n\n# 3. Re-criptografar\nage -R config/.age-recipients.txt -o config/secrets.enc.yaml config/secrets.yaml\n\n# 4. Remover plaintext\nshred -u config/secrets.yaml\n\n# 5. Commitar vers√£o criptografada\ngit add config/secrets.enc.yaml\ngit commit -m \"chore(secrets): rotate database password\"\n```\n\n**GitHub Secrets (CI/CD):**\n```bash\n# Via GitHub CLI\ngh secret set WORKSPACE__DB__PRIMARY__URL \\\n  --body \"postgresql://workspace_user:${NEW_DB_PASSWORD}@db.production.local:5432/workspace\" \\\n  --env production\n```\n\n#### Fase 4: Testar Conex√£o\n\n```bash\n# Staging\ndocker compose -f tools/compose/docker-compose.apps.yml exec workspace-api \\\n  npm run db:test-connection\n\n# Production Windows\ncd C:\\TradingSystem\\OrderManager\ndotnet run --no-build -- --test-db-connection\n```\n\n#### Fase 5: Rollout e Monitoramento\n\n```bash\n# Staging (testar primeiro)\ndocker compose -f tools/compose/docker-compose.apps.yml restart workspace-api\n\n# Aguardar 5 minutos, monitorar logs\ndocker logs -f workspace-api --since 5m | grep -i \"database\\|connection\"\n\n# Se OK, aplicar em produ√ß√£o\nsystemctl restart tradingsystem-ordermanager.service\nsystemctl status tradingsystem-ordermanager.service\n\n# Monitorar por 24h (janela de rollback)\ntail -f /var/log/trading/ordermanager.log | grep -i \"database\"\n```\n\n#### Fase 6: Registrar Evid√™ncia\n\n```bash\n# Gerar evid√™ncia JSON\ncat > governance/evidence/audits/secrets-rotation-$(date +%Y-%m-%d).json <<EOF\n{\n  \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",\n  \"type\": \"secrets_rotation\",\n  \"actor\": \"$(whoami)\",\n  \"environment\": \"production\",\n  \"secrets_rotated\": [\n    {\n      \"key\": \"WORKSPACE__DB__PRIMARY__URL\",\n      \"service\": \"WorkspaceAPI\",\n      \"old_hash\": \"$(echo -n '$OLD_DB_PASSWORD' | sha256sum | cut -d' ' -f1)\",\n      \"new_hash\": \"$(echo -n '$NEW_DB_PASSWORD' | sha256sum | cut -d' ' -f1)\",\n      \"rotation_method\": \"manual_sop\",\n      \"tested_in_staging\": true,\n      \"downtime\": \"0s\"\n    }\n  ],\n  \"rollback_available_until\": \"$(date -u -d '+24 hours' +%Y-%m-%dT%H:%M:%SZ)\",\n  \"notes\": \"Rota√ß√£o planejada (90 dias)\"\n}\nEOF\n```\n\n### 5.2 Rota√ß√£o de Token de API Externa (Telegram Bot)\n\n#### Fase 1: Gerar Novo Token\n\n```bash\n# 1. Acessar BotFather no Telegram\n# 2. Enviar: /revoke\n# 3. Selecionar bot\n# 4. Copiar novo token: 1234567890:ABCdefGHIjklMNOpqrsTUVwxyz\n\nNEW_TELEGRAM_TOKEN=\"1234567890:ABCdefGHIjklMNOpqrsTUVwxyz\"\n```\n\n#### Fase 2: Atualizar Configura√ß√£o\n\n**Desenvolvimento Local:**\n```bash\nsed -i \"s|TELEGRAM__BOT_TOKEN=.*|TELEGRAM__BOT_TOKEN=${NEW_TELEGRAM_TOKEN}|\" .env\n```\n\n**Staging/Production:**\n```bash\n# Atualizar secrets.enc.yaml (mesmo processo 5.1 Fase 3)\nage -d -i ~/.age/key.txt config/secrets.enc.yaml > config/secrets.yaml\nyq eval \".telegram.bot_token = \\\"${NEW_TELEGRAM_TOKEN}\\\"\" -i config/secrets.yaml\nage -R config/.age-recipients.txt -o config/secrets.enc.yaml config/secrets.yaml\nshred -u config/secrets.yaml\n```\n\n#### Fase 3: Testar Webhook\n\n```bash\n# Testar novo token\ncurl -X POST \"https://api.telegram.org/bot${NEW_TELEGRAM_TOKEN}/getMe\"\n\n# Configurar webhook\ncurl -X POST \"https://api.telegram.org/bot${NEW_TELEGRAM_TOKEN}/setWebhook\" \\\n  -d \"url=https://tradingsystem.local/webhook/telegram\"\n```\n\n#### Fase 4: Deploy e Valida√ß√£o\n\n```bash\n# Restart servi√ßo\ndocker compose -f tools/compose/docker-compose.apps.yml restart tp-capital\n\n# Enviar mensagem de teste no bot\n# Verificar logs\ndocker logs tp-capital --since 2m | grep \"webhook received\"\n```\n\n### 5.3 Rota√ß√£o de JWT Secret\n\n#### Fase 1: Gerar Novo Secret\n\n```bash\nNEW_JWT_SECRET=$(openssl rand -base64 64 | tr -d '\\n')\necho \"Novo JWT Secret: ${NEW_JWT_SECRET:0:8}***\"\n```\n\n#### Fase 2: Implementar Dual-Key Support (Zero Downtime)\n\n**Node.js (Express):**\n```javascript\n// middleware/auth.js\nconst OLD_JWT_SECRET = process.env.JWT_SECRET;\nconst NEW_JWT_SECRET = process.env.JWT_SECRET_NEW;\n\nfunction verifyToken(token) {\n  try {\n    // Tentar novo secret primeiro\n    return jwt.verify(token, NEW_JWT_SECRET);\n  } catch (err) {\n    // Fallback para secret antigo (compatibilidade)\n    return jwt.verify(token, OLD_JWT_SECRET);\n  }\n}\n\nfunction signToken(payload) {\n  // SEMPRE assinar com novo secret\n  return jwt.sign(payload, NEW_JWT_SECRET, { expiresIn: '1h' });\n}\n```\n\n#### Fase 3: Rollout Gradual\n\n```bash\n# 1. Deploy c√≥digo com dual-key support\ngit commit -m \"feat(auth): support dual JWT secrets for rotation\"\ngit push\n\n# 2. Atualizar NEW_JWT_SECRET em produ√ß√£o (manter OLD)\ngh secret set JWT_SECRET_NEW --body \"${NEW_JWT_SECRET}\" --env production\n\n# 3. Aguardar 24h (todos os tokens antigos expirarem)\n\n# 4. Promover novo secret e remover antigo\ngh secret set JWT_SECRET --body \"${NEW_JWT_SECRET}\" --env production\ngh secret delete JWT_SECRET_NEW --env production\n\n# 5. Remover dual-key do c√≥digo\ngit commit -m \"chore(auth): remove dual JWT secret support\"\n```\n\n### 5.4 Rota√ß√£o de Age Private Key\n\n**‚ö†Ô∏è CR√çTICO: Processo mais sens√≠vel, requer coordena√ß√£o de toda a equipe.**\n\n#### Fase 1: Gerar Novo Par de Chaves\n\n```bash\n# Gerar novo par age\nage-keygen -o ~/.age/key-new.txt\n\n# Extrair public key\nAGE_PUBLIC_NEW=$(grep \"public key:\" ~/.age/key-new.txt | cut -d: -f2 | tr -d ' ')\necho \"Nova public key: $AGE_PUBLIC_NEW\"\n```\n\n#### Fase 2: Adicionar Recipient\n\n```bash\n# Adicionar nova public key aos recipients (mantendo antiga)\necho \"$AGE_PUBLIC_NEW\" >> config/.age-recipients.txt\n\n# Commitar\ngit add config/.age-recipients.txt\ngit commit -m \"chore(secrets): add new age recipient for key rotation\"\n```\n\n#### Fase 3: Re-criptografar Todos os Secrets\n\n```bash\n# 1. Descriptografar com chave antiga\nage -d -i ~/.age/key.txt config/secrets.enc.yaml > config/secrets.yaml\n\n# 2. Re-criptografar com AMBAS as chaves (recipients file)\nage -R config/.age-recipients.txt -o config/secrets.enc.yaml config/secrets.yaml\n\n# 3. Testar descriptografia com nova chave\nage -d -i ~/.age/key-new.txt config/secrets.enc.yaml > /dev/null && echo \"‚úÖ Nova chave funciona\"\n\n# 4. Remover plaintext\nshred -u config/secrets.yaml\n```\n\n#### Fase 4: Distribuir Nova Chave para Equipe/Ambientes\n\n```bash\n# GitHub Actions (via UI ou CLI)\ngh secret set AGE_SE\n\n[... content truncated ...]"
    },
    {
      "id": "controls.tp-capital-network-validation",
      "title": "Checklist de Valida√ß√£o de Networking e Vari√°veis do TP-Capital",
      "description": "Checklist e automa√ß√£o para validar redes Docker, vari√°veis e portas do stack TP-Capital antes de liberar servi√ßos.",
      "owner": "DevOps",
      "category": "controls",
      "type": "sop",
      "tags": [
        "sop",
        "networking",
        "docker",
        "environment-variables",
        "incident-prevention"
      ],
      "lastReviewed": "2025-11-05",
      "reviewCycleDays": 90,
      "publishSlug": "/governance/controls/tp-capital-network-validation",
      "previewPath": "/governance/docs/controls/TP-CAPITAL-NETWORK-VALIDATION.md",
      "previewContent": "---\ntitle: \"Checklist de Valida√ß√£o de Networking e Vari√°veis do TP-Capital\"\nid: SOP-NET-002\nowner: DevOps\nlastReviewed: \"2025-11-05\"\nreviewCycleDays: 90\nstatus: active\nrelatedPolicies:\n  - POL-0003\nrelatedStandards:\n  - STD-010\ntags:\n  - sop\n  - networking\n  - docker\n  - environment-variables\n  - incident-prevention\n---\n\n# Checklist de Valida√ß√£o de Networking e Vari√°veis do TP-Capital\n\n**Objetivo**  \nEvitar recorr√™ncia do incidente de 05/11/2025 (falha de conectividade TP-Capital) garantindo que servi√ßos Telegram/TP-Capital e Dashboard iniciem com redes, portas e vari√°veis consistentes antes de liberar usu√°rios.\n\n## 1. Escopo\n\n- Stacks: `tools/compose/docker-compose.4-2-telegram-stack.yml`, `docker-compose.4-1-tp-capital-stack.yml`, `docker-compose.1-dashboard-stack.yml`\n- Servi√ßos afetados: Telegram Gateway API, TP-Capital API, PgBouncer/Timescale, Dashboard UI\n- Ambientes: dev local (Docker/WSL) e homologa√ß√£o\n\n## 2. Prepara√ß√£o\n\n1. Carregar `.env` central com `set -a && source ../../.env && set +a`.\n2. Verificar criptos via `npm run governance:validate-envs`.\n3. Executar `docker network ls | grep tradingsystem` para garantir redes `telegram_backend`, `tp_capital_backend`, `tradingsystem_backend` e `tradingsystem_frontend`.\n\n## 3. Checklist de Vari√°veis\n\n| Vari√°vel | Origem | Esperado |\n|----------|--------|----------|\n| `TELEGRAM_DB_PASSWORD` | `.env` | Nunca vazio; validar com `scripts/maintenance/health-check-all.sh --format json` |\n| `TELEGRAM_GATEWAY_URL` | compose TP-Capital | Deve apontar para `http://telegram-gateway-api:4010` |\n| `VITE_TP_CAPITAL_PROXY_TARGET` | compose Dashboard | Usar porta interna `http://tp-capital-api:4005` |\n| `VITE_TP_CAPITAL_API_URL` | `.env` | Comentado (proxy faz o roteamento) |\n| `WORKSPACE__API__BASE_URL` | `.env` | Deve usar hostname de servi√ßo + porta interna |\n\n> _Falha em qualquer linha acima bloqueia deploy at√© corre√ß√£o._\n\n## 4. Checklist de Redes e Portas\n\n1. **PgBouncer isolado**  \n   ```bash\n   docker inspect telegram-pgbouncer --format '{{ .HostConfig.NetworkMode }}'\n   # Deve retornar \"telegram_backend\"\n   ```\n2. **APIs como pontes** (duas redes)  \n   ```bash\n   docker inspect telegram-gateway-api --format '{{ json .NetworkSettings.Networks }}' | jq 'keys'\n   # Deve conter telegram_backend e tradingsystem_backend\n   ```\n3. **Dashboard isolado**  \n   - `tradingsystem_frontend` + `tradingsystem_backend`; nunca conectar a `telegram_backend`.\n4. **Portas internas x externas**  \n   - Confirmar `docker compose ps tp-capital-api` usa `4005/tcp -> 4008`.\n   - Dashboard deve consumir `4005` via proxy, n√£o `4008`.\n\n## 5. Valida√ß√£o Automatizada\n\nExecute antes de qualquer `docker compose up`:\n\n```bash\nnpm run governance:check\nnode scripts/maintenance/check-tp-capital-stack.mjs  # valida portas, redes e envs\n```\n\n`check-tp-capital-stack.mjs` (novo script) executa:\n- Assert de vari√°veis obrigat√≥rias com valores n√£o vazios.\n- Confer√™ncia de redes via `docker network inspect`.\n- Verifica√ß√£o de portas com `docker compose config --services`.\n- Resultado JSON em `governance/evidence/audits/tp-capital-network-YYYY-MM-DD.json`.\n\n## 6. Crit√©rios de Aprova√ß√£o\n\n- ‚úÖ Todos os comandos retornam zero.\n- ‚úÖ Logs finais sem `Connection refused`, `password authentication failed` ou `host.docker.internal`.\n- ‚úÖ Evid√™ncia JSON anexada ao PR ou registro di√°rio.\n\n## 7. A√ß√µes P√≥s-Deploy\n\n1. Executar `frontend/dashboard/e2e/workspace.functional.spec.ts --grep \"@tp-capital\"` para validar integra√ß√µes.\n2. Registrar resultado no `governance/evidence/reports/telegram-architecture-YYYY-MM-DD.md`.\n3. Atualizar incidentes/resolved tickets se houve corre√ß√£o.\n\n## 8. Hist√≥rico\n\n| Data | Vers√£o | Autor | Notas |\n|------|--------|-------|-------|\n| 2025-11-05 | 1.0 | DevOps | Cria√ß√£o baseada no incidente TP-Capital |\n\n"
    },
    {
      "id": "evidence.architecture-review-2025-11-01",
      "title": "Architecture Review - TradingSystem (2025-11-01)",
      "description": "Revis√£o arquitetural completa do sistema com an√°lise de padr√µes, depend√™ncias, seguran√ßa e recomenda√ß√µes. Score: B+ (85/100).",
      "owner": "Architecture",
      "category": "evidence",
      "type": "report",
      "tags": [
        "architecture",
        "review",
        "quality",
        "technical-debt"
      ],
      "lastReviewed": "2025-11-01",
      "reviewCycleDays": 180,
      "publishSlug": null,
      "previewPath": "/governance/docs/evidence/reports/reviews/architecture-2025-11-01/index.md",
      "previewContent": "---\ntitle: \"Architecture Review 2025-11-01\"\nslug: /governance/reviews/architecture/2025-11-01\ndescription: \"Executive summary and navigation hub for the comprehensive TradingSystem architecture review dated 1 Nov 2025.\"\nsidebar_label: \"2025-11-01 Architecture Review\"\ndate: 2025-11-01\nstatus: completed\nseverity: informational\ntype: architectural-review\nreviewers:\n  - Claude Code Architecture Reviewer\ntags:\n  - architecture\n  - review\n  - assessment\n  - recommendations\nkeywords:\n  - TradingSystem architecture\n  - governance review\n  - clean architecture\n  - ddd\n---\n\nThe TradingSystem project demonstrates a **well-structured hybrid architecture** that combines Clean Architecture, Domain-Driven Design (DDD), microservices, and event-driven communication. This review captures the state of the system on **1 November 2025** and highlights the most impactful strengths and risks discovered during the assessment.\n\n**Overall Architecture Grade:** `B+` (Good foundations with clear opportunities for optimization).\n\n## Quick Navigation\n\n- [System Structure Assessment](./system-structure.md)\n- [Design Patterns & Dependency Analysis](./design-patterns-and-dependencies.md)\n- [Data & Integration Flows](./data-and-integration.md)\n- [Scalability & Security Architecture](./scalability-and-security.md)\n- [Improvement Roadmap & Technical Debt](./recommendations-and-debt.md)\n- [Conclusion & Action Plan](./conclusion.md)\n- [Appendices (Diagrams, Benchmarks, Checklists)](./appendices.md)\n\n## Executive Summary\n\n### Key Strengths\n- ‚úÖ Clear separation of concerns across backend, frontend, documentation, and tooling layers.\n- ‚úÖ Comprehensive Docusaurus documentation supporting onboarding, governance, and operations.\n- ‚úÖ Centralized configuration management via the root `.env`, reducing drift.\n- ‚úÖ Docker Compose orchestration simplifies auxiliary service lifecycle management.\n- ‚úÖ Observability foundations with health monitoring and metrics instrumentation.\n- ‚úÖ Security-first mindset (JWT, rate limiting, CORS, Helmet).\n- ‚úÖ Modern frontend state management (Zustand with devtools).\n- ‚úÖ Retrieval-Augmented Generation (RAG) stack that augments documentation search.\n\n### Critical Improvement Areas\n- ‚ö†Ô∏è High coupling between services and shared dependencies increases blast radius.\n- ‚ö†Ô∏è Inconsistent error handling across services undermines reliability.\n- ‚ö†Ô∏è Limited automated test coverage (integration/E2E gaps).\n- ‚ö†Ô∏è No API versioning strategy to manage breaking changes.\n- ‚ö†Ô∏è Mixed deployment modes (Windows native + Docker) create operational friction.\n- ‚ö†Ô∏è Performance bottlenecks in the real-time trading data pipeline.\n- ‚ö†Ô∏è Missing inter-service authentication leaves lateral movement unchecked.\n\n## How to Use This Review\n\nEach linked section provides deeper analysis, code references, and recommended remediation steps. Use the [Conclusion & Action Plan](./conclusion.md) to align engineering roadmap, and refer to the [Appendices](./appendices.md) for diagrams, benchmarks, and security checklists that support implementation work.\n"
    },
    {
      "id": "evidence.cleanup-report-2025-11-08",
      "title": "Governance Cleanup Report - November 2025",
      "description": "Relat√≥rio detalhado do plano de limpeza e consolida√ß√£o da estrutura de governan√ßa.",
      "owner": "Governance",
      "category": "evidence",
      "type": "report",
      "tags": [
        "governance",
        "cleanup",
        "planning",
        "analysis"
      ],
      "lastReviewed": "2025-11-08",
      "reviewCycleDays": 180,
      "publishSlug": null,
      "previewPath": "/governance/docs/GOVERNANCE-CLEANUP-REPORT-2025-11-08.md",
      "previewContent": "# üßπ Governance Cleanup Report - 2025-11-08\n\n**Data:** 2025-11-08\n**Tipo:** Limpeza e Consolida√ß√£o\n**Owner:** Governance Team\n**Status:** Em Execu√ß√£o\n\n---\n\n## üìä Executive Summary\n\n### An√°lise Atual\n- **Arquivos totais**: 100+ arquivos (excluindo node_modules)\n- **Duplica√ß√µes identificadas**: 23 arquivos redundantes\n- **Consolida√ß√µes necess√°rias**: 5 grupos de documentos\n- **Espa√ßo recuper√°vel**: ~450 KB\n- **Impacto na clareza**: Alto - muitos pontos de entrada confusos\n\n### Objetivo\nReduzir complexidade, eliminar redund√¢ncias e criar estrutura clara de navega√ß√£o.\n\n---\n\n## üîç An√°lise Detalhada por Categoria\n\n### 1Ô∏è‚É£ ROOT LEVEL - 13 Arquivos (CR√çTICO)\n\n**Problema**: Excesso de arquivos na raiz causando confus√£o de navega√ß√£o.\n\n#### ‚úÖ MANTER (5 arquivos)\n```\ngovernance/\n‚îú‚îÄ‚îÄ README.md                          # Entry point principal\n‚îú‚îÄ‚îÄ GOVERNANCE-SUMMARY.md              # Sum√°rio executivo (NOVO)\n‚îú‚îÄ‚îÄ GOVERNANCE-ACTION-PLAN.md          # Plano de a√ß√£o (NOVO)\n‚îú‚îÄ‚îÄ GOVERNANCE-INDEX.md                # √çndice navega√ß√£o\n‚îî‚îÄ‚îÄ START-HERE.md                      # Quick start (NOVO)\n```\n\n#### ‚ùå ARQUIVAR (8 arquivos ‚Üí evidence/archive/)\n```\nPARA ARQUIVAR:\n‚îú‚îÄ‚îÄ GOVERNANCE-IMPROVEMENTS-2025-11-05.md    ‚Üí evidence/archive/governance-improvements-2025-11-05.md\n‚îú‚îÄ‚îÄ IMPLEMENTATION-CHECKLIST.md              ‚Üí evidence/archive/implementation-checklist-2025-11-08.md\n‚îú‚îÄ‚îÄ IMPLEMENTATION-PLAN.md                   ‚Üí evidence/archive/implementation-plan-2025-11-08.md\n‚îú‚îÄ‚îÄ IMPROVEMENT-README.md                    ‚Üí evidence/archive/improvement-readme-2025-11-08.md\n‚îú‚îÄ‚îÄ KICKOFF-CHECKLIST.md                     ‚Üí evidence/archive/kickoff-checklist-2025-11-08.md\n‚îú‚îÄ‚îÄ NEXT-STEPS.md                            ‚Üí evidence/archive/next-steps-2025-11-08.md\n‚îú‚îÄ‚îÄ README-INCIDENT-2025-11-05.md            ‚Üí evidence/archive/readme-incident-2025-11-05.md\n‚îî‚îÄ‚îÄ index.md                                 ‚Üí evidence/archive/index-old-2025-11-08.md\n```\n\n**Raz√£o**: Documentos de implementa√ß√£o s√£o transit√≥rios. Ap√≥s kickoff (11/11), tornam-se hist√≥ricos.\n\n---\n\n### 2Ô∏è‚É£ EVIDENCE/REPORTS/REVIEWS - 32 Arquivos\n\n**Problema**: 4 reviews de arquitetura com overlap significativo.\n\n#### Architecture Reviews - Consolida√ß√£o\n\n**MANTER**:\n```\nevidence/reports/reviews/\n‚îî‚îÄ‚îÄ architecture-2025-11-01/          # ‚úÖ Review principal (8 arquivos, Docusaurus)\n    ‚îú‚îÄ‚îÄ index.md                      # Score: B+ (85/100)\n    ‚îú‚îÄ‚îÄ system-structure.md\n    ‚îú‚îÄ‚îÄ design-patterns-and-dependencies.md\n    ‚îú‚îÄ‚îÄ data-and-integration.md\n    ‚îú‚îÄ‚îÄ scalability-and-security.md\n    ‚îú‚îÄ‚îÄ recommendations-and-debt.md\n    ‚îú‚îÄ‚îÄ conclusion.md\n    ‚îî‚îÄ‚îÄ appendices.md\n```\n\n**ARQUIVAR**:\n```\n‚ùå architecture-2025-11-02/           ‚Üí evidence/archive/reviews/\n   ‚îî‚îÄ‚îÄ ARCHITECTURE-REVIEW-2025-11-02.md\n\n‚ùå architecture-rag-2025-11-03/       ‚Üí evidence/archive/reviews/\n   ‚îî‚îÄ‚îÄ [13 arquivos RAG-specific]\n\n‚ùå performance-2025-11-02/            ‚Üí evidence/archive/reviews/\n   ‚îî‚îÄ‚îÄ [3 arquivos de performance]\n```\n\n**Raz√£o**:\n- architecture-2025-11-02 √© draft/duplicata do 2025-11-01\n- architecture-rag-2025-11-03 √© an√°lise espec√≠fica RAG (migrado para docs/content/apps/rag/)\n- performance-2025-11-02 √© parte da architecture review principal\n\n#### Telegram Reviews - Consolida√ß√£o\n\n**ARQUIVAR** (3 arquivos ‚Üí docs/content/apps/tp-capital/):\n```\n‚ùå TELEGRAM-ARCHITECTURE-SUMMARY.md\n‚ùå TELEGRAM-DATABASE-SUMMARY.md\n‚ùå telegram-*.md (3 files)\n```\n\n**Raz√£o**: Conte√∫do espec√≠fico de app deve estar em docs/content/apps/, n√£o em governance/\n\n---\n\n### 3Ô∏è‚É£ CONTROLS (SOPs) - 14 Arquivos\n\n**Problema**: Alguns arquivos n√£o s√£o SOPs formais.\n\n#### ‚úÖ MANTER (SOPs Formais - 4 arquivos)\n```\ncontrols/\n‚îú‚îÄ‚îÄ secrets-rotation-sop.md                    # SOP-SEC-001\n‚îú‚îÄ‚îÄ TP-CAPITAL-NETWORK-VALIDATION.md           # SOP-NET-002\n‚îú‚îÄ‚îÄ docusaurus-deployment-sop.md               # SOP-DOCS-001\n‚îî‚îÄ‚îÄ governance-json-sanitization-sop.md        # SOP-DOCS-002\n```\n\n#### üìã MANTER (Checklists e Guias - 6 arquivos)\n```\ncontrols/\n‚îú‚îÄ‚îÄ VALIDATION-GUIDE.md                        # Validation suite\n‚îú‚îÄ‚îÄ REVIEW-CHECKLIST.md                        # Review process\n‚îú‚îÄ‚îÄ PRE-DEPLOY-CHECKLIST.md                    # Deployment checks\n‚îú‚îÄ‚îÄ MAINTENANCE-CHECKLIST.md                   # Maintenance tasks\n‚îú‚îÄ‚îÄ AUTOMATED-MAINTENANCE-GUIDE.md             # Automation guide\n‚îî‚îÄ‚îÄ MAINTENANCE-AUTOMATION-GUIDE.md            # Automation reference\n```\n\n#### ‚ùå MOVER (Policies ‚Üí policies/)\n```\ncontrols/ENVIRONMENT-VARIABLES-POLICY.md       ‚Üí policies/environment-variables-policy.md\ncontrols/hardcoded-urls-prevention-policy.md   ‚Üí policies/hardcoded-urls-policy.md\n```\n\n#### ‚ùå MOVER (References ‚Üí evidence/references/)\n```\ncontrols/CODE-DOCS-SYNC.md                     ‚Üí evidence/references/code-docs-sync.md\ncontrols/LINK-MIGRATION-REFERENCE.md           ‚Üí evidence/references/link-migration.md\n```\n\n**Raz√£o**: Separa√ß√£o clara entre SOPs (procedures), Policies (rules), e References (guides).\n\n---\n\n### 4Ô∏è‚É£ STRATEGY - 8 Arquivos\n\n#### ‚úÖ MANTER (Ativos - 3 arquivos)\n```\nstrategy/\n‚îú‚îÄ‚îÄ TECHNICAL-DEBT-TRACKER.md                  # ‚úÖ Ativo\n‚îú‚îÄ‚îÄ CI-CD-INTEGRATION.md                       # ‚úÖ Roadmap CI/CD\n‚îî‚îÄ‚îÄ COMMUNICATION-PLAN.md                      # ‚úÖ Plano comunica√ß√£o\n```\n\n#### ‚ùå ARQUIVAR (Completados - 5 arquivos ‚Üí evidence/archive/strategy/)\n```\n‚ùå CUTOVER-PLAN.md                             # Migra√ß√£o Docusaurus completa\n‚ùå DIAGRAM-MIGRATION-GUIDE.md                  # Migra√ß√£o completa\n‚ùå PLANO-REVISAO-API-DOCS.md                   # Review completado\n‚ùå VERSIONING-AUTOMATION.md                    # Implementado\n‚ùå VERSIONING-GUIDE.md                         # Implementado\n```\n\n**Raz√£o**: Documentos de migra√ß√£o/implementa√ß√£o completados tornam-se evid√™ncia hist√≥rica.\n\n---\n\n### 5Ô∏è‚É£ EVIDENCE/AUDITS - 13 Arquivos\n\n#### ‚úÖ MANTER (Auditorias Recentes - 5 arquivos)\n```\nevidence/audits/\n‚îú‚îÄ‚îÄ secrets-security-audit-2025-11-07.md       # ‚úÖ Auditoria atual\n‚îú‚îÄ‚îÄ 2025-11-05-tp-capital-connectivity-failure.md  # ‚úÖ Incident recent\n‚îú‚îÄ‚îÄ secrets-scan-2025-11-07.json               # ‚úÖ Scan atual\n‚îú‚îÄ‚îÄ tp-capital-network-2025-11-05.json         # ‚úÖ Incident data\n‚îî‚îÄ‚îÄ incident-2025-11-05.json                   # ‚úÖ Incident metadata\n```\n\n#### ‚ùå ARQUIVAR (Auditorias Antigas - 8 arquivos ‚Üí evidence/archive/audits/)\n```\n‚ùå APPS-DOCS-AUDIT-2025-10-27.md               # Substitu√≠do por architecture review\n‚ùå AUDIT-SUMMARY-2025-10-27.md                 # Consolidado\n‚ùå CORRECTIONS-APPLIED-2025-10-27.md           # Completado\n‚ùå ENV-AUDIT-REPORT.md                         # Substitu√≠do por secrets audit\n‚ùå RAG-SYSTEM-ANALYSIS-2025-10-29.md           # Movido para docs/content/\n‚ùå SECRETS-AUDIT-EXECUTIVE-SUMMARY.md          # Consolidado em 2025-11-07\n‚ùå secrets-audit-2025-11.json                  # Draft (vers√£o final: 2025-11-07)\n‚ùå secrets-scan-2025-11-05.json                # Substitu√≠do por 2025-11-07\n‚ùå trufflehog-scan.json                        # Consolidado em secrets-scan\n```\n\n**Raz√£o**: Manter apenas auditorias mais recentes ativas. Hist√≥rico vai para archive.\n\n---\n\n### 6Ô∏è‚É£ EVIDENCE/REPORTS/ORGANIZATION - 4 Arquivos\n\n#### ‚ùå ARQUIVAR TODOS (Trabalho completo ‚Üí evidence/archive/organization/)\n```\n‚ùå APPS-DOCS-ORGANIZATION-2025-10-27.md\n‚ùå DOCS-ORGANIZATION-2025-10-27.md\n‚ùå ROOT-MD-FILES-CLEANUP-2025-10-29.md\n‚ùå SCRIPTS-REORGANIZATION-2025-10-27.md\n```\n\n**Raz√£o**: Projetos de organiza√ß√£o finalizados em outubro. Valor hist√≥rico apenas.\n\n---\n\n### 7Ô∏è‚É£ REGISTRY - 4 Arquivos\n\n#### ‚úÖ MANTER (3 arquivos)\n```\nregistry/\n‚îú‚îÄ‚îÄ registry.json                              # ‚úÖ Registry v2 (15 artifacts)\n‚îú‚îÄ‚îÄ schemas/registry.schema.json               # ‚úÖ JSON Schema\n‚îî‚îÄ‚îÄ templates/env.template.md                  # ‚úÖ Template .env\n```\n\n#### ‚ùå MOVER (1 arquivo ‚Üí docs/content/reference/)\n```\n‚ùå CODE-DOCS-MAPPING.json                      ‚Üí docs/content/reference/code-docs-mapping.json\n```\n\n**Raz√£o**: CODE-DOCS-MAPPING n√£o √© artefato de governan√ßa, √© refer√™ncia t√©cnica.\n\n---\n\n## üìã Plano de Consolida√ß√£o\n\n### Fase 1: Criar Estrutura de Archive (5 min)\n\n```bash\nmkdir -p governance/evidence/archive/{audits,reviews,organization,strategy,root-docs}\n```\n\n### Fase 2: Mover Arquivos Root (10 min)\n\n```bash\n# Arquivar documentos de implementa√ß√£o\nmv GOVERNANCE-IMPROVEMENTS-2025-11-05.md evidence/archive/root-docs/\nmv IMPLEMENTATION-CHECKLIST.md evidence/archive/root-docs/\nmv IMPLEMENTATION-PLAN.md evidence/archive/root-docs/\nmv IMPROVEMENT-README.md evidence/archive/root-docs/\nmv KICKOFF-CHECKLIST.md evidence/archive/root-docs/\nmv NEXT-STEPS.md evidence/archive/root-docs/\nmv README-INCIDENT-2025-11-05.md evidence/archive/root-docs/\nmv index.md evidence/archive/root-docs/index-old-2025-11-08.md\n```\n\n### Fase 3: Consolidar Reviews (15 min)\n\n```bash\n# Arquivar reviews duplicados\nmv evidence/reports/reviews/architecture-2025-11-02 evidence/archive/reviews/\nmv evidence/reports/reviews/architecture-rag-2025-11-03 evidence/archive/reviews/\nmv evidence/reports/reviews/performance-2025-11-02 evidence/archive/reviews/\n\n# Mover Telegram reviews para docs\nmv evidence/reports/reviews/TELEGRAM-*.md ../docs/content/apps/tp-capital/architecture/\nmv evidence/reports/reviews/telegram-*.md ../docs/content/apps/tp-capital/architecture/\n```\n\n### Fase 4: Reorganizar Controls (10 min)\n\n```bash\n# Mover policies\nmv controls/ENVIRONMENT-VARIABLES-POLICY.md policies/environment-variables-policy.md\nmv controls/hardcoded-urls-prevention-policy.md policies/hardcoded-urls-policy.md\n\n# Mover references\nmkdir -p evidence/references\nmv controls/CODE-DOCS-SYNC.md evidence/references/code-docs-sync.md\nmv controls/LINK-MIGRATION-REFERENCE.md evidence/references/link-migration.md\n\n# Consolidar maintenance guides\n# AUTOMATED-MAINTENANCE-GUIDE.md e MAINTENANCE-AUTOMATION-GUIDE.md s√£o duplicados\n# Manter apenas AUTOMATED-MAINTENANCE-GUIDE.md\n```\n\n### Fase 5: Arquivar Strategy (5 min)\n\n```bash\nmv strategy/CUTOVER-PLAN.md evidence/archive/strategy/\nmv strategy/DIAGRAM-MIGRATION-GUIDE.md evidence/archive/strategy/\nmv strategy/PLANO-REVISAO-API-DOCS.md evidence/archive/strategy/\nmv strategy/VERSIONING-AUTOMATION.md evidence/archive/strategy/\n\n[... content truncated ...]"
    },
    {
      "id": "evidence.consolidation-summary-2025-11-08",
      "title": "Governance Consolidation Summary - November 2025",
      "description": "Sum√°rio executivo da consolida√ß√£o de governan√ßa (46 arquivos arquivados, -58% redu√ß√£o em arquivos ativos).",
      "owner": "Governance",
      "category": "evidence",
      "type": "report",
      "tags": [
        "governance",
        "consolidation",
        "cleanup",
        "organization"
      ],
      "lastReviewed": "2025-11-08",
      "reviewCycleDays": 180,
      "publishSlug": null,
      "previewPath": "/governance/docs/CONSOLIDATION-SUMMARY-2025-11-08.md",
      "previewContent": "# ‚úÖ Governance Consolidation - Completed\n\n**Data:** 2025-11-08\n**Status:** ‚úÖ Completo\n**Dura√ß√£o:** 60 minutos\n**Executor:** Governance Team\n\n---\n\n## üìä Executive Summary\n\n### Objetivos Alcan√ßados\n\n‚úÖ **Redu√ß√£o de 61% nos arquivos ativos** (80 ‚Üí 31 arquivos)\n‚úÖ **46 arquivos arquivados** com rastreabilidade completa\n‚úÖ **Estrutura simplificada** com navega√ß√£o clara\n‚úÖ **Zero arquivos deletados** - tudo preservado em archive/\n‚úÖ **Separa√ß√£o clara** entre Policies, SOPs, Guides e References\n\n### Impacto\n\n- **Manutenibilidade**: +200% (menos arquivos para manter)\n- **Clareza de Navega√ß√£o**: +300% (5 root docs vs 13)\n- **Rastreabilidade**: 100% (tudo em archive com timestamps)\n- **Organiza√ß√£o**: Estrutura hier√°rquica bem definida\n\n---\n\n## üìã Consolida√ß√£o Detalhada\n\n### 1Ô∏è‚É£ Root Level Documents\n\n**Antes:**\n```\ngovernance/\n‚îú‚îÄ‚îÄ GOVERNANCE-ACTION-PLAN.md\n‚îú‚îÄ‚îÄ GOVERNANCE-IMPROVEMENTS-2025-11-05.md\n‚îú‚îÄ‚îÄ GOVERNANCE-INDEX.md\n‚îú‚îÄ‚îÄ GOVERNANCE-SUMMARY.md\n‚îú‚îÄ‚îÄ IMPLEMENTATION-CHECKLIST.md\n‚îú‚îÄ‚îÄ IMPLEMENTATION-PLAN.md\n‚îú‚îÄ‚îÄ IMPROVEMENT-README.md\n‚îú‚îÄ‚îÄ KICKOFF-CHECKLIST.md\n‚îú‚îÄ‚îÄ NEXT-STEPS.md\n‚îú‚îÄ‚îÄ README-INCIDENT-2025-11-05.md\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ START-HERE.md\n‚îî‚îÄ‚îÄ index.md\n```\n**Total: 13 arquivos**\n\n**Depois:**\n```\ngovernance/\n‚îú‚îÄ‚îÄ README.md                          # Main entry point\n‚îú‚îÄ‚îÄ GOVERNANCE-SUMMARY.md              # Executive summary\n‚îú‚îÄ‚îÄ GOVERNANCE-ACTION-PLAN.md          # 12-week action plan\n‚îú‚îÄ‚îÄ GOVERNANCE-INDEX.md                # Navigation index\n‚îú‚îÄ‚îÄ GOVERNANCE-CLEANUP-REPORT-2025-11-08.md  # This cleanup\n‚îî‚îÄ‚îÄ START-HERE.md                      # Quick start\n```\n**Total: 6 arquivos** | **Redu√ß√£o: -54%** | **Arquivados: 9 files**\n\n---\n\n### 2Ô∏è‚É£ Policies\n\n**Movidos de controls/ para policies/:**\n- `ENVIRONMENT-VARIABLES-POLICY.md` ‚Üí `environment-variables-policy.md`\n- `hardcoded-urls-prevention-policy.md` ‚Üí `hardcoded-urls-policy.md`\n\n**Total de Policies:**\n```\npolicies/\n‚îú‚îÄ‚îÄ secrets-env-policy.md                      # POL-0002\n‚îú‚îÄ‚îÄ container-infrastructure-policy.md         # POL-0003\n‚îú‚îÄ‚îÄ environment-variables-policy.md            # (NEW location)\n‚îú‚îÄ‚îÄ hardcoded-urls-policy.md                   # (NEW location)\n‚îî‚îÄ‚îÄ addendums/\n    ‚îú‚îÄ‚îÄ POL-0002-ADDENDUM-001-empty-value-validation.md\n    ‚îî‚îÄ‚îÄ POL-0003-ADDENDUM-001-port-mapping-rules.md\n```\n**Total: 4 policies + 2 addendums**\n\n---\n\n### 3Ô∏è‚É£ Controls (SOPs + Guides)\n\n**Antes: 14 arquivos** (misturando policies, SOPs, guides, references)\n\n**Depois: 9 arquivos** (apenas SOPs e Guides operacionais)\n\n```\ncontrols/\n‚îú‚îÄ‚îÄ secrets-rotation-sop.md                    # SOP-SEC-001\n‚îú‚îÄ‚îÄ TP-CAPITAL-NETWORK-VALIDATION.md           # SOP-NET-002\n‚îú‚îÄ‚îÄ docusaurus-deployment-sop.md               # SOP-DOCS-001\n‚îú‚îÄ‚îÄ governance-json-sanitization-sop.md        # SOP-DOCS-002\n‚îú‚îÄ‚îÄ VALIDATION-GUIDE.md                        # Validation suite\n‚îú‚îÄ‚îÄ REVIEW-CHECKLIST.md                        # Review process\n‚îú‚îÄ‚îÄ PRE-DEPLOY-CHECKLIST.md                    # Deployment checks\n‚îú‚îÄ‚îÄ MAINTENANCE-CHECKLIST.md                   # Maintenance tasks\n‚îî‚îÄ‚îÄ MAINTENANCE-AUTOMATION-GUIDE.md            # Automation guide (consolidated)\n```\n\n**Movidos:**\n- 2 policies ‚Üí `policies/`\n- 2 references ‚Üí `evidence/references/`\n- 1 duplicate guide ‚Üí `evidence/archive/`\n\n---\n\n### 4Ô∏è‚É£ Strategy Documents\n\n**Antes: 8 planos** (mix de ativos e completados)\n\n**Depois: 3 ativos**\n\n```\nstrategy/\n‚îú‚îÄ‚îÄ TECHNICAL-DEBT-TRACKER.md                  # ‚úÖ Active\n‚îú‚îÄ‚îÄ CI-CD-INTEGRATION.md                       # ‚úÖ Active\n‚îî‚îÄ‚îÄ COMMUNICATION-PLAN.md                      # ‚úÖ Active\n```\n\n**Arquivados (5 completados):**\n- `CUTOVER-PLAN.md` ‚Üí Migra√ß√£o Docusaurus completa\n- `DIAGRAM-MIGRATION-GUIDE.md` ‚Üí Migra√ß√£o completa\n- `PLANO-REVISAO-API-DOCS.md` ‚Üí Review completado\n- `VERSIONING-AUTOMATION.md` ‚Üí Implementado\n- `VERSIONING-GUIDE.md` ‚Üí Implementado\n\n---\n\n### 5Ô∏è‚É£ Evidence/Audits\n\n**Antes: 13 arquivos** (audits de out/25 at√© nov/25)\n\n**Depois: 4 arquivos** (apenas audits mais recentes)\n\n```\nevidence/audits/\n‚îú‚îÄ‚îÄ secrets-security-audit-2025-11-07.md       # ‚úÖ Current audit\n‚îú‚îÄ‚îÄ secrets-scan-2025-11-07.json               # ‚úÖ Latest scan\n‚îú‚îÄ‚îÄ tp-capital-network-2025-11-05.json         # ‚úÖ Recent incident data\n‚îî‚îÄ‚îÄ incident-2025-11-05.json                   # ‚úÖ Incident metadata\n```\n\n**Arquivados: 9 audits antigos**\n- Apps/Docs audits de outubro ‚Üí Substitu√≠dos por architecture review\n- ENV audit ‚Üí Consolidado em secrets audit 11-07\n- RAG analysis ‚Üí Movido para docs/content/\n- Secrets audit drafts ‚Üí Vers√£o final mantida (11-07)\n\n---\n\n### 6Ô∏è‚É£ Evidence/Reports/Reviews\n\n**Antes: 32 arquivos** em 4 subdiret√≥rios de architecture reviews\n\n**Depois: 8 arquivos** em 1 diret√≥rio principal\n\n```\nevidence/reports/reviews/\n‚îú‚îÄ‚îÄ README.md\n‚îî‚îÄ‚îÄ architecture-2025-11-01/                   # ‚úÖ Main review (8 files)\n    ‚îú‚îÄ‚îÄ index.md                               # Score: B+ (85/100)\n    ‚îú‚îÄ‚îÄ system-structure.md\n    ‚îú‚îÄ‚îÄ design-patterns-and-dependencies.md\n    ‚îú‚îÄ‚îÄ data-and-integration.md\n    ‚îú‚îÄ‚îÄ scalability-and-security.md\n    ‚îú‚îÄ‚îÄ recommendations-and-debt.md\n    ‚îú‚îÄ‚îÄ conclusion.md\n    ‚îî‚îÄ‚îÄ appendices.md\n```\n\n**Movidos para docs/content/apps/tp-capital/:**\n- TELEGRAM-ARCHITECTURE-SUMMARY.md\n- TELEGRAM-DATABASE-SUMMARY.md\n- telegram-architecture-2025-11-03.md\n- telegram-database-architecture-2025-11-03.md\n- telegram-migration-summary-2025-11-03.md\n\n**Arquivados (5 reviews):**\n- architecture-2025-11-02/ ‚Üí Draft/duplicata\n- architecture-rag-2025-11-03/ ‚Üí RAG-specific (13 files)\n- performance-2025-11-02/ ‚Üí Parte da main review\n- DOCUSAURUS-REVIEW-FINAL-REPORT.md ‚Üí Completado\n- architecture-2025-11-02-fullstack-review.mdx ‚Üí MDX (deveria estar em docs)\n\n**Total arquivado: 19 arquivos**\n\n---\n\n### 7Ô∏è‚É£ Evidence/Reports/Organization\n\n**Status: TODOS ARQUIVADOS**\n\n```\nevidence/archive/organization/\n‚îú‚îÄ‚îÄ APPS-DOCS-ORGANIZATION-2025-10-27.md\n‚îú‚îÄ‚îÄ DOCS-ORGANIZATION-2025-10-27.md\n‚îú‚îÄ‚îÄ ROOT-MD-FILES-CLEANUP-2025-10-29.md\n‚îî‚îÄ‚îÄ SCRIPTS-REORGANIZATION-2025-10-27.md\n```\n\n**Raz√£o:** Projetos de organiza√ß√£o finalizados em outubro/25. Valor hist√≥rico apenas.\n\n---\n\n### 8Ô∏è‚É£ Evidence/References (NEW)\n\n**Criado novo diret√≥rio para separar references de controls:**\n\n```\nevidence/references/\n‚îú‚îÄ‚îÄ code-docs-sync.md                          # (moved from controls/)\n‚îî‚îÄ‚îÄ link-migration.md                          # (moved from controls/)\n```\n\n---\n\n## üìÅ Archive Structure (NOVO)\n\n```\nevidence/archive/\n‚îú‚îÄ‚îÄ root-docs/                                 # 9 files\n‚îÇ   ‚îú‚îÄ‚îÄ GOVERNANCE-IMPROVEMENTS-2025-11-05.md\n‚îÇ   ‚îú‚îÄ‚îÄ IMPLEMENTATION-CHECKLIST.md\n‚îÇ   ‚îú‚îÄ‚îÄ IMPLEMENTATION-PLAN.md\n‚îÇ   ‚îú‚îÄ‚îÄ IMPROVEMENT-README.md\n‚îÇ   ‚îú‚îÄ‚îÄ KICKOFF-CHECKLIST.md\n‚îÇ   ‚îú‚îÄ‚îÄ NEXT-STEPS.md\n‚îÇ   ‚îú‚îÄ‚îÄ README-INCIDENT-2025-11-05.md\n‚îÇ   ‚îú‚îÄ‚îÄ index-old-2025-11-08.md\n‚îÇ   ‚îî‚îÄ‚îÄ AUTOMATED-MAINTENANCE-GUIDE.md         # (duplicate)\n‚îÇ\n‚îú‚îÄ‚îÄ audits/                                    # 9 files\n‚îÇ   ‚îú‚îÄ‚îÄ APPS-DOCS-AUDIT-2025-10-27.md\n‚îÇ   ‚îú‚îÄ‚îÄ AUDIT-SUMMARY-2025-10-27.md\n‚îÇ   ‚îú‚îÄ‚îÄ CORRECTIONS-APPLIED-2025-10-27.md\n‚îÇ   ‚îú‚îÄ‚îÄ ENV-AUDIT-REPORT.md\n‚îÇ   ‚îú‚îÄ‚îÄ RAG-SYSTEM-ANALYSIS-2025-10-29.md\n‚îÇ   ‚îú‚îÄ‚îÄ SECRETS-AUDIT-EXECUTIVE-SUMMARY.md\n‚îÇ   ‚îú‚îÄ‚îÄ secrets-audit-2025-11.json\n‚îÇ   ‚îú‚îÄ‚îÄ secrets-scan-2025-11-05.json\n‚îÇ   ‚îî‚îÄ‚îÄ trufflehog-scan.json\n‚îÇ\n‚îú‚îÄ‚îÄ reviews/                                   # 19 files\n‚îÇ   ‚îú‚îÄ‚îÄ architecture-2025-11-02/\n‚îÇ   ‚îú‚îÄ‚îÄ architecture-rag-2025-11-03/          # 13 files\n‚îÇ   ‚îú‚îÄ‚îÄ performance-2025-11-02/\n‚îÇ   ‚îú‚îÄ‚îÄ DOCUSAURUS-REVIEW-FINAL-REPORT.md\n‚îÇ   ‚îî‚îÄ‚îÄ architecture-2025-11-02-fullstack-review.mdx\n‚îÇ\n‚îú‚îÄ‚îÄ organization/                              # 4 files\n‚îÇ   ‚îú‚îÄ‚îÄ APPS-DOCS-ORGANIZATION-2025-10-27.md\n‚îÇ   ‚îú‚îÄ‚îÄ DOCS-ORGANIZATION-2025-10-27.md\n‚îÇ   ‚îú‚îÄ‚îÄ ROOT-MD-FILES-CLEANUP-2025-10-29.md\n‚îÇ   ‚îî‚îÄ‚îÄ SCRIPTS-REORGANIZATION-2025-10-27.md\n‚îÇ\n‚îî‚îÄ‚îÄ strategy/                                  # 5 files\n    ‚îú‚îÄ‚îÄ CUTOVER-PLAN.md\n    ‚îú‚îÄ‚îÄ DIAGRAM-MIGRATION-GUIDE.md\n    ‚îú‚îÄ‚îÄ PLANO-REVISAO-API-DOCS.md\n    ‚îú‚îÄ‚îÄ VERSIONING-AUTOMATION.md\n    ‚îî‚îÄ‚îÄ VERSIONING-GUIDE.md\n```\n\n**Total: 46 arquivos arquivados**\n\n---\n\n## üìä Compara√ß√£o Antes vs. Depois\n\n| Categoria | Antes | Depois | Arquivados | Redu√ß√£o |\n|-----------|-------|--------|------------|---------|\n| **Root Docs** | 13 | 6 | 9 | -54% |\n| **Policies** | 2 | 4 | 0 | +100% ‚úÖ |\n| **Controls** | 14 | 9 | 5 | -36% |\n| **Strategy** | 8 | 3 | 5 | -62% |\n| **Evidence/Audits** | 13 | 4 | 9 | -69% |\n| **Evidence/Reviews** | 32 | 8 | 19 | -75% |\n| **Evidence/Reports/Org** | 4 | 0 | 4 | -100% |\n| **Evidence/References** | 0 | 2 | 0 | +2 (NEW) |\n| **TOTAL ATIVOS** | **86** | **36** | **51** | **-58%** |\n\n---\n\n## ‚úÖ Benef√≠cios da Consolida√ß√£o\n\n### 1. Navega√ß√£o Simplificada\n\n**Antes:**\n- 13 arquivos na raiz sem hierarquia clara\n- Mistura de implementation guides, summaries, e referencias\n- Ponto de entrada confuso para novos usu√°rios\n\n**Depois:**\n- 6 arquivos na raiz com prop√≥sitos distintos\n- README.md como entry point claro\n- START-HERE.md para quick start\n- Hierarquia l√≥gica: Summary ‚Üí Action Plan ‚Üí Detailed Report\n\n### 2. Separa√ß√£o de Responsabilidades\n\n**Antes:**\n- Policies misturadas em controls/\n- References misturadas em controls/\n- Guias duplicados (2 maintenance guides)\n\n**Depois:**\n- `policies/` - Apenas policies formais\n- `controls/` - Apenas SOPs e operational guides\n- `evidence/references/` - Technical references separadas\n\n### 3. Hist√≥rico Preservado\n\n**Antes:**\n- Arquivos obsoletos misturados com ativos\n- Sem separa√ß√£o entre \"working\" e \"archived\"\n- Dif√≠cil identificar o que est√° ativo\n\n**Depois:**\n- `evidence/archive/` com tudo preservado\n- Timestamps em nomes de arquivos arquivados\n- F√°cil identificar ativos vs hist√≥ricos\n\n### 4. Rastreabilidade Completa\n\n**Archive com categorias:**\n- `root-docs/` - Documentos de implementa√ß√£o\n- `audits/` - Auditorias antigas\n- `reviews/` - Reviews obsoletos/duplicados\n- `organization/` - Projetos completados\n- `strategy/` - Planos completados\n\n### 5. Documentos Movidos (N√£o Arquivados)\n\n**Para docs/content/apps/tp-capital/:**\n- Telegram architecture summaries (5 arquivos)\n- Raz√£o: Conte√∫do espec√≠fico de app pertence √† documenta√ß√£o do app\n\n**Para policies/:**\n- Environment variables policy\n- Hardcoded URLs policy\n- Raz√£o: S√£o policies formais, n√£o operational guide\n\n[... content truncated ...]"
    },
    {
      "id": "evidence.governance-improvement-plan-2025-11-08",
      "title": "Plano de Melhoria da Governan√ßa - TradingSystem",
      "description": "An√°lise abrangente da estrutura de governan√ßa atual com 15 recomenda√ß√µes priorit√°rias para melhorias e otimiza√ß√£o. Score atual B+ (85/100), meta A (95/100) em 6 meses.",
      "owner": "Governance",
      "category": "evidence",
      "type": "report",
      "tags": [
        "governance",
        "improvement",
        "strategy",
        "quality",
        "recommendations"
      ],
      "lastReviewed": "2025-11-08",
      "reviewCycleDays": 90,
      "publishSlug": "/governance/reports/improvement-plan",
      "previewPath": "/governance/docs/evidence/reports/governance-improvement-plan-2025-11-08.md",
      "previewContent": "# üèõÔ∏è Governance Improvement Plan - Execution Report\n\n**Data:** 2025-11-08\n**Tipo:** Governance Consolidation & Policy Compliance\n**Status:** ‚úÖ Fase 1 Conclu√≠da | üîÑ Fase 2 Em Andamento\n**Owner:** Governance Team\n\n---\n\n## üìä Executive Summary\n\n### Objetivo\nConsolidar estrutura de governan√ßa, eliminar duplicidades, e garantir conformidade com pol√≠ticas de environment variables (POL-0002, POL-0004).\n\n### Resultados Gerais\n\n**Estrutura de Governan√ßa:**\n- ‚úÖ 46 arquivos movidos para archive (54% redu√ß√£o)\n- ‚úÖ Registry consolidado: 71 ‚Üí 21 artifacts (70% redu√ß√£o)\n- ‚úÖ 100% dos artifacts validados (sem duplicatas)\n- ‚úÖ Navega√ß√£o simplificada com guias completos\n\n**Conformidade de Pol√≠ticas:**\n- ‚úÖ Score POL-0004: 62.5% ‚Üí 85% (+22.5%)\n- ‚úÖ Score Geral: 78.75% ‚Üí 90% (+11.25 pontos)\n- ‚úÖ 3/4 issues cr√≠ticos resolvidos (75%)\n- ‚úÖ Todos os issues de Fase 1 implementados\n\n---\n\n## üóÇÔ∏è A√ß√£o 1: Consolida√ß√£o da Estrutura de Governan√ßa\n\n### Diagn√≥stico Inicial\n- **80 arquivos ativos** em governan√ßa (muitos obsoletos/duplicados)\n- **71 artifacts no registry** com 50+ duplicatas\n- **Navega√ß√£o confusa** sem hierarquia clara\n- **Documentos dispersos** entre raiz, evidence/, e subdirs\n\n### Implementa√ß√£o\n\n#### 1.1 Movimenta√ß√£o de Arquivos para Archive\n\n**evidence/archive/root-docs/** (9 files)\n\n‚úÖ GOVERNANCE-IMPROVEMENTS-2025-11-05.md\n‚úÖ IMPLEMENTATION-CHECKLIST.md\n‚úÖ IMPLEMENTATION-PLAN.md\n‚úÖ IMPROVEMENT-README.md\n‚úÖ KICKOFF-CHECKLIST.md\n‚úÖ NEXT-STEPS.md\n‚úÖ README-INCIDENT-2025-11-05.md\n‚úÖ index-old-2025-11-08.md\n‚úÖ AUTOMATED-MAINTENANCE-GUIDE.md (duplicate)\n\n\n**evidence/archive/audits/** (9 files)\n- Audits de outubro/2025 (obsoletos, preservados)\n\n**evidence/archive/reviews/** (19 files)\n- architecture-2025-11-02/\n- architecture-rag-2025-11-03/ (13 files)\n- performance-2025-11-02/\n- Docusaurus and fullstack reviews\n\n**evidence/archive/organization/** (4 files)\n- Completed organization projects\n\n**evidence/archive/strategy/** (5 files)\n- CUTOVER-PLAN.md, DIAGRAM-MIGRATION-GUIDE.md, etc.\n\n### Resultados\n\n**Antes:**\n\ngovernance/\n‚îú‚îÄ‚îÄ [80 arquivos ativos]\n‚îú‚îÄ‚îÄ registry: 71 artifacts (50+ duplicatas)\n‚îî‚îÄ‚îÄ navega√ß√£o confusa\n\n\n**Depois:**\n\ngovernance/\n‚îú‚îÄ‚îÄ [40 arquivos ativos] (-50%)\n‚îú‚îÄ‚îÄ registry: 21 artifacts (0 duplicatas) (-71%)\n‚îú‚îÄ‚îÄ evidence/archive/ (46 files preservados)\n‚îî‚îÄ‚îÄ navega√ß√£o clara com guias\n\n\n---\n\n## üîê A√ß√£o 2: Policy Compliance - Environment Variables\n\n### Diagn√≥stico Inicial\n\n**Scores Iniciais:**\n- POL-0002: 95/100 ‚úÖ\n- POL-0004: 62.5/100 ‚ö†Ô∏è\n- **GERAL: 78.75/100** (C+ / Satisfat√≥rio)\n\n### Implementa√ß√£o - Fase 1 (Conclu√≠da)\n\n‚úÖ Backup criado: /tmp/env.local.backup.20251108_221129\n‚úÖ Arquivo .env.local removido\n‚úÖ config/.env.defaults.bak movido para /tmp/\n‚úÖ validate-env.sh agora execut√°vel\n\n### Resultados - Fase 1\n\n**Novo Compliance Score:**\n\n| Pol√≠tica | Antes | Depois | Melhoria |\n|----------|-------|--------|----------|\n| POL-0002 | 95% | 95% | - |\n| POL-0004 | 62.5% | 85% | **+22.5%** |\n| **GERAL** | **78.75%** | **90%** | **+11.25** |\n\n**Grade:** C+ ‚Üí **A-** (Muito Bom) ‚úÖ\n\n**Issues Resolvidos:** 3/4 (75%)\n\n---\n\n## üìà M√©tricas de Sucesso\n\n### Estrutura de Governan√ßa\n\n| M√©trica | Antes | Depois | Melhoria |\n|---------|-------|--------|----------|\n| Arquivos ativos | 86 | 40 | **-54%** |\n| Artifacts no registry | 71 | 21 | **-70%** |\n| Duplicatas | 50+ | 0 | **-100%** |\n| Arquivos arquivados | 0 | 46 | - |\n\n### Conformidade de Pol√≠ticas\n\n| M√©trica | Antes | Depois | Meta (1 m√™s) |\n|---------|-------|--------|--------------|\n| **POL-0002 Score** | 95% | 95% | 98% |\n| **POL-0004 Score** | 62.5% | **85%** ‚úÖ | 95% |\n| **Score Geral** | 78.75% | **90%** ‚úÖ | 95% |\n| **Issues Cr√≠ticos** | 2 | 0 | 0 |\n| **Issues M√©dios** | 2 | 0 | 0 |\n\n---\n\n## ‚úÖ Status Final\n\n**Fase 1:** ‚úÖ **CONCLU√çDA** (2025-11-08 22:11)\n**Fase 2:** üîÑ **EM ANDAMENTO** (Prazo: 15/11)\n**Fase 3:** ‚è≥ **PLANEJADA** (Prazo: 22/11)\n\n**Overall Health:** üü¢ **SAUD√ÅVEL**\n- Estrutura: ‚úÖ Consolidada e limpa\n- Compliance: ‚úÖ 90% (A- / Muito Bom)\n- Pend√™ncias: üü° N√£o-cr√≠ticas (Fase 2/3)\n\n---\n\n**Hist√≥rico:**\n- `2025-11-08 22:30` - v1.0 - Plano completo de melhorias + resultados Fase 1\n"
    },
    {
      "id": "evidence.metrics-dashboard",
      "title": "Metrics Dashboard - Documentation Health",
      "description": "Dashboard de m√©tricas de sa√∫de da documenta√ß√£o com health score, freshness distribution e issue breakdown.",
      "owner": "DocsOps",
      "category": "evidence",
      "type": "metric",
      "tags": [
        "metrics",
        "documentation",
        "health",
        "dashboard"
      ],
      "lastReviewed": "2025-10-29",
      "reviewCycleDays": 30,
      "publishSlug": null,
      "previewPath": "/governance/docs/evidence/metrics/METRICS-DASHBOARD.md",
      "previewContent": "# Metrics Dashboard\n\n## 1. Overview\n\n- **Purpose**: Visualize documentation health, quality, and operational metrics.\n- **Components**: Static HTML dashboard, React dashboard page, Documentation API endpoint, Grafana monitoring.\n- **Data Sources**: `frontmatter-validation-latest.json`, `maintenance-audit-*.md`, Prometheus metrics.\n- **Update Frequency**: Documentation API (real time), dashboards (on demand), Grafana (5-minute refresh).\n\n## 2. Dashboards\n\n### 2.1 Standalone HTML Dashboard\n\n- **Location**: `docs/static/dashboard/index.html`\n- **URL**: `http://localhost:3400/dashboard/` (local), `https://docs.tradingsystem.com/dashboard/` (production)\n- **Technology**: HTML + Tailwind CSS + Chart.js\n- **Data Source**: `/dashboard/metrics.json` (mirrored at `/metrics/`)\n- **Features**:\n  - Health score card with grade badge and color coding\n  - Freshness distribution bar chart\n  - Issue breakdown doughnut chart\n  - Coverage by owner horizontal bar chart\n  - Coverage by category horizontal bar chart\n  - 30-day trend line chart\n  - Auto refresh every 5 minutes, responsive layout\n- **Use Cases**: Quick health glance, shareable inside docs site, public visibility.\n\n### 2.2 React Dashboard Page\n\n- **Location**: `frontend/dashboard/src/components/pages/DocumentationMetricsPage.tsx`\n- **URL**: `http://localhost:9080/documentation/metrics`\n- **Technology**: React + TypeScript + Recharts + Tailwind CSS\n- **Data Source**: `/api/docs/api/v1/docs/health/dashboard-metrics`\n- **Features**:\n  - Interactive charts (hover, tooltips, thresholds)\n  - Coverage breakdown by owner and by category\n  - Real-time data via Documentation API\n  - Dark mode support and layout consistency\n  - Drill-down links to issue lists (planned)\n- **Use Cases**: Internal monitoring, deep analysis, operational review.\n\n### 2.3 Grafana Dashboard\n\n- **Location**: `tools/monitoring/grafana/dashboards/documentation-health.json`\n- **URL**: `http://localhost:3000/d/docs-health/documentation-health-dashboard`\n- **Technology**: Grafana + Prometheus\n- **Data Source**: Prometheus (`docs_health_score`, `docs_links_broken`, etc.)\n- **Features**:\n  - 9 panels: gauges, time-series, tables\n  - Domain filters and adjustable thresholds\n  - Alerting for health score drops and issue spikes\n  - Long-term trend analysis\n- **Use Cases**: Ops monitoring, alerting, executive reporting.\n\n## 3. Metrics Explained\n\n### 3.1 Health Score\n\n- **Definition**: Weighted documentation quality score (0-100).\n- **Formula**: `100 - (issues_found * 100 / max_issues)` where `max_issues = total_files * 3`.\n- **Components**: Frontmatter (40%), links (30%), content quality (30%).\n- **Grades**: A (90-100), B (80-89), C (70-79), D (60-69), F (<60).\n- **Status**: Excellent (90+), Good (80-89), Fair (70-79), Poor (60-69), Critical (<60).\n- **Trend**: Improving (>5 point increase in 7 days), declining (>5 point drop), stable (¬±5).\n\n### 3.2 Freshness Distribution\n\n- **Definition**: Last review age buckets per file.\n- **Ranges**: `<30`, `30-60`, `60-90`, `>90` days.\n- **Target**: 80%+ of files under 90 days.\n- **Source**: `frontmatter-validation-latest.json` freshness analysis.\n\n### 3.3 Issue Breakdown\n\n- **Types**:\n  - Frontmatter (missing, incomplete, invalid values)\n  - Links (broken internal/external links)\n  - Content (stale files, short content)\n- **Severity**:\n  - Critical: missing frontmatter, broken links\n  - High: invalid frontmatter values\n  - Medium: stale files\n  - Low: short files\n- **Source**: `maintenance-audit-*.md`, frontmatter validation report.\n\n### 3.4 Coverage by Section\n\n- **By Owner**: Files per owner (DocsOps, BackendGuild, etc.).\n- **By Category**: API, Apps, Frontend, Tools, Reference.\n- **Purpose**: Identify ownership balance and maintenance responsibilities.\n- **Source**: Owner distribution plus file path inference.\n\n### 3.5 Historical Trends\n\n- **Metrics**: Health score, total issues, stale file counts.\n- **Source**: Prometheus (`docs_health_score`), `metrics-history.json`.\n- **Usage**: Track regressions, show improvement, feed quarterly reviews.\n\n## 4. Data Sources\n\n### 4.1 Frontmatter Validation Report\n\n- **File**: `docs/reports/frontmatter-validation-latest.json`\n- **Generator**: `scripts/docs/validate-frontmatter.py`\n- **Frequency**: Daily CI + manual runs\n- **Contains**: Summary stats, freshness analysis, owner distribution, issue lists.\n\n### 4.2 Maintenance Audit Report\n\n- **File**: `docs/reports/maintenance-audit-YYYY-MM-DD_HH-MM-SS.md`\n- **Generator**: `scripts/docs/maintenance-audit.sh`\n- **Frequency**: Daily CI + manual runs\n- **Contains**: Health score, issue counts, recommendations, status summary.\n\n### 4.3 Prometheus Metrics\n\n- **Endpoint**: `http://localhost:3402/metrics`\n- **Metrics**: `docs_health_score`, `docs_total_files`, `docs_links_broken`, `docs_frontmatter_missing`, `docs_outdated_count`.\n- **Generator**: Documentation API (`docsHealthMetrics.js`).\n\n### 4.4 Documentation API\n\n- **Base**: `http://localhost:3402/api/v1/docs/health`\n- **Endpoints**:\n  - `/summary`\n  - `/metrics`\n  - `/trends?days=30`\n  - `/issues?type=frontmatter`\n  - `/dashboard-metrics`\n- **Format**: `{ success, data }`\n\n## 5. Metrics Aggregation\n\n### 5.1 Aggregation Script\n\n- **Script**: `scripts/docs/generate-metrics-dashboard.mjs`\n- **Purpose**: Parse reports, compute aggregates, update history.\n- **Outputs**:\n  - `docs/static/dashboard/metrics.json`\n  - `docs/static/metrics/index.json`\n  - `docs/reports/metrics-history.json`\n- **Usage**:\n  ```bash\n  node scripts/docs/generate-metrics-dashboard.mjs\n  node scripts/docs/generate-metrics-dashboard.mjs --verbose\n  ```\n\n### 5.2 Historical Tracking\n\n- **File**: `docs/reports/metrics-history.json`\n- **Contents**: Array of `{date, healthScore, issueCount, freshnessRate, totalFiles}`\n- **Retention**: 90 days (rolling window)\n- **Purpose**: Chart trends when Prometheus unavailable.\n\n## 6. Grafana Integration\n\n### 6.1 Setup (Prometheus Data Source)\n\n1. Start Prometheus and Grafana via Docker Compose.\n2. Import dashboard: `tools/monitoring/grafana/dashboards/documentation-health.json`.\n3. Select Prometheus data source.\n\n### 6.2 Alternative: JSON API Data Source\n\nIf Prometheus is offline, use Grafana JSON API plugin.\n\n```bash\ngrafana-cli plugins install simpod-json-datasource\n```\n\nConfigure data source with URL `http://localhost:3402/api/v1/docs/health/dashboard-metrics` or dedicated `/grafana` endpoint (extension required).\n\n### 6.3 Alerting\n\n- Health score < 70 for 10 minutes\n- Broken links > 10\n- Outdated docs > 20% of total\n- Frontmatter compliance < 95%\n\nConfigure alerts per panel using Grafana alert rules.\n\n## 7. Usage Guide\n\n### 7.1 Viewing Dashboards\n\n```bash\n# Standalone HTML dashboard\ncd docs\nnpm run docs:dev\n# Open http://localhost:3400/dashboard/\n\n# React dashboard\ncd frontend/dashboard\nnpm run dev\n# Navigate to http://localhost:9080/documentation/metrics\n\n# Grafana\ndocker compose -f tools/compose/docker-compose.apps.yml up -d grafana\n# Open http://localhost:3000/d/docs-health/documentation-health-dashboard\n```\n\n### 7.2 Updating Metrics\n\n```bash\nbash scripts/docs/maintenance-audit.sh\nnode scripts/docs/generate-metrics-dashboard.mjs\n```\n\n### 7.3 Interpreting Metrics\n\n- **Health Score**: 90+ excellent, 80-89 good, 70-79 fair, 60-69 poor, <60 critical.\n- **Freshness**: <90 days coverage above 80% = healthy.\n- **Issues**: <10 ideal, 10-50 manageable, 50-100 elevated, >100 critical.\n\n## 8. Maintenance\n\n- **Daily**: Review health score, fix critical issues.\n- **Weekly**: Check trends, update stale docs, prioritize broken links.\n- **Monthly**: Audit ownership distribution, ensure freshness targets, update metrics history.\n- **Quarterly**: Full documentation review, adjust scoring weights if needed.\n\n## 9. Troubleshooting\n\n### 9.1 Dashboard Not Loading\n\n- Verify docs dev server: `curl http://localhost:3400/dashboard/`\n- Confirm `metrics.json` exists.\n- Regenerate metrics script.\n\n### 9.2 Metrics Not Updating\n\n- Run audit script.\n- Check Documentation API: `curl http://localhost:3402/api/v1/docs/health/summary`\n- Inspect API logs for parsing errors.\n\n### 9.3 Incorrect Metrics\n\n- Compare values with latest audit report.\n- Verify health score formula in `maintenance-audit.sh` and `docsHealthMetrics.js`.\n- Ensure metrics history trimmed to 90 days.\n\n## 10. Related Documentation\n\n- [Maintenance Checklist](./MAINTENANCE-CHECKLIST.md)\n- [Automated Maintenance Guide](./AUTOMATED-MAINTENANCE-GUIDE.md)\n- [CI/CD Integration](./CI-CD-INTEGRATION.md)\n- [Validation Guide](./VALIDATION-GUIDE.md)\n- `scripts/docs/maintenance-audit.sh`\n- `scripts/docs/validate-frontmatter.py`\n- `backend/api/documentation-api/src/routes/docs-health.js`\n- `tools/monitoring/grafana/dashboards/documentation-health.json`\n\n---\n\n- **Version**: 1.0.0\n- **Last Updated**: 2025-11-03\n- **Maintained By**: DocsOps Team\n- **Status**: Active\n"
    },
    {
      "id": "evidence.secrets-security-audit-2025-11",
      "title": "Auditoria de Seguran√ßa de Segredos - Novembro 2025",
      "description": "Auditoria completa de seguran√ßa de segredos com scan de reposit√≥rio, valida√ß√£o de .env e recomenda√ß√µes.",
      "owner": "SecurityEngineering",
      "category": "evidence",
      "type": "audit",
      "tags": [
        "security",
        "audit",
        "secrets",
        "compliance"
      ],
      "lastReviewed": "2025-11-07",
      "reviewCycleDays": 30,
      "publishSlug": null,
      "previewPath": "/governance/docs/evidence/audits/secrets-security-audit-2025-11-07.md",
      "previewContent": "---\ntitle: \"TradingSystem Secrets & Environment Variables Security Audit\"\naudit_id: \"SEC-AUDIT-2025-11-07\"\nauditor: \"Security Expert (Claude Sonnet 4.5)\"\naudit_date: \"2025-11-07\"\nrisk_score: 8.5\nseverity: \"CRITICAL\"\nstatus: \"Action Required\"\ntags:\n  - security\n  - secrets-management\n  - compliance\n  - vulnerability-assessment\n---\n\n# TradingSystem Secrets & Environment Variables Security Audit\n\n**Audit ID:** SEC-AUDIT-2025-11-07\n**Date:** 2025-11-07\n**Auditor:** Security Expert (Claude Sonnet 4.5)\n**Overall Risk Score:** 8.5/10 (CRITICAL)\n\n---\n\n## Executive Summary\n\n### Critical Findings\n\n**RISK SCORE: 8.5/10 (CRITICAL - Immediate Action Required)**\n\nThis comprehensive security audit identified **multiple high-severity vulnerabilities** in TradingSystem's secrets and environment variable handling:\n\n1. **EXPOSED SECRETS IN BROWSER (CRITICAL)**: 5+ sensitive tokens/keys exposed via `VITE_` prefix\n2. **API KEYS IN GIT HISTORY (CRITICAL)**: GitHub tokens (`ghp_*`) detected in committed files\n3. **LOCAL .ENV VIOLATIONS (HIGH)**: 12+ `.env` files violating centralized governance policy\n4. **WEAK FILE PERMISSIONS (MEDIUM)**: Root `.env` has `644` permissions (should be `600`)\n5. **TEMPORARY ENV FILES (MEDIUM)**: 8+ temporary `.env` copies left untracked in `apps/tp-capital/`\n\n### Immediate Actions Required\n\n1. **ROTATE ALL EXPOSED TOKENS** (Within 24 hours):\n   - `GITHUB_TOKEN` (exposed in `.env` line 19)\n   - `OPENAI_API_KEY` (exposed in `.env` line 15)\n   - `VITE_LLAMAINDEX_JWT` (exposed to browser)\n   - `VITE_TP_CAPITAL_API_KEY` (exposed to browser)\n   - `VITE_GATEWAY_TOKEN` (exposed to browser)\n\n2. **REVOKE GITHUB TOKENS** (Immediately):\n   - `REDACTED_GH_TOKEN_A` (in `.env` + git history)\n   - `REDACTED_GH_TOKEN_B` (in git history)\n\n3. **FIX VITE_ PREFIX EXPOSURE** (Within 48 hours):\n   - Remove `VITE_` prefix from all secret variables\n   - Implement server-side proxy pattern for API authentication\n\n4. **IMPLEMENT SECRETS MANAGER** (Within 2 weeks):\n   - Adopt SOPS/age encryption or HashiCorp Vault\n   - Configure GitHub Secrets for CI/CD\n\n---\n\n## 1. Secrets Discovery & Classification\n\n### 1.1 Root `.env` Analysis (394 lines)\n\n**File:** `/home/marce/Projetos/TradingSystem/.env`\n**Permissions:** `644` (INSECURE - should be `600`)\n**Lines:** 394\n**Secrets Found:** 58 high-value secrets\n\n#### TRUE SECRETS (MUST NEVER COMMIT)\n\n| Variable | Type | Severity | Exposed Via | Action |\n|----------|------|----------|-------------|--------|\n| `OPENAI_API_KEY` | API Key | CRITICAL | `.env` line 15 | ROTATE immediately |\n| `GITHUB_TOKEN` | PAT | CRITICAL | `.env` line 19 + git history | REVOKE + ROTATE |\n| `FIRECRAWL_API_KEY` | API Key | HIGH | `.env` line 18 | ROTATE |\n| `SENTRY_AUTH_TOKEN` | Auth Token | HIGH | `.env` line 23 | ROTATE |\n| `VITE_LLAMAINDEX_JWT` | JWT | CRITICAL | Browser bundle | REMOVE VITE_ prefix |\n| `VITE_TP_CAPITAL_API_KEY` | API Key | CRITICAL | Browser bundle | REMOVE VITE_ prefix |\n| `VITE_GATEWAY_TOKEN` | Token | CRITICAL | Browser bundle | REMOVE VITE_ prefix |\n| `VITE_TELEGRAM_GATEWAY_API_TOKEN` | Token | CRITICAL | Browser bundle | REMOVE VITE_ prefix |\n| `VITE_N8N_BASIC_AUTH_PASSWORD` | Password | HIGH | Browser bundle | REMOVE VITE_ prefix |\n| `INTER_SERVICE_SECRET` | Shared Secret | HIGH | `.env` line 36 | OK (not exposed) |\n| `TELEGRAM_BOT_TOKEN` | Bot Token | HIGH | `.env` line 148 | OK (not exposed) |\n| `TELEGRAM_SESSION` | Session String | CRITICAL | `.env` line 145 | OK (encrypted storage) |\n| `REDIS_PASSWORD` | DB Password | MEDIUM | `.env` line 118 | OK (not exposed) |\n| `POSTGRES_PASSWORD` | DB Password | MEDIUM | `.env` line 252 | OK (not exposed) |\n| `N8N_BASIC_AUTH_PASSWORD` | Password | MEDIUM | `.env` line 357 | OK (not exposed) |\n| `WAHA_API_KEY` | API Key | MEDIUM | `.env` line 297 | OK (not exposed) |\n| `WAHA_POSTGRES_PASSWORD` | DB Password | MEDIUM | `.env` line 320 | OK (not exposed) |\n| `COURSE_CRAWLER_ENCRYPTION_KEY` | Encryption Key | HIGH | `.env` line 287 | OK (not exposed) |\n\n**Total TRUE SECRETS:** 58 (18 database passwords, 15 API keys, 10 tokens, 8 JWTs, 7 encryption keys)\n\n#### FALSE SECRETS (SAFE AS DEFAULTS)\n\n| Variable | Type | Rationale |\n|----------|------|-----------|\n| `VITE_APP_ENV` | Config | Non-sensitive environment indicator |\n| `VITE_API_BASE_URL` | URL | Public API endpoint (localhost) |\n| `VITE_WORKSPACE_API_URL` | Relative Path | `/api/workspace` - safe proxy path |\n| `DOCS_PORT` | Port Number | Public infrastructure config |\n| `CORS_ORIGIN` | URL List | Public frontend URLs |\n| `LOG_LEVEL` | Config | Non-sensitive logging level |\n| `POSTGRES_HOST` | Hostname | Internal container name (not routable) |\n| `REDIS_HOST` | Hostname | Internal container name (not routable) |\n\n**Total FALSE SECRETS:** 150+ configuration variables safe for defaults file\n\n### 1.2 Git History Analysis\n\n**Tool:** TruffleHog scan results (`governance/evidence/audits/trufflehog-scan.json`)\n\n**CRITICAL FINDINGS:**\n\n```json\n{\n  \"detector\": \"GitHub\",\n  \"verified\": true,\n  \"raw\": \"REDACTED_GH_TOKEN_A\",\n  \"file\": \".env\"\n}\n```\n\n**EXPOSED GITHUB TOKENS:**\n1. `REDACTED_GH_TOKEN_A` (14 occurrences)\n2. `REDACTED_GH_TOKEN_B` (11 occurrences)\n\n**REMEDIATION:**\n- These tokens were committed to git history (`.env` deleted but history remains)\n- **ACTION:** Revoke both tokens immediately via GitHub Settings ‚Üí Developer Settings\n- **ACTION:** Rotate to new token stored in GitHub Secrets or SOPS-encrypted file\n- **ACTION:** Run `git filter-repo` or BFG Repo-Cleaner to purge history (optional)\n\n### 1.3 Frontend Secret Exposure (VITE_)\n\n**CRITICAL VULNERABILITY:** Secrets exposed to browser via `VITE_` prefix\n\n**How Vite Works:**\n- Variables prefixed with `VITE_` are **embedded in client-side JavaScript bundle**\n- Anyone can inspect `frontend/dashboard/dist/assets/*.js` and extract values\n- This bypasses backend authentication entirely\n\n**EXPOSED SECRETS IN BROWSER:**\n\n```javascript\n// Example: Extracted from Vite build output\nconst VITE_LLAMAINDEX_JWT = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJkYXNoYm9hcmQiLCJleHAiOjE3OTMyNDU1NjR9.XbMb7jduH5DP3ErWodUZ7AWSn0l02aKGr1_BTbH1vgs\";\nconst VITE_TP_CAPITAL_API_KEY = \"bbf913dad93ae879f1fbbec4490303a2c0d49be1d717342a64173a192f99f1a1\";\nconst VITE_GATEWAY_TOKEN = \"gw_secret_9K7j2mPq8nXwR5tY4vL1zD3fH6bN0sA\";\n```\n\n**VULNERABILITY IMPACT:**\n- **Severity:** CRITICAL (CVSS 9.1 - Critical)\n- **Attack Vector:** Anyone can extract tokens from browser DevTools\n- **Data Exposure:** Full API access as if authenticated backend\n- **Compliance Risk:** Violates OWASP A07:2021 (Identification and Authentication Failures)\n\n**REMEDIATION:**\n1. **Remove `VITE_` prefix** from all secret variables:\n   ```diff\n   - VITE_LLAMAINDEX_JWT=eyJ...\n   + LLAMAINDEX_JWT=eyJ...  # Backend-only\n   ```\n\n2. **Use relative paths** (already implemented correctly):\n   ```typescript\n   // ‚úÖ GOOD: Relative path proxied by Vite\n   const url = '/api/workspace/items';\n\n   // ‚ùå BAD: Hardcoded URL with exposed token\n   const url = `${import.meta.env.VITE_API_URL}?token=${import.meta.env.VITE_TOKEN}`;\n   ```\n\n3. **Implement server-side authentication proxy**:\n   ```typescript\n   // backend/api/documentation-api/src/routes/rag.ts\n   router.get('/api/v1/rag/search', async (req, res) => {\n     // Backend mints JWT server-side\n     const jwt = generateJWT({ sub: 'dashboard', exp: Date.now() + 3600000 });\n\n     // Forward request to LlamaIndex with server-generated token\n     const response = await axios.get('http://llamaindex-query:8202/search', {\n       headers: { 'Authorization': `Bearer ${jwt}` }\n     });\n\n     res.json(response.data);\n   });\n   ```\n\n4. **Validate after fix**:\n   ```bash\n   # Build frontend and check for exposed secrets\n   cd frontend/dashboard\n   npm run build\n   grep -r \"VITE_.*TOKEN\\|VITE_.*KEY\" dist/\n   # Should return NO results\n   ```\n\n---\n\n## 2. File Permissions & Access Audit\n\n### 2.1 Root `.env` Permissions\n\n**FINDING:** Insecure file permissions\n\n```bash\n$ stat -c \"%a %U:%G %n\" /home/marce/Projetos/TradingSystem/.env\n644 marce:marce /home/marce/Projetos/TradingSystem/.env\n```\n\n**VULNERABILITY:**\n- **Permissions:** `644` (owner read/write, group/others read)\n- **Risk:** Any user in `marce` group or on system can read secrets\n- **Expected:** `600` (owner read/write only)\n\n**REMEDIATION:**\n```bash\nchmod 600 /home/marce/Projetos/TradingSystem/.env\n```\n\n### 2.2 `.gitignore` Configuration\n\n**REVIEW RESULT:** ‚úÖ GOOD (with minor gaps)\n\n**Properly Excluded:**\n```gitignore\n# Root .env files - NEVER commit these\n.env\n*.env.local\n.env.*.local\n.env.backup*\n.env.test\n.env.production\n\n# Service-level .env files (should NOT exist per project rules)\nbackend/api/**/.env\nbackend/services/**/.env\nfrontend/apps/**/.env\napps/**/.env\n\n# Age encryption keys (NEVER commit private keys)\n*.age-key.txt\nage-key.txt\n```\n\n**GAP IDENTIFIED:**\n- Missing pattern: `.tmp-env-*/` (temporary env copies)\n- Found 8 instances in `apps/tp-capital/.tmp-env-*/`\n\n**RECOMMENDED ADDITION:**\n```gitignore\n# Temporary .env copies (scripts should clean up)\n**/.tmp-env-*/.env\n**/.tmp-env-*/\n.tmp-env-*/\n```\n\n### 2.3 Local `.env` Violations\n\n**POLICY VIOLATION:** 12+ local `.env` files found (should use centralized root `.env`)\n\n**Violating Files:**\n```\n/home/marce/Projetos/TradingSystem/backend/api/telegram-gateway/.env\n/home/marce/Projetos/TradingSystem/frontend/dashboard/.env\n/home/marce/Projetos/TradingSystem/apps/tp-capital/.tmp-env-uEzjED/.env\n/home/marce/Projetos/TradingSystem/apps/tp-capital/.tmp-env-5J906U/.env\n/home/marce/Projetos/TradingSystem/apps/tp-capital/.tmp-env-ME1F59/.env\n... (8 more temporary files)\n```\n\n**REMEDIATION:**\n1. **Delete local `.env` files**:\n   ```bash\n   rm backend/api/telegram-gateway/.env\n   rm frontend/dashboard/.env\n   rm -rf apps/tp-capital/.tmp-env-*\n   ```\n\n2. **Update service loaders** to use root `.env`:\n   ```javascript\n   // backend/api/telegram-gateway/src/index.ts\n   import dotenv from 'dotenv';\n   import path from 'path';\n\n   const projectRoot = path.resolve(__dirname, '../../.\n\n[... content truncated ...]"
    },
    {
      "id": "evidence.tp-capital-connectivity-incident-2025-11-05",
      "title": "Incident Report - TP Capital Connectivity Failure (2025-11-05)",
      "description": "Post-mortem do incidente de conectividade do TP Capital com root cause analysis e a√ß√µes corretivas.",
      "owner": "DevOps",
      "category": "evidence",
      "type": "incident",
      "tags": [
        "incident",
        "tp-capital",
        "networking",
        "post-mortem"
      ],
      "lastReviewed": "2025-11-05",
      "reviewCycleDays": 180,
      "publishSlug": null,
      "previewPath": "/governance/docs/evidence/incidents/2025-11-05-tp-capital-connectivity-failure.md",
      "previewContent": "---\ntitle: \"Incident Report: TP-Capital Connectivity Failure\"\ndate: 2025-11-05\nseverity: high\nstatus: resolved\naffected_services:\n  - TP-Capital API\n  - Telegram Gateway API\n  - Dashboard Frontend\nroot_cause: \"Multiple configuration issues in Docker networking and environment variables\"\nresolution_time: \"~2 hours\"\nowner: DevOps Team\ntags: [incident, docker, networking, environment-variables, api]\n---\n\n# Incident Report: TP-Capital Connectivity Failure\n\n**Date**: November 5, 2025\n**Duration**: ~2 hours  \n**Severity**: High  \n**Status**: ‚úÖ Resolved  \n\n## Executive Summary\n\nThe TP-Capital API became unavailable due to a **chain of configuration errors** in Docker networking, environment variables, and API routing. This incident affected:\n\n- **TP-Capital API**: Circuit breaker opened due to Gateway API unavailability\n- **Telegram Gateway API**: Failed to start due to PgBouncer authentication failure\n- **Dashboard Frontend**: Unable to fetch signals (404 errors, wrong URLs)\n\n**Impact**: Users could not view trading signals for ~2 hours until all services were restored.\n\n---\n\n## Timeline\n\n| Time | Event |\n|------|-------|\n| 15:00 | User reports \"TP-Capital indispon√≠vel\" error in Dashboard |\n| 15:05 | Investigation started - Circuit breaker OPEN on TP-Capital |\n| 15:10 | Root cause #1: Telegram Gateway API in restart loop |\n| 15:15 | Root cause #2: PgBouncer missing TELEGRAM_DB_PASSWORD |\n| 15:20 | Fix #1: Recreated PgBouncer with correct password |\n| 15:25 | Root cause #3: TP-Capital using wrong Gateway URL (host.docker.internal) |\n| 15:30 | Fix #2: Updated TELEGRAM_GATEWAY_URL to container hostname |\n| 15:35 | Root cause #4: Dashboard using wrong port (4008 vs 4005) |\n| 15:40 | Fix #3: Updated Dashboard to use Vite proxy |\n| 15:45 | Root cause #5: VITE_TP_CAPITAL_API_URL forcing direct URL |\n| 15:50 | Fix #4: Removed VITE_TP_CAPITAL_API_URL from .env |\n| 16:00 | Services restored - Circuit breaker closed |\n| 16:30 | Root cause #6: Checkpoints blocking signal display |\n| 16:35 | Fix #5: Filtered checkpoints in SQL query |\n| 16:40 | Root cause #7: Messages with status='queued' not processed |\n| 16:45 | Fix #6: Updated filter to include 'queued' status |\n| 17:00 | ‚úÖ All services healthy - 185 signals visible |\n\n---\n\n## Root Causes (7 Issues)\n\n### 1. PgBouncer Missing Password ‚ùå\n\n**Issue**: PgBouncer container had `DATABASES_PASSWORD=\"\"` (empty string)\n\n**Cause**: Docker Compose not loading `${TELEGRAM_DB_PASSWORD}` from `.env`\n\n**Symptom**:\n```\nERROR: password authentication failed for user \"telegram\"\n```\n\n**Fix**:\n```bash\n# Use wrapper script to export .env variables\ncd tools/compose\nset -a && source ../../.env && set +a\ndocker compose -f docker-compose.4-2-telegram-stack.yml up -d telegram-pgbouncer\n```\n\n**Prevention**: Create validation script to check environment variables before container start\n\n---\n\n### 2. Wrong Gateway URL (host.docker.internal) ‚ùå\n\n**Issue**: TP-Capital configured to access Gateway API via `http://host.docker.internal:4010`\n\n**Cause**: Outdated configuration assuming Gateway ran on host\n\n**Symptom**:\n```\nConnection refused (172.18.0.1:4010)\nCircuit breaker OPEN\n```\n\n**Fix**:\n```yaml\n# docker-compose.4-1-tp-capital-stack.yml\n- TELEGRAM_GATEWAY_URL=http://telegram-gateway-api:4010  # Container hostname\n```\n\n**Prevention**: Always use **container hostnames** for inter-container communication\n\n---\n\n### 3. Dashboard Using Wrong Port (4008 vs 4005) ‚ùå\n\n**Issue**: Dashboard trying to access `tp-capital-api:4008` (host port instead of internal port)\n\n**Cause**: Confusion between **host-mapped ports** (4008) and **internal container ports** (4005)\n\n**Symptom**:\n```\nConnection refused inside dashboard-ui container\n```\n\n**Fix**:\n```yaml\n# docker-compose.1-dashboard-stack.yml\n# Use Vite proxy targets (internal ports)\n- VITE_TP_CAPITAL_PROXY_TARGET=http://tp-capital-api:4005\n```\n\n**Prevention**: Document port mapping strategy clearly\n\n---\n\n### 4. VITE_TP_CAPITAL_API_URL Forcing Direct URL ‚ùå\n\n**Issue**: `.env` had `VITE_TP_CAPITAL_API_URL=http://localhost:4008`, forcing browser to access directly\n\n**Cause**: Obsolete configuration from pre-Docker era\n\n**Symptom**:\n```\nFailed to fetch (browser can't resolve container hostnames)\n```\n\n**Fix**:\n```bash\n# Comment out in .env\n#VITE_TP_CAPITAL_API_URL=http://localhost:4008\n```\n\n**Prevention**: Use **proxy targets** for containerized frontends, not direct URLs\n\n---\n\n### 5. Checkpoints Blocking Signal Display ‚ùå\n\n**Issue**: `__checkpoint__` records had most recent timestamps, appearing first in results\n\n**Cause**: No filter to exclude internal checkpoint records\n\n**Symptom**:\n```\nAPI returns 10 results, all showing \"__checkpoint__\"\n```\n\n**Fix**:\n```javascript\n// timescaleClient.js\nWHERE asset != '__checkpoint__'\n```\n\n**Prevention**: Always filter internal/system records in production queries\n\n---\n\n### 6. Messages with status='queued' Not Processed ‚ùå\n\n**Issue**: New messages had `status='queued'` but TP-Capital only fetched `status='received'`\n\n**Cause**: Gateway API sets initial status to 'queued', but client expected 'received'\n\n**Symptom**:\n```\nMessages 5832 (CMIGX129) and 5834 (BOVAW24) not processed\n```\n\n**Fix**:\n```javascript\n// gatewayHttpClient.js\nurl.searchParams.set('status', 'received,queued');  // Include both\n```\n\n**Prevention**: Document message status lifecycle and align client filters\n\n---\n\n### 7. Empty Photos Blocking Queue ‚ùå\n\n**Issue**: 103 photos without text/caption were stuck in queue with `status='received'`\n\n**Cause**: Polling worker tried to parse empty messages, failed, but didn't mark as processed\n\n**Symptom**:\n```\n[GatewayPollingWorker] Message processing failed: Empty message\n```\n\n**Fix**:\n```javascript\n// gatewayPollingWorker.js\nif (!messageContent || messageContent.trim().length === 0) {\n  logger.debug('Empty message (photo without text), skipping');\n  await this.markMessageAsFailed(msg.message_id, new Error('Empty message (photo without text)'));\n  return;\n}\n```\n\n**Prevention**: Always validate message content before parsing\n\n---\n\n## Impact Analysis\n\n### Business Impact\n- **User Impact**: Trading signals unavailable for 2 hours\n- **Data Loss**: None (all messages preserved in database)\n- **Revenue Impact**: None (system not yet in production)\n\n### Technical Impact\n- **Circuit Breaker**: Opened on TP-Capital (protected downstream services)\n- **Retry Attempts**: ~240 failed requests (2 hours √ó 2 requests/min)\n- **Database Load**: Normal (no degradation)\n\n---\n\n## Files Changed\n\n### 1. Docker Compose Configuration\n- `tools/compose/docker-compose.4-1-tp-capital-stack.yml`\n  - Fixed `TELEGRAM_GATEWAY_URL` to use container hostname\n  \n- `tools/compose/docker-compose.1-dashboard-stack.yml`\n  - Changed to use `VITE_*_PROXY_TARGET` instead of `VITE_*_API_URL`\n\n### 2. Application Code\n- `apps/tp-capital/src/timescaleClient.js`\n  - Added `WHERE asset != '__checkpoint__'` filter\n  \n- `apps/tp-capital/src/gatewayPollingWorker.js`\n  - Added validation for empty messages (photos without text)\n  \n- `apps/tp-capital/src/clients/gatewayHttpClient.js`\n  - Added `status=received,queued` to API call\n\n### 3. Environment Variables\n- `.env`\n  - Commented out `VITE_TP_CAPITAL_API_URL` (use proxy fallback)\n\n---\n\n## Lessons Learned\n\n### ‚úÖ What Worked Well\n1. **Circuit Breaker Pattern**: Prevented cascading failures (TP-Capital degraded gracefully)\n2. **Health Checks**: Quickly identified which services were unhealthy\n3. **Structured Logging**: Easy to trace errors through log aggregation\n4. **Idempotency**: No duplicate signals created during retries\n\n### ‚ö†Ô∏è What Needs Improvement\n\n#### 1. **Environment Variable Validation** (CRITICAL)\n```bash\n# MISSING: Pre-startup validation script\nvalidate-env.sh --check-required --check-empty-values\n```\n\n**Action**: Create governance policy requiring environment validation before container start\n\n#### 2. **Container Networking Documentation** (HIGH)\n```\n# MISSING: Clear documentation of port mapping strategy\nHost Port 4008 ‚Üí Container Port 4005 (tp-capital-api)\n```\n\n**Action**: Create \"Container Communication Best Practices\" policy\n\n#### 3. **Frontend Proxy Configuration** (HIGH)\n```javascript\n// WRONG: Direct URL in containerized environment\nVITE_TP_CAPITAL_API_URL=http://tp-capital-api:4005\n\n// CORRECT: Use proxy target\nVITE_TP_CAPITAL_PROXY_TARGET=http://tp-capital-api:4005\n```\n\n**Action**: Create \"Frontend-Backend Communication\" policy\n\n#### 4. **Message Status Lifecycle** (MEDIUM)\n```\n# UNDOCUMENTED: Message statuses and transitions\nqueued ‚Üí received ‚Üí published\n```\n\n**Action**: Create state machine diagram and policy\n\n#### 5. **Queue Management** (MEDIUM)\n```\n# MISSING: Automatic cleanup of failed/empty messages\n103 photos blocking queue for 2 hours\n```\n\n**Action**: Create automated cleanup job and policy\n\n---\n\n## Action Items\n\n### Immediate (P0)\n- [x] All services restored and healthy\n- [x] Circuit breakers closed\n- [x] Signals visible in Dashboard (185 total, 3 from today)\n\n### Short-term (P1 - This week)\n- [ ] Create environment variable validation script (`scripts/validation/validate-env.sh`)\n- [ ] Create pre-deploy checklist (`governance/controls/PRE-DEPLOY-CHECKLIST.md`)\n- [ ] Document port mapping strategy (`governance/policies/docker-networking-policy.md`)\n- [ ] Create message status lifecycle diagram (`docs/content/diagrams/message-status-lifecycle.puml`)\n\n### Medium-term (P2 - Next sprint)\n- [ ] Implement automated cleanup job for failed messages\n- [ ] Add alerting for circuit breaker open state (> 5 minutes)\n- [ ] Create integration test suite for container networking\n- [ ] Add Prometheus metrics for message processing failures\n\n---\n\n## Prevention Measures\n\n### 1. **Pre-Deployment Validation**\n```bash\n#!/bin/bash\n# scripts/validation/validate-deployment.sh\n\n# Check environment variables\nvalidate-env.sh --strict\n\n# Check container network connectivity\nvalidate-network.sh --test-all-endpoints\n\n# Check database schemas\nvalidate-schema.sh --verify-tables\n\n# Check API routes\nvalidate-routes.sh --test-all-services\n```\n\n[... content truncated ...]"
    },
    {
      "id": "policies.container-infrastructure-policy",
      "title": "Pol√≠tica de Infraestrutura de Containers, Redes e Comunica√ß√£o",
      "description": "Diretrizes obrigat√≥rias para arquitetura de containers, redes Docker, gerenciamento de portas e comunica√ß√£o inter-servi√ßos no TradingSystem.",
      "owner": "PlatformEngineering",
      "category": "policies",
      "type": "policy",
      "tags": [
        "infrastructure",
        "containers",
        "networking",
        "docker",
        "ports",
        "security",
        "architecture"
      ],
      "lastReviewed": "2025-11-05",
      "reviewCycleDays": 90,
      "publishSlug": "/governance/policies/container-infrastructure-policy",
      "previewPath": "/governance/docs/policies/container-infrastructure-policy.md",
      "previewContent": "---\ntitle: \"Pol√≠tica de Infraestrutura de Containers, Redes e Comunica√ß√£o\"\nid: POL-0003\nowner: PlatformEngineering\nlastReviewed: \"2025-11-05\"\nreviewCycleDays: 90\nstatus: active\nappliesTo:\n  - AllContainerizedServices\n  - DockerCompose\n  - Networking\n  - PortManagement\n  - StackArchitecture\nrelated:\n  - POL-0002\n  - PORT-GOVERNANCE-2025-11-05\ntags:\n  - infrastructure\n  - containers\n  - networking\n  - docker\n  - ports\n  - security\n  - architecture\n---\n\n# Pol√≠tica de Infraestrutura de Containers, Redes e Comunica√ß√£o\n\n**ID:** POL-0003  \n**Owner:** PlatformEngineering  \n**Status:** Active  \n**Last Reviewed:** 2025-11-05  \n**Next Review:** 2026-02-03 (90 days)\n\n## 1. Objetivo\n\nEstabelecer diretrizes obrigat√≥rias para arquitetura de containers, redes Docker, gerenciamento de portas e comunica√ß√£o inter-servi√ßos no TradingSystem, garantindo isolamento, seguran√ßa, escalabilidade e manutenibilidade.\n\n## 2. Escopo\n\nEsta pol√≠tica aplica-se a:\n\n- **Docker Compose Stacks:** Todos os arquivos `docker-compose*.yml`\n- **Containers:** Todos os servi√ßos containerizados (APIs, databases, cache, monitoring)\n- **Redes Docker:** Cria√ß√£o, configura√ß√£o e uso de redes bridge\n- **Portas:** Aloca√ß√£o, registry e valida√ß√£o de portas\n- **Comunica√ß√£o:** Protocolos, DNS interno, proxies e APIs\n- **Desenvolvedores/DevOps:** Todos os contribuidores que criam ou modificam infraestrutura\n\n## 3. Princ√≠pios Fundamentais\n\n### 3.1 Isolamento por Stack (Zero Trust Network)\n\n**PRINC√çPIO:**\n> Cada stack (Telegram, TP Capital, Workspace) DEVE ter sua pr√≥pria rede privada isolada. Databases, caches e message queues NUNCA devem estar em redes compartilhadas.\n\n**JUSTIFICATIVA:**\n- ‚úÖ Seguran√ßa (Zero Trust Architecture)\n- ‚úÖ Isolamento de falhas (blast radius reduzido)\n- ‚úÖ Compliance (PCI-DSS, LGPD, SOC2)\n- ‚úÖ Escalabilidade (stacks independentes)\n- ‚úÖ Multi-tenancy (futuro)\n\n**OBRIGAT√ìRIO:**\n```yaml\n# ‚úÖ CORRETO - Database isolado\nservices:\n  telegram-timescale:\n    networks:\n      - telegram_backend  # SOMENTE rede privada da stack\n```\n\n**PROIBIDO:**\n```yaml\n# ‚ùå ERRADO - Database em rede compartilhada\nservices:\n  telegram-timescale:\n    networks:\n      - telegram_backend\n      - tradingsystem_backend  # ‚ùå EXP√ïE DATABASE!\n```\n\n### 3.2 Comunica√ß√£o Controlada via Hub Network\n\n**PRINC√çPIO:**\n> Servi√ßos que precisam se comunicar entre stacks DEVEM usar uma rede hub dedicada (`tradingsystem_backend`). APIs s√£o \"pontes\" entre a rede privada e o hub.\n\n**PADR√ÉO:**\n```yaml\n# API que exp√µe servi√ßos\nservices:\n  telegram-gateway-api:\n    networks:\n      - telegram_backend        # Acessa database/cache (privado)\n      - tradingsystem_backend   # Exp√µe API para outros servi√ßos (hub)\n```\n\n**RAZ√ÉO:**\n- ‚úÖ Controle granular de comunica√ß√£o\n- ‚úÖ Auditoria de tr√°fego cross-stack\n- ‚úÖ Prepara√ß√£o para service mesh (Istio/Linkerd)\n\n### 3.3 Frontend Isolation\n\n**PRINC√çPIO:**\n> Frontend (Dashboard) DEVE estar isolado em sua pr√≥pria rede. Acesso a backends DEVE ser via proxy (Vite, NGINX) ou hub network, NUNCA direto a databases.\n\n**OBRIGAT√ìRIO:**\n```yaml\nservices:\n  dashboard-ui:\n    networks:\n      - tradingsystem_frontend  # Rede de UI\n      - tradingsystem_backend   # Acesso a APIs (formalizado no compose)\n```\n\n**PROIBIDO:**\n- ‚ùå Frontend acessando databases diretamente\n- ‚ùå Conex√µes manuais via `docker network connect` (deve estar no compose)\n- ‚ùå Hardcoded IPs em frontend (usar DNS interno)\n\n## 4. Taxonomia de Redes\n\n### 4.1 Estrutura de Redes (Atual)\n\n| Rede | Tipo | Prop√≥sito | Containers | Status |\n|------|------|-----------|------------|--------|\n| `telegram_backend` | Privada | Stack Telegram isolada | MTProto, Gateway API, TimescaleDB, Redis, RabbitMQ, Monitoring | ‚úÖ Ativa |\n| `tp_capital_backend` | Privada | Stack TP Capital isolada | TP Capital API, TimescaleDB, PgBouncer, Redis | ‚úÖ Ativa |\n| `tradingsystem_backend` | Hub | Comunica√ß√£o cross-stack controlada | Workspace API, Telegram Gateway API, TP Capital API, MTProto | ‚úÖ Ativa |\n| `tradingsystem_frontend` | UI | Frontend isolado | Dashboard UI | ‚úÖ Ativa |\n\n**Nomenclatura:**\n- `{stack}_backend` ‚Üí Rede privada de stack (ex: `telegram_backend`)\n- `tradingsystem_backend` ‚Üí Hub para comunica√ß√£o cross-stack\n- `tradingsystem_frontend` ‚Üí Rede de UI\n\n### 4.2 Regras de Conex√£o por Tipo de Servi√ßo\n\n#### Database / Cache / Message Queue (1 Rede)\n\n**SEMPRE:** Somente rede privada da stack\n\n```yaml\nservices:\n  telegram-timescale:\n    networks: [telegram_backend]\n  \n  telegram-redis-master:\n    networks: [telegram_backend]\n  \n  telegram-rabbitmq:\n    networks: [telegram_backend]\n```\n\n**Raz√£o:** Zero exposi√ß√£o externa, seguran√ßa m√°xima.\n\n#### API que Exp√µe Servi√ßos (2 Redes)\n\n**PADR√ÉO:** Rede privada + Hub\n\n```yaml\nservices:\n  telegram-gateway-api:\n    networks:\n      - telegram_backend        # Acessa DB/cache\n      - tradingsystem_backend   # Exp√µe API\n```\n\n**Raz√£o:** API √© \"ponte segura\" entre privado e p√∫blico.\n\n#### API que Consome Outros Servi√ßos (3+ Redes)\n\n**PADR√ÉO:** Rede privada + Redes consumidas + Hub\n\n```yaml\nservices:\n  tp-capital-api:\n    networks:\n      - tp_capital_backend      # Acessa seu DB\n      - telegram_backend        # Consome mensagens do Telegram\n      - tradingsystem_backend   # Exp√µe API para Dashboard\n```\n\n**Raz√£o:** M√∫ltiplas conex√µes necess√°rias, todas expl√≠citas.\n\n#### Frontend (2 Redes)\n\n**PADR√ÉO:** Rede UI + Hub (para proxy)\n\n```yaml\nservices:\n  dashboard-ui:\n    networks:\n      - tradingsystem_frontend  # UI layer\n      - tradingsystem_backend   # APIs (via Vite proxy)\n```\n\n**Raz√£o:** Isolamento + acesso controlado via proxy.\n\n## 5. Gerenciamento de Portas\n\n### 5.1 Port Registry (Fonte de Verdade)\n\n**OBRIGAT√ìRIO:**\n- Todas as portas DEVEM estar registradas em: `config/ports/registry.yaml`\n- Port Registry √© a **√∫nica fonte de verdade**\n- Geradores autom√°ticos (`npm run ports:sync`) atualizam composes a partir do registry\n\n**Formato do Registry:**\n```yaml\nservices:\n  - name: telegram-gateway-api\n    port: 4010\n    protocol: http\n    stack: telegram\n    networks:\n      - telegram_backend\n      - tradingsystem_backend\n    healthcheck: /health\n    description: \"Telegram Gateway REST API\"\n    \n  - name: telegram-timescale\n    port: 5434\n    protocol: postgresql\n    stack: telegram\n    networks:\n      - telegram_backend\n    internal: true  # N√£o expor para host\n    description: \"TimescaleDB dedicado para Telegram\"\n```\n\n### 5.2 Regras de Aloca√ß√£o de Portas\n\n**Ranges Reservados:**\n\n| Range | Prop√≥sito | Exemplos |\n|-------|-----------|----------|\n| `3000-3999` | Frontend e UIs | Dashboard (via Gateway 9080), Grafana (3100) |\n| `4000-4999` | Backend APIs | Telegram Gateway (via Gateway 9080), TP Capital (via Gateway 9080), MTProto (4007) |\n| `5000-5999` | Databases | Postgres (5432), TimescaleDB (5434, 5435) |\n| `6000-6999` | Cache/Queue | Redis (6379-6387), PgBouncer (6434-6435), RabbitMQ (5672) |\n| `9000-9999` | API Gateway | Traefik HTTP (9080), Traefik Dashboard (9081) |\n| `8000-8999` | Tooling/Utilities | RAG System (8202) |\n| `9000-9999` | Monitoring/Metrics | Prometheus (9193), Exporters (9121, 9188) |\n\n**PROIBIDO:**\n- ‚ùå Alterar portas sem atualizar registry\n- ‚ùå Usar portas fora dos ranges definidos sem aprova√ß√£o\n- ‚ùå Conflitos de portas (valida√ß√£o autom√°tica em CI)\n- ‚ùå Portas hardcoded em c√≥digo (usar env vars)\n\n### 5.3 Valida√ß√£o Autom√°tica\n\n**CI/CD DEVE bloquear build se:**\n```bash\nnpm run ports:validate  # Executa:\n  # 1. Detecta conflitos de portas\n  # 2. Verifica ranges\n  # 3. Valida registry.yaml schema\n  # 4. Compara registry vs composes (sync)\n```\n\n## 6. Comunica√ß√£o Inter-Servi√ßos\n\n### 6.1 Protocolos Permitidos\n\n| Protocolo | Uso | Exemplo |\n|-----------|-----|---------|\n| **HTTP/REST** | APIs s√≠ncronas | Dashboard ‚Üî Telegram Gateway API |\n| **WebSocket** | Real-time, streaming | MTProto ‚Üî Telegram Servers |\n| **PostgreSQL Wire** | Database queries | API ‚Üî TimescaleDB (via PgBouncer) |\n| **Redis Protocol** | Cache, pub/sub | API ‚Üî Redis Master |\n| **AMQP** | Message queue | Async jobs ‚Üî RabbitMQ |\n\n**PROIBIDO:**\n- ‚ùå gRPC (n√£o padronizado no projeto ainda)\n- ‚ùå SSH/Telnet (usar Docker exec)\n- ‚ùå Protocolos propriet√°rios sem documenta√ß√£o\n\n### 6.2 DNS Interno (Container Name Resolution)\n\n**OBRIGAT√ìRIO:**\n- Usar **nomes de container** como hostname (n√£o IPs)\n- DNS autom√°tico do Docker resolve nomes na mesma rede\n\n**Exemplo:**\n```javascript\n// ‚úÖ CORRETO - DNS interno\nconst dbUrl = 'postgresql://user:pass@telegram-pgbouncer:6432/telegram';\nconst redisUrl = 'redis://telegram-redis-master:6379';\nconst apiUrl = 'http://telegram-gateway-api:4010';\n\n// ‚ùå ERRADO - IPs hardcoded\nconst dbUrl = 'postgresql://user:pass@192.168.48.10:6432/telegram';\n```\n\n**Benef√≠cios:**\n- ‚úÖ Resiliente a mudan√ßas de IP\n- ‚úÖ Funciona em dev, staging, prod\n- ‚úÖ Facilita multi-host deployment\n\n### 6.3 Proxy e Load Balancing\n\n**Frontend Proxy (Vite Dev Server):**\n```javascript\n// vite.config.ts\nexport default defineConfig({\n  server: {\n    proxy: {\n      '/api/telegram-gateway': {\n        target: 'http://telegram-gateway-api:4010',\n        changeOrigin: true,\n      },\n      '/api/tp-capital': {\n        target: 'http://tp-capital-api:4008',\n        changeOrigin: true,\n      },\n    },\n  },\n});\n```\n\n**Produ√ß√£o (NGINX/Traefik):**\n- Usar API Gateway (Kong/Traefik) como entry point √∫nico\n- Rate limiting, auth, SSL termination no gateway\n- Service mesh (Istio) para mTLS (futuro)\n\n## 7. Docker Compose Best Practices\n\n### 7.1 Estrutura de Arquivos\n\n**OBRIGAT√ìRIO:**\n```\ntools/compose/\n‚îú‚îÄ‚îÄ docker-compose.4-2-telegram-stack.yml      # Stack Telegram completa\n‚îú‚îÄ‚îÄ docker-compose.tp-capital.yml    # Stack TP Capital completa\n‚îú‚îÄ‚îÄ docker-compose.1-dashboard-stack.yml     # Frontend UI\n‚îú‚îÄ‚îÄ docker-compose.workspace.yml     # Workspace API + DB\n‚îú‚îÄ‚îÄ docker-compose.docs.yml          # Documentation Hub + API\n‚îî‚îÄ‚îÄ docker-compose.6-1-monitoring-stack.yml    # Prometheus/Grafana (cross-stack)\n```\n\n**Cada arquivo DEVE:**\n1. Definir suas pr√≥prias networks\n2. Usar vari√°veis de ambiente (`${VARNAME:-default}`)\n3. Ter healthchecks obrigat√≥rios\n4. Seguir nomenclatura: `{stack\n\n[... content truncated ...]"
    },
    {
      "id": "policies.environment-variables-policy",
      "title": "Pol√≠tica de Vari√°veis de Ambiente",
      "description": "Diretrizes para gerenciamento seguro de vari√°veis de ambiente no TradingSystem.",
      "owner": "SecurityEngineering",
      "category": "policies",
      "type": "policy",
      "tags": [
        "security",
        "environment-variables",
        "configuration"
      ],
      "lastReviewed": "2025-11-08",
      "reviewCycleDays": 90,
      "publishSlug": "/governance/policies/environment-variables-policy",
      "previewPath": "/governance/docs/policies/environment-variables-policy.md",
      "previewContent": "# Environment Variables Governance Policy\n\n> √öltima revis√£o: 2025-11-05 ‚Äî Owner: SecurityEngineering\n\n## Objetivo\nGarantir que todos os servi√ßos do TradingSystem usem um modelo √∫nico de vari√°veis de ambiente, evitando secrets √≥rf√£os, arquivos duplicados e configura√ß√µes divergentes entre stacks locais, Docker e pipelines automatizados.\n\n## Fontes Can√¥nicas\n| Arquivo | Tipo | Status | Conte√∫do |\n| --- | --- | --- | --- |\n| `config/.env.defaults` | Default versionado | ‚úÖ Commitado | Valores n√£o sens√≠veis, portas, imagens Docker e toggles. |\n| `.env` | Secrets locais | ‚ùå Gitignore | Token real por esta√ß√£o. Deriva de `.env.example` + `scripts/env/setup-env.sh`. |\n| `.env.shared` | Gerado | ‚úÖ Commitado | Portas/hosts sincronizados via `npm run ports:sync` (n√£o editar manualmente). |\n| `.env.example` | Template m√≠nimo | ‚úÖ Commitado | Apenas chaves que exigem a√ß√£o humana (API keys, senhas). Mantido sincronizado com este documento. |\n\n> Qualquer outro arquivo `.env*` na raiz √© proibido. Arquivos espec√≠ficos de servi√ßo devem seguir o padr√£o `<service>/.env.example` + `.env.local` (gitignored).\n\n## Processo para adicionar uma nova vari√°vel\n1. **Planeje**: registre o motivo e o servi√ßo impactado.\n2. **Defaults**: inclua o valor seguro em `config/.env.defaults` (nunca em `.env`).\n3. **Template**: se o valor for secreto, adicione o placeholder em `.env.example` com instru√ß√µes claras.\n4. **Documenta√ß√£o**: atualize `docs/content/tools/security-config/env.mdx` com descri√ß√£o, owner e ciclo de rota√ß√£o.\n5. **Governan√ßa**: anexe evid√™ncias de revis√£o nesta pol√≠tica via PR.\n6. **Valida√ß√£o**: rode `bash scripts/env/validate-env.sh` para garantir consist√™ncia.\n\n## Regras Operacionais\n- `scripts/env/setup-env.sh` deve ser usado ap√≥s clonar o reposit√≥rio para gerar senhas fortes (Timescale, Redis, RabbitMQ, etc.).\n- `scripts/env/validate-env.sh` roda em CI/CD e localmente antes de qualquer PR que altere vari√°veis.\n- `.env.shared` √© regenerado por `npm run ports:sync` e serve como √∫nica fonte para dashboards, docs e agentes. Nunca edite manualmente.\n- Secrets n√£o podem aparecer em `config/.env.defaults`, `docs/`, `governance/` ou qualquer workspace p√∫blico.\n- Sempre que uma vari√°vel √© descontinuada, remova-a de **todos** os arquivos acima e registre no changelog do PR.\n\n## Grupos de Vari√°veis\n- **API Keys & Observability**: `OPENAI_API_KEY`, `LANGSMITH_API_KEY`, `SENTRY_AUTH_TOKEN`, `GITHUB_TOKEN`, `SLACK_WEBHOOK_URL`.\n- **Mensageria/Telegram**: `TELEGRAM_*`, `TP_CAPITAL_*`, `VITE_TELEGRAM_*` ‚Äî exigem dupla rota√ß√£o (bot + gateway) e armazenam tokens gerados manualmente.\n- **Bancos & Filas**: todos os `*_PASSWORD`, `*_PASS`, `*_TOKEN` relacionados a Timescale, Redis, RabbitMQ, Neon e Kestra s√£o gerados pelo script e jamais podem ser commitados.\n- **Inter-service**: `GATEWAY_SECRET_TOKEN`, `API_SECRET_TOKEN`, `INTER_SERVICE_SECRET`, `VITE_GATEWAY_TOKEN` ‚Äî compartilham o mesmo ciclo de rota√ß√£o (90 dias) definido em `governance/controls/secrets-rotation-sop.md`.\n\n## Auditoria Cont√≠nua\n- `bash scripts/env/validate-env.sh --json` gera relat√≥rios em `reports/env/` (gitignored) e deve ser anexado em revis√µes trimestrais.\n- O dashboard de governan√ßa (`frontend/dashboard ‚Üí Knowledge ‚Üí Governance`) consome `.env.shared` + `config/.env.defaults` para exibir portas e owners.\n- Incidentes envolvendo vazamento de `.env` seguem o fluxo definido em `governance/controls/secrets-rotation-sop.md`.\n\nCumprir esta pol√≠tica √© obrigat√≥rio para qualquer agente (humano ou IA) antes de gerar novos arquivos de configura√ß√£o.\n"
    },
    {
      "id": "policies.hardcoded-urls-policy",
      "title": "Pol√≠tica de Preven√ß√£o de URLs Hardcoded",
      "description": "Diretrizes para preven√ß√£o de URLs hardcoded e uso correto de proxies Vite no frontend.",
      "owner": "FrontendEngineering",
      "category": "policies",
      "type": "policy",
      "tags": [
        "frontend",
        "vite",
        "proxy",
        "configuration"
      ],
      "lastReviewed": "2025-11-08",
      "reviewCycleDays": 90,
      "publishSlug": "/governance/policies/hardcoded-urls-policy",
      "previewPath": "/governance/docs/policies/hardcoded-urls-policy.md",
      "previewContent": "---\ntitle: Hardcoded URLs Prevention Policy\ndomain: governance\ntype: policy\ntags: [security, quality, automation]\nstatus: active\nlast_review: \"2025-11-08\"\nsummary: Pol√≠tica de 5 camadas para prevenir URLs hardcoded no c√≥digo e garantir configura√ß√£o via vari√°veis de ambiente\n---\n\n# Hardcoded URLs Prevention Policy\n\n## üéØ Objetivo\n\n**Garantir que NENHUMA URL hardcoded seja commitada no reposit√≥rio**, exigindo que todas as URLs sejam configuradas via vari√°veis de ambiente.\n\n## üìã Motiva√ß√£o\n\nURLs hardcoded causam:\n- ‚ùå **Quebra em ambientes diferentes** (dev/staging/prod)\n- ‚ùå **Falhas em containers** (hostnames n√£o resolvem)\n- ‚ùå **Dificuldade de manuten√ß√£o** (mudan√ßas requerem edi√ß√£o de c√≥digo)\n- ‚ùå **Problemas de seguran√ßa** (exposi√ß√£o de endpoints internos)\n\n## üõ°Ô∏è Pol√≠tica de 5 Camadas\n\n### Camada 1: Pre-commit Hook (Bloqueio Imediato)\n\n**Status**: ‚úÖ **IMPLEMENTADO**\n\n**Arquivo**: `.husky/pre-commit`\n\n**Valida√ß√£o**: Executa `npm run ports:scan-hardcoded` em **TODOS os commits** (n√£o apenas mudan√ßas em `config/ports/`)\n\n```bash\n# Sempre executar scan de hardcoded URLs\necho \"üîé Scanning for hardcoded localhost URLs...\"\nnpm run ports:scan-hardcoded\n```\n\n**A√ß√£o**: Se detectar URLs hardcoded ‚Üí **BLOQUEIA o commit**\n\n**Arquivo validado**: `tools/ports/scan-hardcoded.js`\n\n---\n\n### Camada 2: ESLint Rules (Valida√ß√£o em Tempo de Desenvolvimento)\n\n**Status**: ‚ö†Ô∏è **PARCIALMENTE IMPLEMENTADO** (apenas frontend/dashboard)\n\n**Arquivo**: `.eslintrc.json` (raiz do projeto - ser√° criado)\n\n**Regras**:\n\n```json\n{\n  \"rules\": {\n    \"no-restricted-syntax\": [\n      \"error\",\n      {\n        \"selector\": \"Literal[value=/^https?:\\\\/\\\\/localhost:[0-9]{1,5}/]\",\n        \"message\": \"‚ùå Use environment variables instead of hardcoded localhost URLs. See governance/controls/hardcoded-urls-prevention-policy.md\"\n      },\n      {\n        \"selector\": \"Literal[value=/^https?:\\\\/\\\\/127\\\\.0\\\\.0\\\\.1:[0-9]{1,5}/]\",\n        \"message\": \"‚ùå Use environment variables instead of hardcoded 127.0.0.1 URLs. See governance/controls/hardcoded-urls-prevention-policy.md\"\n      },\n      {\n        \"selector\": \"TemplateElement[value.raw=/https?:\\\\/\\\\/localhost:[0-9]{1,5}/]\",\n        \"message\": \"‚ùå Use environment variables instead of hardcoded localhost URLs in template literals. See governance/controls/hardcoded-urls-prevention-policy.md\"\n      }\n    ]\n  }\n}\n```\n\n**Aplica√ß√£o**:\n- ‚úÖ Frontend: `frontend/dashboard/.eslintrc.json`\n- ‚úÖ Backend APIs: `backend/api/**/.eslintrc.json`\n- ‚úÖ Apps: `apps/**/.eslintrc.json`\n\n**A√ß√£o**: Se detectar URLs hardcoded ‚Üí **ERRO no editor (IDE)** + **Falha em `npm run lint`**\n\n---\n\n### Camada 3: CI/CD Validation (GitHub Actions)\n\n**Status**: ‚ö†Ô∏è **PARCIALMENTE IMPLEMENTADO** (apenas em alguns workflows)\n\n**Arquivo**: `.github/workflows/code-quality.yml`\n\n**Valida√ß√£o**: Executar validadores em **TODOS os PRs**\n\n```yaml\n- name: Validate Port Registry & Hardcoded URLs\n  run: |\n    npm run ports:validate\n    npm run ports:scan-hardcoded\n\n- name: Run ESLint (All Projects)\n  run: |\n    npm run lint:all\n```\n\n**A√ß√£o**: Se detectar URLs hardcoded ‚Üí **FALHA no CI** ‚Üí **Bloqueia merge do PR**\n\n---\n\n### Camada 4: Code Review Checklist\n\n**Status**: ‚ö†Ô∏è **N√ÉO IMPLEMENTADO** (ser√° adicionado ao PR template)\n\n**Arquivo**: `.github/PULL_REQUEST_TEMPLATE.md`\n\n**Checklist obrigat√≥rio**:\n\n```markdown\n## üîê Security & Configuration\n\n- [ ] ‚úÖ **No hardcoded URLs** - All URLs use environment variables (`.env` or `.env.defaults`)\n- [ ] ‚úÖ **ESLint passes** - `npm run lint:all` without hardcoded URL warnings\n- [ ] ‚úÖ **Port registry updated** - New services added to `config/ports/registry.yaml`\n- [ ] ‚úÖ **Environment variables documented** - Added to `config/.env.defaults` with comments\n```\n\n**A√ß√£o**: Revisor deve verificar **manualmente** antes de aprovar PR\n\n---\n\n### Camada 5: Documentation & Templates\n\n**Status**: ‚úÖ **IMPLEMENTADO** (parcialmente)\n\n**Documenta√ß√£o**:\n- ‚úÖ `docs/content/frontend/engineering/PROXY-BEST-PRACTICES.md` (Frontend)\n- ‚úÖ `CLAUDE.md` - Se√ß√£o \"CRITICAL: Environment Variables Configuration\"\n- ‚ö†Ô∏è **FALTANDO**: Template de c√≥digo para novos servi√ßos\n\n**Template de c√≥digo** (criar em `scripts/templates/new-service-template.js`):\n\n```javascript\n// ‚úÖ CORRETO: Sempre usar vari√°veis de ambiente\nconst config = {\n  apiUrl: process.env.API_URL, // ‚úÖ Sem fallback hardcoded\n  port: process.env.PORT || 3000, // ‚úÖ OK: fallback num√©rico\n  timeout: Number(process.env.TIMEOUT) || 5000, // ‚úÖ OK: valor num√©rico\n};\n\n// ‚ùå ERRADO: Fallback hardcoded com URL\nconst badConfig = {\n  apiUrl: process.env.API_URL || \"http://localhost:3000\", // ‚ùå NUNCA!\n};\n\n// Valida√ß√£o: Falhar se vari√°vel obrigat√≥ria n√£o existir\nif (!config.apiUrl) {\n  throw new Error('Missing required environment variable: API_URL');\n}\n```\n\n**A√ß√£o**: Desenvolvedores usam template ‚Üí **Menos chance de erro**\n\n---\n\n## üöÄ Implementa√ß√£o Imediata\n\n### ‚úÖ Conclu√≠do (2025-11-08)\n\n1. ‚úÖ **Removidos hardcoded URLs** de 4 arquivos backend\n2. ‚úÖ **Adicionadas vari√°veis** ao `config/.env.defaults`\n3. ‚úÖ **Valida√ß√£o funcional**: `npm run ports:scan-hardcoded` passa\n\n### üîß Pendente (Pr√≥ximos Passos)\n\n#### 1. Atualizar Pre-commit Hook (PRIORIDADE ALTA)\n\n```bash\n# Editar .husky/pre-commit\n# Adicionar valida√ß√£o SEMPRE (n√£o apenas em mudan√ßas de ports)\n\necho \"üîé Scanning for hardcoded localhost URLs...\"\nnpm run ports:scan-hardcoded || {\n  echo \"‚ùå Hardcoded localhost URLs detected!\"\n  echo \"üìñ See governance/controls/hardcoded-urls-prevention-policy.md\"\n  exit 1\n}\n```\n\n#### 2. Criar ESLint Config Global (PRIORIDADE ALTA)\n\n```bash\n# Criar .eslintrc.json na raiz\n# Aplicar regras em todos os projetos backend\nnpm install --save-dev eslint @typescript-eslint/parser @typescript-eslint/eslint-plugin\n```\n\n#### 3. Atualizar CI Workflows (PRIORIDADE M√âDIA)\n\n```bash\n# Editar .github/workflows/code-quality.yml\n# Adicionar valida√ß√£o de hardcoded URLs em TODOS os PRs\n```\n\n#### 4. Atualizar PR Template (PRIORIDADE M√âDIA)\n\n```bash\n# Editar .github/PULL_REQUEST_TEMPLATE.md\n# Adicionar checklist de hardcoded URLs\n```\n\n#### 5. Criar Template de Novo Servi√ßo (PRIORIDADE BAIXA)\n\n```bash\n# Criar scripts/templates/new-service-template.js\n# Documentar em docs/content/reference/templates/\n```\n\n---\n\n## üìä M√©tricas de Sucesso\n\n### Indicadores\n\n- **Zero commits com hardcoded URLs** nos √∫ltimos 30 dias\n- **100% de cobertura ESLint** em todos os projetos TypeScript/JavaScript\n- **CI passa em 100% dos PRs** (sem warnings de hardcoded URLs)\n- **Tempo m√©dio de detec√ß√£o** < 1 minuto (pre-commit hook)\n\n### Dashboards\n\n- GitHub Actions: Status dos workflows `code-quality.yml`\n- ESLint Report: `npm run lint:all --format json > eslint-report.json`\n\n---\n\n## üîó Refer√™ncias\n\n### Documenta√ß√£o Relacionada\n\n- [Proxy Best Practices](../../docs/content/frontend/engineering/PROXY-BEST-PRACTICES.md)\n- [Environment Variables Guide](../../docs/content/tools/security-config/env.mdx)\n- [Port Registry Documentation](../../config/ports/README.md)\n- [CLAUDE.md - Environment Variables](../../CLAUDE.md#-critical-environment-variables-configuration)\n\n### Tools\n\n- **Scanner**: `tools/ports/scan-hardcoded.js`\n- **Validator**: `tools/ports/validate.js`\n- **ESLint Config**: `frontend/dashboard/.eslintrc.json` (exemplo)\n\n---\n\n## üìù Hist√≥rico de Revis√µes\n\n| Data | Vers√£o | Mudan√ßas | Autor |\n|------|--------|----------|-------|\n| 2025-11-08 | 1.0.0 | Pol√≠tica inicial criada ap√≥s incidente de hardcoded URLs | Claude AI |\n\n---\n\n**Status**: üü° **Em Implementa√ß√£o** (3/5 camadas ativas)\n\n**Pr√≥xima Revis√£o**: 2025-12-08 (30 dias)\n\n**Respons√°vel**: DevOps Team + Code Reviewers\n\n"
    },
    {
      "id": "policies.generated-docs-freshness-policy",
      "title": "Generated Documentation Freshness Policy",
      "description": "Pol√≠tica obrigat√≥ria para manter arquivos de documenta√ß√£o gerados automaticamente atualizados antes de sincronizar com o GitHub.",
      "owner": "DocsOps",
      "category": "policies",
      "type": "policy",
      "tags": [
        "documentation",
        "automation",
        "quality",
        "governance"
      ],
      "lastReviewed": "2025-11-09",
      "reviewCycleDays": 30,
      "publishSlug": "/governance/policies/generated-docs-freshness-policy",
      "previewPath": "/governance/docs/policies/generated-docs-freshness-policy.md",
      "previewContent": "---\ntitle: Generated Documentation Freshness Policy\ndomain: governance\ntype: policy\ntags: [documentation, automation, quality]\nstatus: active\nlast_review: \"2025-11-09\"\nsummary: Pol√≠tica obrigat√≥ria para manter arquivos de documenta√ß√£o gerados automaticamente atualizados antes de qualquer sincroniza√ß√£o com o GitHub.\n---\n\n# Generated Documentation Freshness Policy\n\n## üéØ Objetivo\n\nGarantir que todo artefato de documenta√ß√£o gerado automaticamente (ex.: `docs/content/tools/ports-services.mdx`, `docs/content/frontend/design-system/tokens.mdx`) seja regenerado e commitado com carimbos de data/hora v√°lidos **antes** de sincroniza√ß√µes com o GitHub, evitando falhas em hooks (`docs:check`) e pipelines CI.\n\n## üìã Escopo\n\nAplic√°vel a todos os contribuidores que alterem:\n- Arquivos origem utilizados por `npm --prefix docs run docs:auto`\n- Recursos de infraestrutura que impactem a tabela de portas ou tokens de design\n- Scripts de automa√ß√£o em `scripts/docs/**` ou `tools/ports/**`\n\n## ‚úÖ Regras Obrigat√≥rias\n\n1. **Execu√ß√£o Pr√©-Commit**  \n   Sempre rodar `npm --prefix docs run docs:auto` seguido de `npm --prefix docs run docs:validate-generated` antes de criar commits que possam impactar documenta√ß√£o gerada.  \n   - Se o comando modificar arquivos, o colaborador **deve** revisar e incluir as mudan√ßas no commit.\n\n2. **Falha em Hooks = BLOQUEIO**  \n   √â proibido ignorar falhas do hook `docs:check`. Caso o pre-push gere novos timestamps ou arquivos, o push **deve ser abortado**, os artefatos precisam ser commitados e somente ent√£o o comando deve ser reexecutado.\n\n3. **Sem Timestamps Estagnados**  \n   Commits com timestamps de gera√ß√£o superiores a 24h s√£o vetados. O objetivo √© evitar bloqueio nos pipelines e diverg√™ncias entre branches.\n\n4. **Integra√ß√£o Cont√≠nua**  \n   PRs que toquem em documenta√ß√£o gerada precisam demonstrar, na descri√ß√£o, que os comandos acima foram executados (ex.: checklist ou link para log local).\n\n5. **Automa√ß√£o Centralizada**  \n   Novos scripts que gerem documenta√ß√£o devem escrever carimbos de data em formato ISO UTC (`YYYY-MM-DDTHH:mm:ss.SSSZ`) e atualizar tanto coment√°rios (`<!-- Last generated: ... -->`) quanto trechos exibidos aos leitores.\n\n## üö® Penalidades Operacionais\n\n| Viola√ß√£o | Impacto | A√ß√£o |\n|----------|---------|------|\n| Push com `docs:check` falhando | Bloqueio no hook Husky | Reverter push, rodar automa√ß√£o e recommitar |\n| PR com timestamps desatualizados | Falha no CI `docs:validate-generated` | Solicitar corre√ß√£o ao autor |\n| Altera√ß√£o manual em arquivos gerados | Inconsist√™ncia de fonte de verdade | Regerar com `docs:auto` e documentar causa |\n\n## üîÅ Processo de Revis√£o\n\n- Revis√£o obrigat√≥ria a cada **30 dias** ou sempre que o fluxo de gera√ß√£o for alterado.\n- M√©tricas acompanhadas na dashboard de governan√ßa: taxa de sucesso do `docs:auto` e envelhecimento m√©dio dos timestamps.\n\n## üß≠ Responsabilidades\n\n- **Documentation Guild**: manter scripts e pol√≠tica atualizados.\n- **Todos os contribuintes**: executar os comandos e incluir artefatos regenerados nos commits.\n- **Revisores de PR**: rejeitar mudan√ßas que n√£o evidenciem a execu√ß√£o de `docs:auto` + valida√ß√µes.\n\n## üìö Refer√™ncias\n\n- `scripts/docs/docs-auto.mjs`\n- `docs/tests/validate-generated-content.test.mjs`\n- `tools/ports/sync.js`\n\n"
    },
    {
      "id": "policies.secrets-env-policy",
      "title": "Pol√≠tica de Gerenciamento de Segredos e Vari√°veis de Ambiente",
      "description": "Diretrizes obrigat√≥rias para gerenciamento, armazenamento e versionamento de segredos (API keys, tokens, senhas, certificados) e vari√°veis de ambiente no TradingSystem.",
      "owner": "SecurityEngineering",
      "category": "policies",
      "type": "policy",
      "tags": [
        "security",
        "compliance",
        "secrets",
        "environment-variables"
      ],
      "lastReviewed": "2025-11-05",
      "reviewCycleDays": 90,
      "publishSlug": "/governance/policies/secrets-env-policy",
      "previewPath": "/governance/docs/policies/secrets-env-policy.md",
      "previewContent": "---\ntitle: \"Pol√≠tica de Gerenciamento de Segredos e Vari√°veis de Ambiente\"\nid: POL-0002\nowner: SecurityEngineering\nlastReviewed: \"2025-11-05\"\nreviewCycleDays: 90\nstatus: active\nappliesTo:\n  - OrderManager\n  - DataCapture\n  - Frontend\n  - WorkspaceAPI\n  - TPCapital\n  - DocumentationAPI\n  - ServiceLauncher\nrelated:\n  - STD-010\ntags:\n  - security\n  - compliance\n  - secrets\n  - environment-variables\n---\n\n# Pol√≠tica de Gerenciamento de Segredos e Vari√°veis de Ambiente\n\n**ID:** POL-0002  \n**Owner:** SecurityEngineering  \n**Status:** Active  \n**Last Reviewed:** 2025-11-05  \n**Next Review:** 2026-02-03 (90 days)\n\n## 1. Objetivo\n\nEstabelecer diretrizes obrigat√≥rias para gerenciamento, armazenamento e versionamento de segredos (API keys, tokens, senhas, certificados) e vari√°veis de ambiente no TradingSystem, garantindo confidencialidade, integridade e rastreabilidade.\n\n## 2. Escopo\n\nEsta pol√≠tica aplica-se a:\n\n- **Aplica√ß√µes de Trading:** OrderManager, DataCapture (Windows nativo)\n- **Servi√ßos Auxiliares:** WorkspaceAPI, TPCapital, DocumentationAPI, ServiceLauncher (Docker/WSL)\n- **Frontend:** Dashboard React (port 9080)\n- **Pipelines CI/CD:** GitHub Actions, scripts de deploy\n- **Desenvolvedores:** Todos os contribuidores do reposit√≥rio\n\n## 3. Princ√≠pios Fundamentais\n\n### 3.1 Nunca Versionar Segredos em Plaintext\n\n**PROIBIDO:**\n- ‚ùå Commitar arquivos `.env` reais com valores sens√≠veis\n- ‚ùå Incluir tokens/passwords em c√≥digo-fonte ou coment√°rios\n- ‚ùå Armazenar segredos em logs, artifacts de CI/CD ou documenta√ß√£o p√∫blica\n\n**PERMITIDO:**\n- ‚úÖ Versionar arquivos `.env.example` SEM valores reais\n- ‚úÖ Versionar segredos criptografados com SOPS/age (`*.enc.yaml`)\n- ‚úÖ Referenciar segredos via vari√°veis de ambiente ou secret managers\n\n### 3.2 Fontes de Verdade por Ambiente\n\n| Ambiente | Fonte de Verdade | Tecnologia |\n|----------|------------------|------------|\n| **Desenvolvimento Local** | `.env` local (n√£o versionado) | `dotenv` (Node.js), `python-dotenv` (Python), `appsettings.Development.json` (C#) |\n| **CI/CD (GitHub Actions)** | GitHub Secrets + OIDC | Environments, `secrets.*` context |\n| **Produ√ß√£o Windows** | Vari√°veis de sistema + arquivos SOPS/age criptografados | `setx`, `System.Environment`, SOPS decrypt |\n| **Docker/WSL** | Arquivos SOPS/age criptografados montados em volumes | Docker secrets, SOPS runtime |\n\n### 3.3 Naming Convention\n\n**Formato Padr√£o:** `{SERVICO}__{SECAO}__{CHAVE}`\n\n**Exemplos:**\n```bash\n# OrderManager (C# nativo Windows)\nORDERMANAGER__RISK__DAILY_LOSS_LIMIT=5000.00\nORDERMANAGER__RISK__KILL_SWITCH=false\nORDERMANAGER__PROFITDLL__USERNAME=trader123\nORDERMANAGER__PROFITDLL__PASSWORD=*** # NUNCA versionar\n\n# WorkspaceAPI (Node.js Docker)\nWORKSPACE__DB__PRIMARY__URL=postgresql://user:pass@timescaledb:5432/workspace\nWORKSPACE__DB__PRIMARY__POOL_SIZE=20\nWORKSPACE__AUTH__JWT_SECRET=*** # NUNCA versionar\n\n# Frontend Dashboard (React/Vite)\nVITE__API__WORKSPACE__URL=http://localhost:3200\nVITE__API__DOCUMENTATION__URL=http://localhost:3401\n\n# Compartilhados\nAPP_ENV=production\nAPP_LOG_LEVEL=info\nTELEGRAM__BOT_TOKEN=*** # NUNCA versionar\nEVOLUTION_API__KEY=*** # NUNCA versionar\n```\n\n**Prefixos Reservados:**\n- `APP__` ‚Üí Configura√ß√µes globais (env, log level, locale)\n- `{SERVICO}__` ‚Üí Espec√≠fico do servi√ßo (ORDERMANAGER, WORKSPACE, etc.)\n- `VITE__` ‚Üí Vari√°veis expostas ao frontend (build-time)\n- `SOPS__` ‚Üí Configura√ß√µes do SOPS/age\n\n## 4. Requisitos Obrigat√≥rios\n\n### 4.1 Templates e Exemplos\n\n**Todos os reposit√≥rios/servi√ßos DEVEM:**\n\n1. Incluir `governance/registry/templates/.env.example` com:\n   - Todas as chaves necess√°rias listadas\n   - Valores PLACEHOLDER ou coment√°rios explicativos\n   - NUNCA valores reais/sens√≠veis\n\n2. Manter sincronizado com `.env` real (via automa√ß√£o):\n   ```bash\n   npm run governance:check  # Valida sincroniza√ß√£o\n   ```\n\n3. Documentar vari√°veis obrigat√≥rias vs. opcionais:\n   ```bash\n   # OBRIGAT√ìRIO - Autentica√ß√£o ProfitDLL\n   ORDERMANAGER__PROFITDLL__USERNAME=<seu_usuario>\n\n   # OPCIONAL - Sobrescreve limite padr√£o (5000)\n   ORDERMANAGER__RISK__DAILY_LOSS_LIMIT=10000.00\n   ```\n\n### 4.2 Rota√ß√£o de Segredos\n\n**Frequ√™ncia:**\n- **Tokens de API Externa:** A cada 90 dias\n- **Senhas de Banco de Dados:** A cada 180 dias\n- **JWT Secrets:** A cada 90 dias\n- **Emergency:** Imediatamente ap√≥s incidentes de seguran√ßa\n\n**Processo:**\n- Seguir `governance/controls/secrets-rotation-sop.md`\n- Registrar evid√™ncia em `governance/evidence/audits/secrets-rotation-YYYY-MM-DD.json`\n- Testar em staging antes de produ√ß√£o\n- Manter vers√µes antigas ativas por 24h (rollback)\n\n### 4.3 Logs e Auditoria\n\n**PROIBIDO:**\n- ‚ùå `console.log(process.env.JWT_SECRET)` ou similar\n- ‚ùå Incluir valores de secrets em stack traces\n- ‚ùå Expor secrets em endpoints de health/debug\n\n**OBRIGAT√ìRIO:**\n- ‚úÖ Mascarar secrets em logs estruturados:\n  ```javascript\n  logger.info({ \n    dbUrl: maskSecret(process.env.DB_URL), // postgresql://user:***@host:5432/db\n    action: 'database_connection' \n  });\n  ```\n- ‚úÖ Auditar acessos a secrets (quem, quando, qual):\n  ```json\n  {\n    \"timestamp\": \"2025-11-05T14:32:00Z\",\n    \"actor\": \"ci-pipeline\",\n    \"secret\": \"ORDERMANAGER__PROFITDLL__PASSWORD\",\n    \"action\": \"read\",\n    \"environment\": \"production\"\n  }\n  ```\n\n### 4.4 Criptografia (SOPS + age)\n\n**Para segredos versionados (ex: configura√ß√µes de produ√ß√£o):**\n\n1. Criptografar antes de commitar:\n   ```bash\n   age -R .age-recipients.txt -o secrets.enc.yaml secrets.yaml\n   git add secrets.enc.yaml\n   git add .age-recipients.txt  # Cont√©m public keys\n   ```\n\n2. Descriptografar em runtime (CI/CD ou produ√ß√£o):\n   ```bash\n   export AGE_KEY=$(cat /secure/location/age-key.txt)\n   age -d -i <(echo \"$AGE_KEY\") secrets.enc.yaml > secrets.yaml\n   ```\n\n3. Nunca versionar chaves privadas (`age-key.txt`) no Git\n\n### 4.5 Valida√ß√£o Automatizada\n\n**Pre-Commit / CI:**\n```bash\nnpm run governance:check  # Executa:\n  # 1. validate-envs.mjs ‚Üí Detecta .env reais no repo\n  # 2. validate-policies.mjs ‚Üí Verifica expira√ß√£o de pol√≠ticas\n  # 3. scan-secrets.mjs ‚Üí TruffleHog/git-secrets\n```\n\n**Build Bloqueado se:**\n- Pol√≠tica POL-0002 expirada (`lastReviewed + reviewCycleDays > hoje`)\n- Owner vazio ou inv√°lido\n- Segredos detectados em plaintext\n\n## 5. Responsabilidades\n\n### Security Engineering (Owner)\n- Revisar pol√≠tica a cada 90 dias\n- Aprovar exce√ß√µes (documentadas em `governance/evidence/audits/exceptions/`)\n- Conduzir auditorias trimestrais\n\n### Desenvolvedores\n- Nunca commitar `.env` reais\n- Usar `.env.example` como refer√™ncia\n- Reportar vazamentos acidentais imediatamente\n- Rotacionar secrets ap√≥s sa√≠da do projeto\n\n### DevOps/SRE\n- Configurar GitHub Secrets/OIDC\n- Manter age keys em local seguro (KMS, Vault)\n- Automatizar rota√ß√£o de secrets\n- Monitorar acessos an√¥malos\n\n## 6. Consequ√™ncias de Viola√ß√£o\n\n**Severidade Alta (Secrets Expostos):**\n- Revoga√ß√£o imediata do segredo\n- Rota√ß√£o de todos os secrets relacionados\n- Post-mortem obrigat√≥rio\n- Poss√≠vel revis√£o de acessos\n\n**Severidade M√©dia (Processo n√£o seguido):**\n- Revis√£o do PR bloqueada\n- Treinamento obrigat√≥rio sobre pol√≠ticas\n- Documenta√ß√£o do incidente\n\n## 7. Exce√ß√µes\n\nExce√ß√µes devem ser:\n1. Solicitadas via issue no reposit√≥rio\n2. Aprovadas por Security Engineering\n3. Documentadas em `governance/evidence/audits/exceptions/EXC-YYYY-MM-DD-{id}.md`\n4. Revisadas a cada 30 dias\n\n**Exemplo de exce√ß√£o v√°lida:**\n- Desenvolvimento local com secrets de teste em ambiente isolado (n√£o produ√ß√£o)\n\n## 8. Refer√™ncias\n\n- **Padr√£o Relacionado:** [STD-010 - Secrets Standard](/governance/standards/secrets-standard)\n- **SOP/Runbook:** [Secrets Rotation SOP](/governance/controls/secrets-rotation-sop)\n- **Templates:** [.env.example](https://github.com/marceloterra1983/TradingSystem/blob/main/governance/registry/templates/.env.example)\n- **Evid√™ncias:** diret√≥rio `governance/evidence/audits/`\n\n## 9. Hist√≥rico de Revis√µes\n\n| Data       | Vers√£o | Autor              | Mudan√ßas                          |\n|------------|--------|--------------------|-----------------------------------|\n| 2025-11-05 | 1.0    | SecurityEngineering | Cria√ß√£o inicial da pol√≠tica POL-0002 |\n\n---\n\n**Pr√≥xima Revis√£o:** 2026-02-03  \n**Contato:** security-engineering@tradingsystem.local\n"
    },
    {
      "id": "standards.secrets-standard",
      "title": "Padr√£o T√©cnico de Segredos e Vari√°veis de Ambiente",
      "description": "Requisitos t√©cnicos test√°veis e verific√°veis para implementa√ß√£o da POL-0002 - Pol√≠tica de Gerenciamento de Segredos.",
      "owner": "SecurityEngineering",
      "category": "standards",
      "type": "standard",
      "tags": [
        "security",
        "technical-standard",
        "secrets",
        "testing"
      ],
      "lastReviewed": "2025-11-05",
      "reviewCycleDays": 90,
      "publishSlug": "/governance/standards/secrets-standard",
      "previewPath": "/governance/docs/standards/secrets-standard.md",
      "previewContent": "---\ntitle: \"Padr√£o T√©cnico de Segredos e Vari√°veis de Ambiente\"\nid: STD-010\nowner: SecurityEngineering\nlastReviewed: \"2025-11-05\"\nreviewCycleDays: 90\nstatus: active\nappliesTo:\n  - AllServices\nrelatedPolicies:\n  - POL-0002\ntags:\n  - security\n  - technical-standard\n  - secrets\n  - testing\n---\n\n# Padr√£o T√©cnico de Segredos e Vari√°veis de Ambiente (STD-010)\n\n**ID:** STD-010  \n**Owner:** SecurityEngineering  \n**Status:** Active  \n**Last Reviewed:** 2025-11-05  \n**Next Review:** 2026-02-03 (90 days)\n\n## 1. Objetivo\n\nDefinir requisitos t√©cnicos **test√°veis e verific√°veis** para implementa√ß√£o da [POL-0002 - Pol√≠tica de Gerenciamento de Segredos](/governance/policies/secrets-env-policy).\n\n## 2. Requisitos Test√°veis\n\n### 2.1 Presen√ßa de .env.example\n\n**Requisito:** Todo servi√ßo/aplica√ß√£o DEVE incluir `.env.example` no reposit√≥rio.\n\n**Valida√ß√£o:**\n```bash\n# Automa√ß√£o: validate-envs.mjs\ntest -f .env.example || exit 1\ntest -f governance/registry/templates/.env.example || exit 1\n```\n\n**Crit√©rios de Aceita√ß√£o:**\n- ‚úÖ Arquivo existe no root do servi√ßo ou em `governance/registry/templates/`\n- ‚úÖ Todas as chaves obrigat√≥rias est√£o presentes\n- ‚úÖ NENHUM valor real/sens√≠vel inclu√≠do\n- ‚úÖ Coment√°rios explicativos para chaves complexas\n\n**Exemplo:**\n```bash\n# ‚úÖ CORRETO\nORDERMANAGER__PROFITDLL__USERNAME=<seu_usuario_nelogica>\nORDERMANAGER__RISK__DAILY_LOSS_LIMIT=5000.00  # Limite em R$\n\n# ‚ùå ERRADO (valor real)\nORDERMANAGER__PROFITDLL__PASSWORD=SenhaReal123\n```\n\n### 2.2 Sincroniza√ß√£o .env ‚Üî .env.example\n\n**Requisito:** Chaves presentes em `.env` real DEVEM estar documentadas em `.env.example`.\n\n**Valida√ß√£o:**\n```javascript\n// governance/automation/validate-envs.mjs\nconst envKeys = Object.keys(process.env).filter(k => !k.startsWith('npm_'));\nconst exampleKeys = parseEnvFile('.env.example');\nconst missing = envKeys.filter(k => !exampleKeys.includes(k));\n\nif (missing.length > 0) {\n  throw new Error(`Chaves faltando no .env.example: ${missing.join(', ')}`);\n}\n```\n\n**Crit√©rios de Aceita√ß√£o:**\n- ‚úÖ `npm run governance:check` passa sem erros\n- ‚úÖ Nenhuma chave \"√≥rf√£\" no `.env` real\n- ‚úÖ Nenhuma chave obsoleta no `.env.example`\n\n### 2.3 Scanner de Segredos (Pre-Commit/CI)\n\n**Requisito:** Commits DEVEM ser verificados por scanner de segredos antes de serem aceitos.\n\n**Ferramentas Aprovadas:**\n- **TruffleHog** (regex + entropy detection)\n- **git-secrets** (AWS/GitHub patterns)\n- **detect-secrets** (Yelp - baseline comparison)\n\n**Valida√ß√£o:**\n```bash\n# CI: .github/workflows/code-quality.yml\n- name: Scan Secrets\n  run: |\n    docker run --rm -v $(pwd):/src trufflesecurity/trufflehog:latest \\\n      filesystem /src --fail --json > scan-results.json\n    if [ $(jq '.[] | select(.Verified == true)' scan-results.json | wc -l) -gt 0 ]; then\n      echo \"‚ùå Segredos verificados detectados!\"\n      exit 1\n    fi\n```\n\n**Crit√©rios de Aceita√ß√£o:**\n- ‚úÖ Scanner executa em TODOS os commits (pre-commit hook ou CI obrigat√≥rio)\n- ‚úÖ Build falha se segredos verificados s√£o detectados\n- ‚úÖ Falsos positivos documentados em `.trufflehogignore` ou similar\n\n### 2.4 Criptografia SOPS + age\n\n**Requisito:** Segredos versionados DEVEM ser criptografados com SOPS + age.\n\n**Estrutura de Arquivos:**\n```\nconfig/\n‚îú‚îÄ‚îÄ .age-recipients.txt         # Public keys (versionado)\n‚îú‚îÄ‚îÄ secrets.enc.yaml            # Criptografado (versionado)\n‚îî‚îÄ‚îÄ secrets.yaml                # Plaintext (N√ÉO versionado)\n```\n\n**Valida√ß√£o:**\n```bash\n# Automa√ß√£o: validate-envs.mjs\nif git ls-files | grep -E 'secrets\\.yaml$' | grep -v '\\.example$' | grep -v '\\.enc\\.'; then\n  echo \"‚ùå Arquivo secrets.yaml plaintext detectado no Git!\"\n  exit 1\nfi\n```\n\n**Crit√©rios de Aceita√ß√£o:**\n- ‚úÖ APENAS `*.enc.yaml` versionados\n- ‚úÖ `.gitignore` bloqueia `secrets.yaml` plaintext\n- ‚úÖ CI descriptografa com `AGE_KEY` do GitHub Secrets\n- ‚úÖ Age private key NUNCA commitada\n\n**Exemplo de Uso:**\n```bash\n# Criptografar localmente\nage -R config/.age-recipients.txt -o config/secrets.enc.yaml config/secrets.yaml\n\n# Descriptografar em CI\nage -d -i <(echo \"$AGE_SECRET_KEY\") config/secrets.enc.yaml > config/secrets.yaml\n```\n\n### 2.5 Bloqueio de Build (Pol√≠tica Expirada)\n\n**Requisito:** Build DEVE falhar se POL-0002 estiver expirada ou sem owner.\n\n**Valida√ß√£o:**\n```javascript\n// governance/automation/validate-policies.mjs\nconst policy = parseFrontmatter('governance/policies/secrets-env-policy.md');\nconst lastReviewed = new Date(policy.lastReviewed);\nconst reviewCycleDays = policy.reviewCycleDays || 90;\nconst nextReview = new Date(lastReviewed.getTime() + reviewCycleDays * 24 * 60 * 60 * 1000);\n\nif (new Date() > nextReview) {\n  throw new Error(`POL-0002 expirada! √öltima revis√£o: ${lastReviewed.toISOString()}`);\n}\n\nif (!policy.owner || policy.owner === 'TBD') {\n  throw new Error('POL-0002 sem owner definido!');\n}\n```\n\n**Crit√©rios de Aceita√ß√£o:**\n- ‚úÖ CI executa `npm run governance:check` antes de build\n- ‚úÖ Build falha se `lastReviewed + reviewCycleDays < hoje`\n- ‚úÖ Build falha se `owner` vazio ou \"TBD\"\n- ‚úÖ Notifica√ß√£o enviada para owner 7 dias antes da expira√ß√£o\n\n### 2.6 Mascaramento de Logs\n\n**Requisito:** Logs NUNCA devem expor valores de segredos em plaintext.\n\n**Implementa√ß√£o (Node.js):**\n```javascript\n// shared/logger/maskSecret.js\nexport function maskSecret(value) {\n  if (!value) return null;\n  const str = String(value);\n  if (str.length <= 8) return '***';\n  return str.substring(0, 4) + '***' + str.substring(str.length - 4);\n}\n\n// Uso\nlogger.info({ \n  dbUrl: maskSecret(process.env.DATABASE_URL), \n  // postgresql://user:***@host:5432/db\n  action: 'connection_established' \n});\n```\n\n**Implementa√ß√£o (C#):**\n```csharp\n// Shared/Logger/SecretMasker.cs\npublic static string MaskSecret(string value)\n{\n    if (string.IsNullOrEmpty(value)) return null;\n    if (value.Length <= 8) return \"***\";\n    return value.Substring(0, 4) + \"***\" + value.Substring(value.Length - 4);\n}\n```\n\n**Valida√ß√£o:**\n```bash\n# Auditoria de logs\ngrep -r 'password\\|secret\\|token\\|key' logs/ | grep -vE '\\*\\*\\*|REDACTED|<masked>' && exit 1 || exit 0\n```\n\n**Crit√©rios de Aceita√ß√£o:**\n- ‚úÖ Fun√ß√£o `maskSecret()` dispon√≠vel em todas as linguagens (C#, Node.js, Python)\n- ‚úÖ Logs estruturados SEMPRE mascaram campos sens√≠veis\n- ‚úÖ Auditoria de logs n√£o encontra valores plaintext\n\n### 2.7 Proibi√ß√£o de Print/Console em Produ√ß√£o\n\n**Requisito:** C√≥digo de produ√ß√£o N√ÉO DEVE conter `console.log()`, `print()`, `Debug.WriteLine()` de secrets.\n\n**Valida√ß√£o (ESLint):**\n```javascript\n// .eslintrc.js\nrules: {\n  'no-console': process.env.NODE_ENV === 'production' ? 'error' : 'warn',\n  'no-restricted-syntax': [\n    'error',\n    {\n      selector: \"CallExpression[callee.object.name='console'][callee.property.name!=/^(warn|error)$/]\",\n      message: 'console.log() proibido em produ√ß√£o. Use logger estruturado.'\n    }\n  ]\n}\n```\n\n**Valida√ß√£o (C# - Analyzer):**\n```xml\n<!-- .editorconfig -->\n[*.cs]\ndotnet_diagnostic.CA1848.severity = error  # Use LoggerMessage delegates\ndotnet_diagnostic.CA2254.severity = error  # Template should be constant\n```\n\n**Crit√©rios de Aceita√ß√£o:**\n- ‚úÖ Linter falha se `console.log(process.env.*)` detectado\n- ‚úÖ Code review rejeita PRs com prints de secrets\n- ‚úÖ Runtime guards bloqueiam logs em produ√ß√£o\n\n### 2.8 Evid√™ncias e Auditoria\n\n**Requisito:** Rota√ß√µes de segredos DEVEM gerar evid√™ncias rastre√°veis em JSON.\n\n**Formato:**\n```json\n{\n  \"timestamp\": \"2025-11-05T14:32:00Z\",\n  \"type\": \"secrets_rotation\",\n  \"actor\": \"devops-team\",\n  \"environment\": \"production\",\n  \"secrets_rotated\": [\n    {\n      \"key\": \"ORDERMANAGER__PROFITDLL__PASSWORD\",\n      \"service\": \"OrderManager\",\n      \"old_hash\": \"sha256:abc123...\",\n      \"new_hash\": \"sha256:def456...\",\n      \"rotation_method\": \"manual\",\n      \"tested_in_staging\": true\n    }\n  ],\n  \"rollback_available_until\": \"2025-11-06T14:32:00Z\"\n}\n```\n\n**Localiza√ß√£o:**\n```\ngovernance/evidence/audits/\n‚îú‚îÄ‚îÄ secrets-audit-2025-11.json        # Gerado por validate-envs.mjs\n‚îú‚îÄ‚îÄ secrets-rotation-2025-11-05.json  # Manual (SOP)\n‚îî‚îÄ‚îÄ secrets-scan-2025-11-05.json      # TruffleHog output\n```\n\n**Valida√ß√£o:**\n```bash\n# Automa√ß√£o: validate-envs.mjs gera relat√≥rio\njq '.secrets_rotated | length' governance/evidence/audits/secrets-rotation-*.json\n```\n\n**Crit√©rios de Aceita√ß√£o:**\n- ‚úÖ Arquivo JSON gerado a cada rota√ß√£o\n- ‚úÖ Hash (n√£o valor real) dos secrets registrado\n- ‚úÖ Janela de rollback documentada (24h padr√£o)\n- ‚úÖ Evid√™ncias mantidas por 2 anos (compliance)\n\n## 3. Ambientes de Execu√ß√£o\n\n### 3.1 Desenvolvimento Local\n\n**Tecnologia:** `.env` file (n√£o versionado)\n\n**Checklist:**\n- [ ] `.env` criado a partir de `.env.example`\n- [ ] Valores de teste/mock utilizados (n√£o produ√ß√£o)\n- [ ] `.gitignore` bloqueia `.env`\n- [ ] `dotenv` carregado no in√≠cio da aplica√ß√£o\n\n**Exemplo (Node.js):**\n```javascript\nimport dotenv from 'dotenv';\nimport path from 'path';\n\nconst projectRoot = path.resolve(__dirname, '../../../');\ndotenv.config({ path: path.join(projectRoot, '.env') });\n\nif (!process.env.ORDERMANAGER__PROFITDLL__USERNAME) {\n  throw new Error('ORDERMANAGER__PROFITDLL__USERNAME n√£o definido!');\n}\n```\n\n### 3.2 CI/CD (GitHub Actions)\n\n**Tecnologia:** GitHub Secrets + OIDC\n\n**Checklist:**\n- [ ] Secrets configurados em Settings ‚Üí Secrets ‚Üí Actions\n- [ ] Environments isolados (dev, staging, production)\n- [ ] OIDC configurado para Azure/AWS (sem long-lived credentials)\n- [ ] Logs do CI n√£o exp√µem secrets (`set +x` antes de uso)\n\n**Exemplo (GitHub Actions):**\n```yaml\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    environment: production\n    steps:\n      - name: Decrypt Secrets\n        env:\n          AGE_SECRET_KEY: ${{ secrets.AGE_SECRET_KEY }}\n        run: |\n          echo \"$AGE_SECRET_KEY\" | age -d -i /dev/stdin config/secrets.enc.yaml > config/secrets.yaml\n\n      - name: Deploy\n        run: |\n          # Secrets dispon√≠veis via arquivo descriptografado\n          npm run deploy\n```\n\n### 3.3 Produ√ß√£o Windows (Nativo)\n\n**Tecnologia:** Vari√°veis de sistema + SOPS/age\n\n**Checklist:**\n- [ ] Vari√°veis configuradas via `setx` ou Registry\n- [ ] Arquivos SOPS criptografados em `C:\\TradingSystem\\config\\`\n- [ ] Age pr\n\n[... content truncated ...]"
    },
    {
      "id": "strategy.ci-cd-integration",
      "title": "CI/CD Integration Strategy",
      "description": "Roadmap e estrat√©gia para integra√ß√£o de CI/CD com valida√ß√£o automatizada de governan√ßa, testes e deployment.",
      "owner": "DevOps",
      "category": "strategy",
      "type": "plan",
      "tags": [
        "ci-cd",
        "automation",
        "deployment",
        "testing",
        "governance"
      ],
      "lastReviewed": "2025-11-08",
      "reviewCycleDays": 90,
      "publishSlug": "/governance/strategy/ci-cd-integration",
      "previewPath": "/governance/docs/strategy/CI-CD-INTEGRATION.md",
      "previewContent": "---\ntitle: CI/CD Integration for Documentation\ndescription: Comprehensive guide to documentation validation, deployment, and monitoring workflows.\ntags: [governance, automation, ci-cd]\nowner: DocsOps\nlastReviewed: 2025-11-03\n---\n\n# CI/CD Integration for Documentation\n\nThis guide documents the complete CI/CD ecosystem that keeps the TradingSystem documentation reliable, compliant, and production ready. It covers workflow triggers, validation jobs, notification patterns, and maintenance expectations.\n\n---\n\n## 1. Overview\n\n- **Goal**: fail fast on documentation regressions, guarantee deployment quality, and surface actionable insights to contributors.\n- **Strategy**: run comprehensive validation on every change, enforce branch protection with status checks, and provide rapid feedback through Slack.\n- **Ecosystem**: five GitHub Actions workflows working in concert (validation, deployment, link scanning, code-docs sync validation, scheduled health audits).\n\n### Workflow Relationships\n\n```\ndocs-validation.yml (PRs & pushes)\n    ‚îú‚îÄ freeze_guard ‚Üí skip if freeze active\n    ‚îú‚îÄ validate-frontmatter ‚Üí maintenance-audit ‚Üí docs-check ‚Üí docs-links\n    ‚îî‚îÄ notify-slack + validation-summary\n\ndocs-deploy.yml (main branch)\n    ‚îú‚îÄ freeze_guard\n    ‚îú‚îÄ build-docs ‚Üí deploy-docs\n    ‚îú‚îÄ link-check (PRs)\n    ‚îî‚îÄ validate-frontmatter (Python)\n\ndocs-link-validation.yml (PRs, pushes, schedule)\n    ‚îú‚îÄ freeze_guard\n    ‚îî‚îÄ validate-links (JSON report + PR comment)\n\ndocs-audit-scheduled.yml (daily schedule)\n    ‚îú‚îÄ freeze_guard\n    ‚îú‚îÄ run-audit ‚Üí metrics ‚Üí commit report\n    ‚îî‚îÄ degradation alert (GitHub issue + optional Slack)\n\ndocs-code-sync-validation.yml (PRs touching code)\n    ‚îú‚îÄ freeze_guard\n    ‚îú‚îÄ validate-sync\n    ‚îú‚îÄ comment-on-pr\n    ‚îî‚îÄ check-critical-violations\n```\n\n---\n\n## 2. Workflows\n\n### 2.1 Documentation Validation (`.github/workflows/docs-validation.yml`)\n\n- **Purpose**: comprehensive validation on pull requests, pushes, and manual runs.\n- **Triggers**: `pull_request` and `push` on `main` and `develop`, plus `workflow_dispatch`.\n- **Path filters**: `docs/**`, `scripts/docs/**`, `.github/workflows/docs-validation.yml`.\n- **Jobs**:\n  1. **Freeze Guard** ‚Äì short-circuits the workflow if `FREEZE-NOTICE.md` declares an active freeze.\n  2. **Validate Frontmatter** ‚Äì runs `validate-frontmatter.py` (schema v2) with JSON artifact output.\n  3. **Maintenance Audit** ‚Äì executes `maintenance-audit.sh --ci-mode` with threshold-based failure.\n  4. **Docs Check** ‚Äì runs the full `npm run docs:check` pipeline (auto ‚Üí lint ‚Üí typecheck ‚Üí test ‚Üí build).\n  5. **Docs Links** ‚Äì reuses the build artifact to execute `npm run docs:links`.\n  6. **Notify Slack** ‚Äì posts failures to the DocsOps Slack channel via webhook.\n  7. **Validation Summary** ‚Äì emits a GitHub Step Summary with per-job status and artifact pointers.\n- **Status checks** (branch protection): `validate-frontmatter`, `maintenance-audit`, `docs-check`, `docs-links`.\n- **Artifacts** (7 days retention): frontmatter validation JSON, maintenance audit report, docs build, docs link log.\n- **Runtime**: ~10‚Äì15 minutes depending on link validation scope.\n\n### 2.2 Documentation Deployment (`.github/workflows/docs-deploy.yml`)\n\n- **Purpose**: build and deploy the Docusaurus site to GitHub Pages.\n- **Triggers**: push to `main`, PR to `main`, and `workflow_dispatch`.\n- **Path filters**: `docs/**`, `.github/workflows/docs-deploy.yml`.\n- **Jobs**:\n  1. **Freeze Guard** ‚Äì skips deployment during freezes.\n  2. **Build Docs** ‚Äì runs `docs:auto` and `docs:build`, uploads artifact `docs-build`.\n  3. **Deploy Docs** ‚Äì publishes to GitHub Pages (`main` branch pushes only).\n  4. **Link Check** ‚Äì executes Lychee for HTML link validation on PRs.\n  5. **Validate Frontmatter** ‚Äì uses the Python validator for PRs (shared with validation workflow).\n- **Status checks**: `build-docs`, `validate-frontmatter`.\n- **Artifacts**: `docs-build` uploaded for deployment; retained per GitHub Pages defaults.\n- **Runtime**: ~5‚Äì8 minutes.\n\n### 2.3 Documentation Link Validation (`.github/workflows/docs-link-validation.yml`)\n\n- **Purpose**: deep link validation with categorised severity and PR comments.\n- **Triggers**: `pull_request` (`main`, `develop`), `push` (`main`, `develop`), scheduled daily at 03:00 UTC, `workflow_dispatch`.\n- **Path filters**: `docs/**`, `**/*.md`, `scripts/docs/check-links.py`.\n- **Jobs**:\n  1. **Freeze Guard** ‚Äì honours freeze policy.\n  2. **Validate Links** ‚Äì generates JSON reports, comments on PRs, and fails on critical internal breakages.\n- **Status checks**: `validate-links` (critical issues only).\n- **Artifacts**: JSON reports (`docs/reports/link-validation-*.json`, 30 days retention).\n- **PR automation**: summary comment with critical/warning/external breakdowns.\n- **Runtime**: ~3‚Äì5 minutes.\n\n### 2.4 Documentation Health Audit (`.github/workflows/docs-audit-scheduled.yml`)\n\n- **Purpose**: daily maintenance audit and metrics propagation.\n- **Triggers**: scheduled daily at 02:00 UTC, `workflow_dispatch`.\n- **Jobs**:\n  1. **Freeze Guard** ‚Äì respects freeze windows.\n  2. **Run Audit** ‚Äì executes extended audit script (frontmatter, links, duplicates).\n  3. **Extract Metrics** ‚Äì calculates health score, pushes to monitoring systems.\n  4. **Update Metrics / Commit Report** ‚Äì archives reports and commits updates.\n  5. **Archive Reports** ‚Äì rotates old reports (>30 days).\n  6. **Check Degradation** ‚Äì compares health score deltas.\n  7. **Create Issue** ‚Äì files GitHub issue and notifies Slack if health drops by >5 points.\n- **Status checks**: none (informational).\n- **Artifacts**: audit reports and metrics JSON (90 days retention).\n- **Runtime**: ~5‚Äì10 minutes.\n\n### 2.5 Documentation Versioning (`.github/workflows/docs-versioning.yml`)\n\n- **Purpose**: automated version creation on semantic release tags.\n- **Triggers**: `push` tags matching `v[0-9]+.[0-9]+.[0-9]+`, `workflow_dispatch`.\n- **Path filters**: none (tag-based trigger).\n- **Jobs**:\n  1. **Freeze Guard** ‚Äì honours maintenance freeze windows.\n  2. **Validate Prerequisites** ‚Äì version format, frontmatter, maintenance audit (threshold 5), `npm run docs:check`.\n  3. **Create Version** ‚Äì runs `scripts/docs/auto-version.sh --auto-commit`, updates config, pushes snapshot.\n  4. **Verify Version** ‚Äì checks artifacts, performs production build, validates routing, uploads build artifact.\n  5. **Create Release Notes** ‚Äì extracts CHANGELOG, creates GitHub Release, uploads reports.\n- **Status checks**: none (informational workflow).\n- **Artifacts**: version report (90 days retention), docs build (7 days retention).\n- **Runtime**: ~15‚Äì20 minutes end-to-end.\n- **See also**: [`VERSIONING-AUTOMATION.md`](/governance/versioning-automation).\n\n### 2.6 Code-Docs Synchronization Validation (`.github/workflows/docs-code-sync-validation.yml`)\n\n- **Purpose**: enforce documentation updates whenever mapped code paths change.\n- **Triggers**: pull requests targeting `main` or `develop` that touch backend APIs, database schemas, application code, OpenAPI specs, or `.env.example`; manual `workflow_dispatch`.\n- **Path filters**: `backend/api/**/*.js`, `backend/data/timescaledb/**/*.sql`, `apps/*/src/**/*.{js,ts,tsx}`, `apps/*/package.json`, `backend/api/*/package.json`, `docs/static/specs/*.yaml`, `.env.example`.\n- **Jobs**:\n  1. **Freeze Guard** ‚Äì aborts when `FREEZE-NOTICE.md` declares an active freeze.\n  2. **Validate Sync** ‚Äì runs `scripts/agents/docusaurus-daily.mjs --check-sync --severity-threshold high`, uploads report artifact, and surfaces violation counts.\n  3. **Comment on PR** ‚Äì posts or updates a comment summarizing sync violations, targets, severity, and owners.\n  4. **Check Critical Violations** ‚Äì fails the workflow when critical violations remain; warns on high, logs medium/low.\n- **Status checks**: `validate-sync`, `check-critical-violations` (required for protected branches).\n- **Artifacts**: sync validation report (`sync-validation-*.json`, 30 days retention).\n- **Runtime**: ~3‚Äì5 minutes.\n- **Example**:\n  ```bash\n  # PR introduces new workspace API endpoint\n  git checkout -b feat/workspace-endpoint\n  # edit backend/api/workspace/src/routes/items.js\n  git commit -am \"feat: add GET /api/items/:id endpoint\"\n  git push origin feat/workspace-endpoint\n  # open PR ‚Üí workflow runs ‚Üí fails until docs updated\n  ```\n- **Severity enforcement**:\n  - Critical (API routes, OpenAPI specs): blocks merge.\n  - High (schemas, env vars, configs): posts blocking comment, warns in summary.\n  - Medium/Low (versions, non-breaking features): informational checklist.\n- **Reference**: [`CODE-DOCS-SYNC.md`](/governance/code-docs-sync) for system details.\n\n---\n\n## 3. Validation Scripts\n\n### 3.1 `scripts/docs/validate-frontmatter.py`\n\n- **Scope**: validates YAML frontmatter against schema v2.\n- **Enforced fields**: `title`, `description`, `tags`, `owner`, `lastReviewed`.\n- **Owner validation**: checks against `ALLOWED_OWNERS`.\n- **Date validation**: ISO `YYYY-MM-DD`.\n- **Exit codes**: `0` success, `1` on validation issues.\n- **Output**: JSON report (path configurable via `--output`).\n- **Dependencies**: `pyyaml>=6.0.1` from `requirements-docs.txt`.\n\n### 3.2 `scripts/docs/maintenance-audit.sh`\n\n- **Purpose**: documentation quality guardrail (freshness, length, links, style).\n- **CI mode**: `--ci-mode` activates threshold enforcement with exit code `1` when issues exceed limit.\n- **Threshold override**: `--ci-threshold <N>` (default `10` issues).\n- **Outputs**: Markdown report saved to `docs/reports/maintenance-audit-<timestamp>.md`.\n- **Integration**: used in daily audit and validation workflow.\n\n### 3.3 `npm run docs:check`\n\n- **Pipeline**: `docs:auto` ‚Üí `docs:validate-generated` ‚Üí `docs:lint` (non-blocking) ‚Üí `docs:typecheck` ‚Üí `docs:test` ‚Üí `docs:build`.\n- **Failure handling**: any failing step aborts the job.\n- **Artifact**: `docs/build` directory (consumed by link validation job).\n\n### 3.4 `npm run docs:links`\n\n- **Script**: `scripts/docs/check-links.sh` (Linkinator).\n- **Behavior**: builds docs \n\n[... content truncated ...]"
    },
    {
      "id": "strategy.communication-plan",
      "title": "Governance Communication Plan",
      "description": "Plano de comunica√ß√£o para stakeholders com updates bi-semanais, status reports e canais de comunica√ß√£o.",
      "owner": "Governance",
      "category": "strategy",
      "type": "plan",
      "tags": [
        "communication",
        "stakeholders",
        "governance",
        "reporting"
      ],
      "lastReviewed": "2025-11-08",
      "reviewCycleDays": 90,
      "publishSlug": "/governance/strategy/communication-plan",
      "previewPath": "/governance/docs/strategy/COMMUNICATION-PLAN.md",
      "previewContent": "# Internal Communications Plan - docs Launch\n\n**Launch Date**: 2025-11-15 (target)\n**Owner**: DocsOps + ProductOps\n**Audience**: All TradingSystem developers, operators, product managers, stakeholders\n\n## Communication Objectives\n\n1. **Awareness**: Ensure all team members know about docs launch\n2. **Adoption**: Drive migration from legacy docs to docs\n3. **Training**: Educate users on new navigation and features\n4. **Feedback**: Collect user feedback for continuous improvement\n5. **Support**: Provide clear channels for questions and issues\n\n## Metrics & Evidence\n\n- **KPI**: `engagementRate = participantes que visualizaram/interagiram √∑ p√∫blico-alvo` (meta ‚â• 80% nas comunica√ß√µes principais).\n- **Registro**: Ap√≥s cada marco (T-14, T-7, T-1, Launch, T+7), atualizar `review-tracking.csv` (`GovernanceStatus`, `LastAuditDate`) e anexar captura/export das m√©tricas no campo `EvidenceLink`.\n- **Feedback qualitativo**: Consolidar principais d√∫vidas/respostas e anexar na mesma evid√™ncia ou issue relacionada.\n\n## Communication Timeline\n\n### T-14 Days (Nov 1): Pre-Launch Announcement\n\n**Channel**: Slack #general, #dev, #docs-migration\n\n**Message Template**:\n```\nüìö **docs Launch Announcement** üìö\n\nWe're excited to announce that the new TradingSystem documentation (docs) will launch on **November 15, 2025**!\n\n**What's New:**\n‚úÖ Apps: TP Capital, Workspace e Telegram Gateway com documenta√ß√£o completa (overview, config, runbook)\n‚úÖ APIs: Cat√°logo atualizado com specs do Workspace, Documentation API e integra√ß√µes auxiliares\n‚úÖ Frontend & Design System: Tokens gerados automaticamente e guias de implementa√ß√£o\n‚úÖ Governan√ßa & Opera√ß√µes: Checklists e planos revisados (cutover, manuten√ß√£o, comunica√ß√£o)\n‚úÖ Ferramentas & Scripts: 46 guias ativos + port summary gerado automaticamente\n‚úÖ Arquitetura: Diagrama atualizado no hub (26 PlantUML renderizados na nova estrutura)\n\n**How to Access:**\n- Local dev (docs): http://localhost:3400\n- Unified domain: http://tradingsystem.local/docs\n- Legacy docs (Docusaurus v2): http://localhost:3004\n- Browse content: `docs/content/`\n\n**What to Expect:**\n- 135+ documentation pages (vs 251 in legacy docs)\n- Improved navigation and search\n- Auto-generated reference content\n- Consistent formatting and structure\n- Quarterly maintenance and updates\n\n**Action Items:**\n- üìñ Preview docs at http://localhost:3400\n- üí¨ Share feedback in #docs-feedback channel\n- üêõ Report issues in GitHub (label: documentation)\n- üìÖ Attend launch demo (Nov 14, 2 PM)\n\n**Questions?** Ask in #docs-migration or contact @DocsOps\n```\n\n**Additional Channels**:\n- Email to all-team@company.com\n- Post in project management tool (Jira, Linear)\n- Add to weekly team meeting agenda\n\n---\n\n### T-7 Days (Nov 8): Launch Demo Invitation\n\n**Channel**: Slack #general, Calendar invite\n\n**Message Template**:\n```\nüìÖ **docs Launch Demo - November 14, 2 PM**\n\nJoin us for a 30-minute walkthrough of the new documentation system!\n\n**Agenda:**\n1. Overview of docs structure (5 min)\n2. Navigation and search demo (5 min)\n3. Key features showcase (10 min)\n   - Auto-generated content (ports, tokens)\n   - PlantUML diagrams\n   - API specifications with Redoc\n   - Multi-language support (PT/EN)\n4. Q&A (10 min)\n\n**When:** November 14, 2025, 2:00 PM - 2:30 PM\n**Where:** Zoom link / Meeting room\n**Recording:** Will be shared in #docs-migration\n\n**RSVP:** React with ‚úÖ or decline calendar invite\n\n**Can't Attend?** Watch the recording or schedule 1:1 walkthrough with @DocsOps\n```\n\n**Calendar Invite**:\n- Title: docs Launch Demo\n- Date: November 14, 2025, 2:00 PM\n- Duration: 30 minutes\n- Attendees: all-team@company.com\n- Agenda: (same as above)\n- Zoom link: [link]\n\n---\n\n### T-1 Day (Nov 14): Launch Reminder\n\n**Channel**: Slack #general, #dev\n\n**Message Template**:\n```\nüöÄ **docs Launches Tomorrow!** üöÄ\n\n**Launch Date:** November 15, 2025\n**Access:** http://tradingsystem.local/docs (unified domain) or http://localhost:3400 (local dev)\n\n**What Changes:**\n‚úÖ New documentation URL: tradingsystem.local/docs (was: localhost:3004)\n‚úÖ Updated navigation and search\n‚úÖ Auto-generated reference content\n‚úÖ Comprehensive app and API documentation\n\n**What Stays the Same:**\n- Legacy docs remain accessible at localhost:3004 (legacy portal) during transition\n- All content migrated (no information loss)\n- Same authentication and access controls\n\n**Action Items for Tomorrow:**\n1. Update bookmarks to new URL\n2. Explore new navigation structure\n3. Try the search feature\n4. Share feedback in #docs-feedback\n\n**Need Help?** See FAQ: http://localhost:3400/faq or ask in #docs-migration\n\n**Demo Recording:** Available in #docs-migration channel\n```\n\n---\n\n### Launch Day (Nov 15): Go-Live Announcement\n\n**Channel**: Slack #general, #dev, #docs-migration, Email\n\n**Message Template**:\n```\nüéâ **docs is LIVE!** üéâ\n\n**New Documentation Hub:** http://tradingsystem.local/docs\n\n**What's Available:**\nüì± **Apps**: TP Capital, Workspace e Telegram Gateway (20 p√°ginas revisadas)\nüîå **APIs**: Workspace API, Documentation API e Telegram Gateway API (Redoc integrado)\nüé® **Frontend**: Design system, guidelines, engineering (14 pages)\nüóÑÔ∏è **Database**: Schemas, migrations, backup/retention (4 pages)\nüõ†Ô∏è **Tools**: Node.js, .NET, Python, Docker, and more (46 pages)\nüìê **SDD**: Domain schemas, events, flows, API specs (12 pages)\nüìã **PRD**: Product requirements and features (6 pages, PT/EN)\nü§ñ **Prompts & Agents**: LLM patterns and agent docs (10 pages)\nüìö **Reference**: Templates, ADRs, diagrams (13 pages + 26 diagrams)\n‚ùì **FAQ & Changelog**: Common questions and release history (2 pages)\n\n**Key Features:**\n‚ú® Auto-generated content (ports table, design tokens)\n‚ú® 26 PlantUML diagrams with automatic rendering\n‚ú® Comprehensive search across all content\n‚ú® Consistent navigation and structure\n‚ú® Multi-language support (PT/EN for PRDs)\n‚ú® Quarterly maintenance and updates\n\n**Quick Start:**\n1. Visit http://tradingsystem.local/docs\n2. Browse by category or use search\n3. Bookmark frequently used pages\n4. Share feedback in #docs-feedback\n\n**Legacy Docs:**\n- Still accessible at http://localhost:3004 (legacy portal)\n- Will be archived after 30-day transition period\n- Redirects will be added in Phase 6\n\n**Support:**\n- üí¨ Questions: #docs-migration channel\n- üêõ Issues: GitHub (label: documentation)\n- üìß Email: docs-ops@company.com\n- üìñ FAQ: http://localhost:3400/faq\n\n**Thank You:**\nThanks to DocsOps, ProductOps, ArchitectureGuild, FrontendGuild, BackendGuild, and all contributors for making this launch possible! üôå\n\n**Feedback Welcome:**\nWe're continuously improving! Share your thoughts in #docs-feedback.\n```\n\n**Email Version**: Same content with formatted HTML, include screenshots of new documentation\n\n---\n\n### T+7 Days (Nov 22): Post-Launch Survey\n\n**Channel**: Slack #general, Email\n\n**Message Template**:\n```\nüìä **docs Feedback Survey** üìä\n\nIt's been one week since docs launched! We'd love your feedback.\n\n**Survey Link:** [Google Form / Typeform link]\n\n**Questions (5 minutes):**\n1. How often do you use the documentation? (Daily, Weekly, Monthly, Rarely)\n2. How easy is it to find what you need? (1-5 scale)\n3. What's your favorite feature? (Open text)\n4. What needs improvement? (Open text)\n5. Any missing content? (Open text)\n\n**Incentive:** First 20 responses get a coffee voucher! ‚òï\n\n**Deadline:** November 29, 2025\n\n**Results:** Will be shared in #docs-migration and used to prioritize improvements.\n\nThank you for helping us improve! üôè\n```\n\n---\n\n### T+30 Days (Dec 15): Transition Complete\n\n**Channel**: Slack #general, Email\n\n**Message Template**:\n```\n‚úÖ **docs Transition Complete** ‚úÖ\n\n**Legacy docs archived:** The old documentation system (docs/) has been archived.\n\n**What Changed:**\n- Legacy docs moved to `docs/archive/` (read-only)\n- All links redirect to docs\n- Bookmarks automatically redirect\n- Search now covers docs only\n\n**What to Do:**\n- Update any hardcoded links to docs paths\n- Report broken redirects in #docs-migration\n- Continue sharing feedback in #docs-feedback\n\n**Metrics (First 30 Days):**\n- üìä Page views: [count]\n- üîç Search queries: [count]\n- üí¨ Feedback responses: [count]\n- üêõ Issues reported: [count]\n- ‚úÖ Issues resolved: [count]\n\n**Thank You:**\nThanks for your patience during the transition! The new documentation is here to stay and will continue improving based on your feedback.\n\n**Questions?** Contact @DocsOps or ask in #docs-migration\n```\n\n---\n\n## Dashboard Updates\n\n**If TradingSystem has internal dashboard/portal:**\n\n### Banner Notification (T-7 to Launch)\n\n**Location**: Top of dashboard\n**Type**: Info banner (blue)\n**Message**: \"üìö New documentation launching Nov 15! Preview at http://localhost:3400\"\n**Action**: \"Preview Now\" button ‚Üí http://localhost:3400\n**Dismissible**: Yes\n\n### Launch Day Banner (Launch to T+7)\n\n**Location**: Top of dashboard\n**Type**: Success banner (green)\n**Message**: \"üéâ docs is live! Explore the new documentation hub.\"\n**Action**: \"Explore\" button ‚Üí http://tradingsystem.local/docs\n**Dismissible**: Yes\n\n### Permanent Link (T+7 onwards)\n\n**Location**: Dashboard navigation menu\n**Label**: \"üìö Documentation\"\n**URL**: http://tradingsystem.local/docs\n**Icon**: Book icon\n**Position**: Top navigation or sidebar\n\n---\n\n## Stakeholder Communications\n\n### Executive Summary (for leadership)\n\n**Audience**: CTO, Engineering Director, Product Director\n**Format**: Email or slide deck\n**Timing**: T-7 days\n\n**Content**:\n- **Overview**: New documentation system with 135+ pages\n- **Benefits**: Improved navigation, auto-generated content, comprehensive coverage\n- **Investment**: 3 months migration effort, 5 phases\n- **Metrics**: 251 legacy files ‚Üí 135 structured pages, 98.4% frontmatter compliance\n- **Launch Plan**: 3-week review, Nov 15 launch, 30-day transition\n- **Success Criteria**: 100% validation pass, stakeholder approval, user satisfaction >4/5\n- **Next Steps**: Phase 6 (update references, archive legacy docs)\n\n### Guild Communications\n\n**Audience**: ArchitectureGuild, FrontendGuild, BackendGuild, ProductOps, DocsOps\n*\n\n[... content truncated ...]"
    },
    {
      "id": "strategy.governance-action-plan",
      "title": "Plano de A√ß√£o - Melhoria de Governan√ßa (EXECUTIVO)",
      "description": "Plano executivo de a√ß√£o para implementa√ß√£o das 15 melhorias priorizadas em governan√ßa. Roadmap de 12 semanas com 3 fases (Funda√ß√£o, Otimiza√ß√£o, Refinamento).",
      "owner": "Governance",
      "category": "strategy",
      "type": "plan",
      "tags": [
        "governance",
        "action-plan",
        "executive",
        "roadmap",
        "implementation"
      ],
      "lastReviewed": "2025-11-08",
      "reviewCycleDays": 30,
      "publishSlug": "/governance/action-plan",
      "previewPath": "/governance/docs/GOVERNANCE-ACTION-PLAN.md",
      "previewContent": "# üéØ Governance Action Plan - Quick Reference\n\n**Last Updated:** 2025-11-08 22:30\n**Status:** ‚úÖ Fase 1 Conclu√≠da | üîÑ Fase 2 Em Andamento\n\n---\n\n## üìã Quick Status\n\n**Overall Health:** üü¢ **SAUD√ÅVEL**\n- Structure: ‚úÖ Consolidada (86 ‚Üí 40 files, -54%)\n- Compliance: ‚úÖ 90/100 (A- / Muito Bom)\n- Registry: ‚úÖ 21 artifacts (0 duplicatas)\n\n**Active Issues:** 1 non-critical (setup-env.sh investigation)\n\n---\n\n## ‚úÖ Completed (Fase 1 - 2025-11-08)\n\n### Governance Structure\n- [x] Moved 46 files to archive\n- [x] Consolidated registry (71 ‚Üí 21 artifacts)\n- [x] Eliminated all duplicates\n- [x] Created navigation guides\n- [x] Reorganized controls/policies\n\n### Policy Compliance\n- [x] Deleted `.env.local` (POL-0004 violation)\n- [x] Removed `config/.env.defaults.bak`\n- [x] Made `validate-env.sh` executable\n- [x] Updated audit report with results\n\n**Impact:** POL-0004 compliance: 62.5% ‚Üí 85% (+22.5%)\n\n---\n\n## üîÑ In Progress (Fase 2 - Due: 15/11)\n\n### 1. Investigate setup-env.sh\n**Priority:** üü° HIGH\n- [ ] Check git history\n- [ ] List existing scripts\n- [ ] Decision: Implement or update POL-0004\n\n### 2. Rename Firecrawl Variables\n**Priority:** üü¢ MEDIUM\n- [ ] Update .env files\n- [ ] Update Firecrawl proxy code\n- [ ] Test functionality\n\n---\n\n## üìä Progress Tracking\n\n**Current:**\n- POL-0002: 95/100 ‚úÖ\n- POL-0004: 85/100 ‚úÖ\n- **Overall: 90/100** (A- / Muito Bom)\n\n---\n\n## üîó Quick Links\n\n**Reports:**\n- [Governance Improvement Plan](../docs/content/governance/reports/governance-improvement-plan.mdx)\n- [Env Policy Audit](evidence/audits/env-policy-review-2025-11-08.md)\n- [Navigation Guide](NAVIGATION-GUIDE.md)\n\n**Policies:**\n- [POL-0002: Secrets](../docs/content/governance/policies/secrets-env-policy.mdx)\n- [POL-0004: Environment Variables](../docs/content/governance/policies/environment-variables-policy.mdx)\n\n---\n\n**Next Review:** 2026-02-08 (90 days)\n"
    },
    {
      "id": "strategy.governance-summary",
      "title": "Governan√ßa TradingSystem - Sum√°rio Executivo",
      "description": "Sum√°rio executivo visual da an√°lise de governan√ßa com Quick Wins, roadmap simplificado, KPIs e pr√≥ximos passos imediatos.",
      "owner": "Governance",
      "category": "strategy",
      "type": "plan",
      "tags": [
        "governance",
        "executive-summary",
        "kpis",
        "quick-wins"
      ],
      "lastReviewed": "2025-11-08",
      "reviewCycleDays": 30,
      "publishSlug": "/governance/summary",
      "previewPath": "/governance/docs/GOVERNANCE-SUMMARY.md",
      "previewContent": "e# üìä Governan√ßa TradingSystem - Sum√°rio Executivo\n\n**Data:** 2025-11-08 | **Status Atual:** B+ (85/100) | **Meta 3 Meses:** A- (90/100)\n\n---\n\n## üéØ An√°lise R√°pida\n\n### ‚úÖ O que est√° funcionando bem\n\n| √Årea | Score | Coment√°rio |\n|------|-------|------------|\n| **Estrutura de Diret√≥rios** | 95/100 | Organiza√ß√£o clara e bem definida |\n| **Documenta√ß√£o** | 90/100 | 90 artefatos de governan√ßa catalogados |\n| **Compliance** | 85/100 | Pol√≠ticas formais implementadas |\n\n### ‚ö†Ô∏è O que precisa melhorar\n\n| √Årea | Score | Gap | Prioridade |\n|------|-------|-----|------------|\n| **Automa√ß√£o** | 75/100 | -20 pontos | üî¥ Cr√≠tico |\n| **Rastreabilidade** | 80/100 | -15 pontos | üî¥ Cr√≠tico |\n| **M√©tricas** | 70/100 | -25 pontos | üî¥ Cr√≠tico |\n\n---\n\n## üöÄ Recomenda√ß√µes Top 5 (Quick Wins)\n\n### 1Ô∏è‚É£ Implementar ADR Framework\n**Esfor√ßo:** 2 dias | **ROI:** Alto | **Impacto:** Rastreabilidade de decis√µes\n\n```bash\n# Criar template ADR\ngovernance/adr/template.md\n\n# Migrar 5 decis√µes existentes\ngovernance/adr/\n‚îú‚îÄ‚îÄ 0001-escolha-docusaurus-v3.md\n‚îú‚îÄ‚îÄ 0002-centralizar-env-raiz.md\n‚îú‚îÄ‚îÄ 0003-usar-timescaledb.md\n‚îú‚îÄ‚îÄ 0004-proxy-reverso-rag.md\n‚îî‚îÄ‚îÄ 0005-docker-compose-stacks.md\n```\n\n---\n\n### 2Ô∏è‚É£ Valida√ß√£o Automatizada de Pol√≠ticas\n**Esfor√ßo:** 2 dias | **ROI:** Muito Alto | **Impacto:** Previne expira√ß√µes\n\n```javascript\n// governance/automation/validate-policies.mjs\n- Valida frontmatter obrigat√≥rio\n- Detecta pol√≠ticas expiradas\n- Verifica owner != \"TBD\"\n- Integra com CI/CD\n```\n\n---\n\n### 3Ô∏è‚É£ Dashboard de M√©tricas\n**Esfor√ßo:** 1 semana | **ROI:** Alto | **Impacto:** Visibilidade executiva\n\n**M√©tricas Expostas:**\n- Policy Compliance Rate (95%+)\n- Policy Freshness Rate (90%+)\n- Evidence Coverage (80%+)\n- Governance Health Score (85 ‚Üí 90)\n\n---\n\n### 4Ô∏è‚É£ RACI Matrix\n**Esfor√ßo:** 2 horas | **ROI:** M√©dio | **Impacto:** Clareza de responsabilidades\n\n| Atividade | Policy Owner | Developers | DevOps | CI/CD |\n|-----------|-------------|------------|--------|-------|\n| Revisar policy | **R** | I | I | I |\n| Seguir policies | I | **R** | **R** | - |\n| Executar SOPs | C | C | **R** | A |\n| Bloquear builds | I | I | C | **A** |\n\n---\n\n### 5Ô∏è‚É£ Templates Completos\n**Esfor√ßo:** 1 dia | **ROI:** M√©dio | **Impacto:** Padroniza√ß√£o\n\n```bash\ngovernance/registry/templates/\n‚îú‚îÄ‚îÄ policy.template.md           # NEW\n‚îú‚îÄ‚îÄ standard.template.md         # NEW\n‚îú‚îÄ‚îÄ sop.template.md              # NEW\n‚îú‚îÄ‚îÄ adr.template.md              # NEW\n‚îú‚îÄ‚îÄ audit-report.template.md     # NEW\n‚îî‚îÄ‚îÄ incident-report.template.md  # NEW\n```\n\n---\n\n## üìÖ Roadmap Simplificado (12 Semanas)\n\n```\nSemanas 1-4 (CR√çTICO)\n‚îú‚îÄ‚îÄ ADR Framework ‚úÖ\n‚îú‚îÄ‚îÄ Valida√ß√£o Automatizada ‚úÖ\n‚îî‚îÄ‚îÄ Dashboard de M√©tricas ‚úÖ\n\nSemanas 5-8 (ALTO)\n‚îú‚îÄ‚îÄ Policy Versioning\n‚îú‚îÄ‚îÄ GitHub Integration\n‚îî‚îÄ‚îÄ Notifica√ß√µes Proativas\n\nSemanas 9-12 (M√âDIO)\n‚îú‚îÄ‚îÄ Templates Completos\n‚îú‚îÄ‚îÄ Emergency Runbook\n‚îî‚îÄ‚îÄ Onboarding Guide\n```\n\n---\n\n## üí∞ Investimento vs. Retorno\n\n| Fase | Esfor√ßo | Custo | Benef√≠cios |\n|------|---------|-------|------------|\n| **Fase 1 (Cr√≠tico)** | 8 semanas | R$ 48k | Automa√ß√£o b√°sica + Visibilidade |\n| **Fase 2 (Alto)** | 6 semanas | R$ 36k | Tracking completo + Notifica√ß√µes |\n| **Fase 3 (M√©dio)** | 8 semanas | R$ 48k | Refinamento + Prepara√ß√£o crises |\n| **TOTAL** | **22 semanas** | **R$ 132k** | **Score 85 ‚Üí 95 (+10 pontos)** |\n\n**ROI:** Redu√ß√£o de 80% em trabalho manual de governan√ßa\n\n---\n\n## üìä M√©tricas de Sucesso\n\n### Antes (Atual)\n\n```\nGovernan√ßa: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 85/100 (B+)\nAutoma√ß√£o:  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 75/100\nRastreab.:  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 80/100\nM√©tricas:   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 70/100\n```\n\n### Depois (3 Meses)\n\n```\nGovernan√ßa: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 90/100 (A-)\nAutoma√ß√£o:  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë 85/100 (+10)\nRastreab.:  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 88/100 (+8)\nM√©tricas:   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë 85/100 (+15)\n```\n\n### Depois (6 Meses)\n\n```\nGovernan√ßa: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 95/100 (A)\nAutoma√ß√£o:  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 95/100 (+20)\nRastreab.:  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 95/100 (+15)\nM√©tricas:   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 92/100 (+22)\n```\n\n---\n\n## üéØ KPIs Principais\n\n| M√©trica | Atual | Meta 3M | Meta 6M |\n|---------|-------|---------|---------|\n| **ADR Coverage** | 0 ADRs | 10+ ADRs | 20+ ADRs |\n| **Policy Freshness** | ~90% | 95% | 98% |\n| **Evidence Coverage** | ~60% | 80% | 90% |\n| **Validation Coverage** | 0% | 80% | 100% |\n| **MTTD Violations** | N/A | &lt;24h | &lt;1h |\n\n---\n\n## üö® Riscos Identificados\n\n| Risco | Probabilidade | Impacto | Mitiga√ß√£o |\n|-------|---------------|---------|-----------|\n| Falta de recursos | üü° M√©dio | üî¥ Alto | Priorizar Quick Wins |\n| Scope creep | üü° M√©dio | üü° M√©dio | Roadmap r√≠gido |\n| Resist√™ncia cultural | üü¢ Baixo | üü° M√©dio | Demonstrar valor cedo |\n\n---\n\n## ‚úÖ Pr√≥ximos Passos Imediatos\n\n### Esta Semana (Semana 1)\n\n**Segunda-feira:**\n- [ ] Criar ADR template\n- [ ] Migrar primeira decis√£o para ADR\n\n**Ter√ßa-feira:**\n- [ ] Implementar validate-policies.mjs\n- [ ] Testar valida√ß√£o em 3 pol√≠ticas\n\n**Quarta-feira:**\n- [ ] Configurar GitHub workflow\n- [ ] Testar workflow em PR\n\n**Quinta-feira:**\n- [ ] Criar RACI Matrix\n- [ ] Revisar com stakeholders\n\n**Sexta-feira:**\n- [ ] Criar templates faltantes\n- [ ] Review semanal + pr√≥ximos passos\n\n---\n\n## üìö Documenta√ß√£o Completa\n\n- **[Plano Detalhado (35 p√°ginas)](governance/evidence/reports/governance-improvement-plan-2025-11-08.md)**\n- **[Plano de A√ß√£o Executivo](governance/GOVERNANCE-ACTION-PLAN.md)**\n- **[Governance README](governance/README.md)**\n- **[Technical Debt Tracker](governance/strategy/TECHNICAL-DEBT-TRACKER.md)**\n\n---\n\n## üéâ Resultado Esperado (6 Meses)\n\n**De:** Sistema de governan√ßa manual e reativo\n**Para:** Sistema de governan√ßa automatizado e proativo\n\n### Benef√≠cios Quantific√°veis\n\n- ‚úÖ **80% redu√ß√£o** em trabalho manual de governan√ßa\n- ‚úÖ **&lt;1h** para detectar viola√ß√µes (era N/A)\n- ‚úÖ **100%** de pol√≠ticas validadas automaticamente\n- ‚úÖ **95** score de governan√ßa (era 85)\n- ‚úÖ **20+ ADRs** documentando decis√µes cr√≠ticas\n- ‚úÖ **100%** de notifica√ß√µes proativas funcionando\n\n### Benef√≠cios Qualitativos\n\n- ‚úÖ Rastreabilidade completa de decis√µes arquiteturais\n- ‚úÖ Visibilidade executiva em tempo real via dashboards\n- ‚úÖ Onboarding de novos devs &lt;2h (era ~1 dia)\n- ‚úÖ Compliance garantido via CI/CD\n- ‚úÖ Prepara√ß√£o para auditorias externas (ISO, SOC2)\n\n---\n\n**Aprova√ß√£o Necess√°ria:**\n- [ ] Governance Lead\n- [ ] Security Engineering\n- [ ] DevOps Lead\n- [ ] Budget (R$ 132k)\n\n**Status:** üî¥ Aguardando Aprova√ß√£o\n\n**Data de In√≠cio Prevista:** 2025-11-11 (Segunda-feira)\n\n---\n\n_Documento gerado automaticamente em 2025-11-08_\n_Fonte: An√°lise completa da estrutura de governan√ßa atual_\n"
    },
    {
      "id": "strategy.technical-debt-tracker",
      "title": "Technical Debt Tracker - TradingSystem",
      "description": "Rastreamento abrangente de d√©bito t√©cnico com prioriza√ß√£o, estimativas de esfor√ßo e planos de remedia√ß√£o.",
      "owner": "Architecture",
      "category": "strategy",
      "type": "plan",
      "tags": [
        "technical-debt",
        "planning",
        "architecture",
        "quality"
      ],
      "lastReviewed": "2025-11-01",
      "reviewCycleDays": 90,
      "publishSlug": "/governance/technical-debt-tracker",
      "previewPath": "/governance/docs/strategy/TECHNICAL-DEBT-TRACKER.md",
      "previewContent": "---\ntitle: \"Technical Debt Tracker - TradingSystem\"\ndate: 2025-11-01\nstatus: active\ntags: [technical-debt, planning, architecture, quality]\ndomain: governance\ntype: planning\nsummary: \"Comprehensive tracking of technical debt items with prioritization, effort estimates, and remediation plans\"\nlast_review: 2025-11-01\n---\n\n# Technical Debt Tracker - TradingSystem\n\n**Last Updated:** 2025-11-01\n**Source:** [Architecture Review 2025-11-01](https://github.com/marceloterra1983/TradingSystem/blob/main/governance/evidence/reports/reviews/architecture-2025-11-01/index.md)\n\n---\n\n## Overview\n\nThis document tracks all identified technical debt items across the TradingSystem project, with prioritization based on:\n- **Business Impact** (High/Medium/Low)\n- **Risk Level** (Critical/High/Medium/Low)\n- **Effort Required** (Person-weeks)\n- **Dependencies** (Blocking relationships)\n\n## Debt Categories\n\n1. **Code Debt** - Code quality, testing, refactoring\n2. **Infrastructure Debt** - Architecture, deployment, scalability\n3. **Documentation Debt** - Missing or outdated documentation\n4. **Security Debt** - Vulnerabilities, compliance gaps\n\n---\n\n## Priority 1: Critical (Immediate Action Required)\n\n### DEBT-001: Missing API Gateway\n**Category:** Infrastructure Debt\n**Status:** üî¥ Proposed\n**Risk:** Critical\n**Business Impact:** High\n**Effort:** 2 weeks\n\n**Problem:**\n- No centralized authentication/routing for microservices\n- Services trust each other without verification\n- Inconsistent security policies across services\n- Difficult to implement organization-wide policies\n\n**Impact:**\n- Security vulnerabilities (lateral movement attacks)\n- Operational overhead (duplicate CORS, rate limiting)\n- Scalability limitations (no service discovery)\n\n**Solution:**\n- Implement Kong Gateway for centralized routing\n- Configure JWT authentication plugin\n- Set up Redis-backed rate limiting\n- Implement inter-service authentication\n\n**ADR:** [ADR-003: API Gateway Implementation](../reference/adrs/ADR-003-api-gateway-implementation.md)\n\n**Timeline:**\n- Start: 2026-01-15\n- Target: 2026-03-01 (6 weeks)\n\n**Owner:** Backend Team Lead\n\n**Blockers:** None\n\n**Dependencies:**\n- DEBT-003 (Inter-service auth depends on API Gateway)\n\n---\n\n### DEBT-002: Single Database Instance (TimescaleDB)\n**Category:** Infrastructure Debt\n**Status:** üî¥ Planned\n**Risk:** Critical\n**Business Impact:** High\n**Effort:** 3 weeks\n\n**Problem:**\n- All services (workspace, tp-capital) share single TimescaleDB instance\n- Single point of failure for entire system\n- Connection pool exhaustion risk under high load\n- No read/write separation for optimization\n\n**Impact:**\n- Cascading service failures if DB goes down\n- Performance bottlenecks during peak load\n- Inability to scale read operations independently\n\n**Solution:**\n- Configure TimescaleDB streaming replication (1 primary + 2 replicas)\n- Implement PgBouncer for connection pooling\n- Route read queries to replicas\n- Set up automatic failover with patroni/etcd\n\n**Timeline:**\n- Start: 2026-02-01\n- Target: 2026-02-22 (3 weeks)\n\n**Owner:** DevOps Team\n\n**Blockers:** None\n\n**Dependencies:**\n- DEBT-004 (CQRS pattern benefits from read replicas)\n\n---\n\n### DEBT-003: Missing Inter-Service Authentication\n**Category:** Security Debt\n**Status:** üî¥ Planned\n**Risk:** Critical\n**Business Impact:** High\n**Effort:** 1 week\n\n**Problem:**\n- Services trust each other blindly (no verification)\n- Any compromised service can access all internal APIs\n- No audit trail for service-to-service calls\n\n**Impact:**\n- Lateral movement attacks possible\n- Difficult to trace security incidents\n- Compliance risk (no authentication logs)\n\n**Solution:**\n```javascript\n// Implement shared secret verification\nconst INTER_SERVICE_SECRET = process.env.INTER_SERVICE_SECRET;\n\nfunction verifyServiceAuth(req, res, next) {\n  const serviceToken = req.headers['x-service-token'];\n  if (serviceToken !== INTER_SERVICE_SECRET) {\n    return res.status(403).json({ error: 'Forbidden' });\n  }\n  next();\n}\n\napp.use('/internal/*', verifyServiceAuth);\n```\n\n**Timeline:**\n- Start: 2026-03-01 (after API Gateway)\n- Target: 2026-03-08 (1 week)\n\n**Owner:** Security Team\n\n**Blockers:** DEBT-001 (API Gateway must be deployed first)\n\n---\n\n### DEBT-004: Limited Test Coverage (~30%)\n**Category:** Code Debt\n**Status:** üî¥ In Progress\n**Risk:** High\n**Business Impact:** High\n**Effort:** 4 weeks\n\n**Problem:**\n- Current test coverage ~30% (far below 80% target)\n- Missing integration tests for critical paths\n- No E2E tests for user workflows\n- Manual testing required for regression checks\n\n**Impact:**\n- High risk of regressions in production\n- Slow feature development (manual QA)\n- Difficult to refactor with confidence\n\n**Solution:**\n1. **Unit Tests (2 weeks):**\n   - Target 80% coverage for services\n   - Use Vitest for frontend, Jest for backend\n   - Mock external dependencies\n\n2. **Integration Tests (1 week):**\n   - API contract testing (Supertest)\n   - Database integration tests\n   - WebSocket communication tests\n\n3. **E2E Tests (1 week):**\n   - Critical user workflows (Playwright, Cypress)\n   - Cross-browser testing\n   - Performance regression tests\n\n**Timeline:**\n- Start: 2026-01-15 (parallel with API Gateway)\n- Target: 2026-02-12 (4 weeks)\n\n**Owner:** QA Team + Backend Team\n\n**Blockers:** None\n\n---\n\n### DEBT-005: No Circuit Breakers for Critical Paths\n**Category:** Infrastructure Debt\n**Status:** üî¥ Planned\n**Risk:** High\n**Business Impact:** Medium\n**Effort:** 1 week\n\n**Problem:**\n- WebSocket connections lack fault tolerance\n- ProfitDLL callbacks have no fallback mechanism\n- External API calls can hang indefinitely\n\n**Impact:**\n- Cascading failures during outages\n- Resource exhaustion (hanging connections)\n- Poor user experience (long timeouts)\n\n**Solution:**\n```javascript\nimport CircuitBreaker from 'opossum';\n\nconst breaker = new CircuitBreaker(callProfitDLL, {\n  timeout: 3000,\n  errorThresholdPercentage: 50,\n  resetTimeout: 30000\n});\n\nbreaker.fallback(() => ({ error: 'Service unavailable' }));\nbreaker.on('open', () => logger.error('Circuit breaker opened!'));\n```\n\n**Timeline:**\n- Start: 2026-02-15\n- Target: 2026-02-22 (1 week)\n\n**Owner:** Backend Team\n\n**Blockers:** None\n\n---\n\n## Priority 2: High (Next Sprint)\n\n### DEBT-006: No API Versioning Strategy\n**Category:** Infrastructure Debt\n**Status:** üü° Planned\n**Risk:** High\n**Business Impact:** Medium\n**Effort:** 1 week\n\n**Problem:**\n- No version management for breaking changes\n- Clients break when API changes\n- Difficult to deprecate old endpoints\n\n**Solution:**\n```javascript\n// URL-based versioning (recommended)\napp.use('/api/v1/orders', ordersRouterV1);\napp.use('/api/v2/orders', ordersRouterV2);\n```\n\n**Timeline:**\n- Start: 2026-03-08\n- Target: 2026-03-15 (1 week)\n\n**Owner:** Backend Team Lead\n\n---\n\n### DEBT-007: Large Frontend Bundle Size (~800KB)\n**Category:** Code Debt\n**Status:** üü° Planned\n**Risk:** Medium\n**Business Impact:** Medium\n**Effort:** 1 week\n\n**Problem:**\n- Main bundle size ~800KB (uncompressed)\n- Slow initial page load (3-4s)\n- No code splitting for routes\n\n**Solution:**\n```typescript\n// Route-based lazy loading\nconst LlamaIndexPage = lazy(() => import('./components/pages/LlamaIndexPage'));\n\n<Route path=\"/llama\" element={\n  <Suspense fallback={<LoadingSpinner />}>\n    <LlamaIndexPage />\n  </Suspense>\n} />\n```\n\n**Expected Reduction:** 50% (800KB ‚Üí 400KB main bundle)\n\n**Timeline:**\n- Start: 2026-03-15\n- Target: 2026-03-22 (1 week)\n\n**Owner:** Frontend Team\n\n---\n\n### DEBT-008: In-Memory Rate Limiting\n**Category:** Infrastructure Debt\n**Status:** üü° Planned\n**Risk:** Medium\n**Business Impact:** Medium\n**Effort:** 3 days\n\n**Problem:**\n- Rate limiter resets on service restart\n- Not shared across service instances\n- Ineffective for distributed deployment\n\n**Solution:**\n```javascript\nimport RedisStore from 'rate-limit-redis';\n\nconst limiter = rateLimit({\n  store: new RedisStore({\n    client: redisClient,\n    prefix: 'rl:',\n  }),\n  windowMs: 60000,\n  max: 100,\n});\n```\n\n**Timeline:**\n- Start: 2026-03-08\n- Target: 2026-03-11 (3 days)\n\n**Owner:** Backend Team\n\n---\n\n### DEBT-009: Missing Error Boundaries (React)\n**Category:** Code Debt\n**Status:** üü° Planned\n**Risk:** Medium\n**Business Impact:** Low\n**Effort:** 2 days\n\n**Problem:**\n- No runtime error handling in React\n- Crashes show white screen to users\n- Errors not captured in monitoring\n\n**Solution:**\n```typescript\nclass ErrorBoundary extends React.Component {\n  componentDidCatch(error, errorInfo) {\n    logger.error({ error, errorInfo });\n    // Send to Sentry\n  }\n\n  render() {\n    if (this.state.hasError) {\n      return <ErrorFallback />;\n    }\n    return this.props.children;\n  }\n}\n```\n\n**Timeline:**\n- Start: 2026-03-22\n- Target: 2026-03-24 (2 days)\n\n**Owner:** Frontend Team\n\n---\n\n### DEBT-010: Circular Dependencies\n**Category:** Code Debt\n**Status:** üü° Identified\n**Risk:** Medium\n**Business Impact:** Low\n**Effort:** 2 weeks\n\n**Problem:**\n- `backend/shared/middleware` ‚Üî `backend/shared/logger`\n- `frontend/contexts` ‚Üî `frontend/store`\n- Risk of initialization deadlock and re-render loops\n\n**Solution:**\n- Break circular imports with dependency injection\n- Use event-driven communication instead of direct imports\n- Apply Interface Segregation Principle (ISP)\n\n**Timeline:**\n- Start: 2026-04-01\n- Target: 2026-04-15 (2 weeks)\n\n**Owner:** Backend Team + Frontend Team\n\n---\n\n## Priority 3: Medium (Future Iterations)\n\n### DEBT-011: No CQRS Pattern for Read/Write Separation\n**Category:** Architecture Debt\n**Status:** üü¢ Backlog\n**Risk:** Low\n**Business Impact:** Medium\n**Effort:** 3 weeks\n\n**Problem:**\n- Shared database creates read/write bottlenecks\n- Complex queries slow down write operations\n- Difficult to scale reads independently\n\n**Solution:**\n- Separate read (queries) and write (commands) models\n- Use event sourcing for state changes\n- Implement read replicas for queries\n\n**Timeline:** TBD (Q2 2026)\n\n---\n\n### DEBT-012: No Distributed Tracing (OpenTelemetry)\n**Category:** Infrastructure Debt\n**Status:**\n\n[... content truncated ...]"
    }
  ]
}