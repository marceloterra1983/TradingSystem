---
title: Course Crawler
sidebar_position: 4
description: Stack dedicada para orquestrar e monitorar raspagens de cursos.
tags:
  - apps
  - course-crawler
  - automation
  - observability
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

## Visão Geral

O **Course Crawler** executa o fluxo descrito em `apps/course-crawler/course-platform-scanning-agent_en.md`, encapsulando:

1. **Captura** via Browser-Use + Playwright
2. **Normalização** (HTML → Markdown + mapas de vídeo)
3. **Persistência** em Postgres (stack Neon local)
4. **Exports** governados (`outputs/course-crawler/<run>/<timestamp>`)
5. **Observabilidade** (relatórios, métricas e incidentes)

A stack roda de forma independente do dashboard principal e oferece:

- API (`tradingsystem-course-crawler-api`)
- Worker de execuções
- Banco Postgres dedicado
- Frontend React (`@tradingsystem/course-crawler-frontend`)

## Arquitetura

```
+------------------+       +---------------------------+
| Course Crawler UI| <---> | Course Crawler API (Express) |
+------------------+       +---------------------------+
           |                          |
           |                          v
           |                 +------------------+
           |                 | Postgres (schema course_crawler) |
           |                 +------------------+
           |                          ^
           v                          |
+------------------+       +---------------------------+
| Course Crawler   | ----> | Course Crawler Worker     |
| CLI (apps/...)   |       | (spawn do CLI + parse)    |
+------------------+       +---------------------------+
                               |
                               v
                     outputs/course-crawler/<runId>/<timestamp>
```

### Tabelas Principais

- `course_crawler.courses`: nome, base_url, username, senha criptografada, URLs segmentadas
- `course_crawler.crawl_runs`: status (`queued`, `running`, `success`, `failed`), métricas, diretório de artefatos

### Frontend (Stack dedicada)

- Formulário para cadastrar credenciais e URLs alvo
- Botão para agendar execuções
- Painel de execuções e detalhes (Markdown renderizado)
- Disponível em: `${VITE_COURSE_CRAWLER_APP_URL}` (padrão `http://localhost:4201`)

O dashboard principal apresenta o Course Crawler via iframe (Menu **Apps → Course Crawler**), mantendo a stack original intacta.

## Executando a Stack

<Tabs>
  <TabItem value="compose" label="Docker Compose">

```bash
export COURSE_CRAWLER_DB_PASSWORD=coursecrawler
docker compose -f tools/compose/docker-compose.course-crawler.yml up -d --build
```

Serviços:

- `course-crawler-db` – Postgres 15 com `pgcrypto`
- `course-crawler-api` – API (porta 3601)
- `course-crawler-worker` – Worker que dispara o CLI
- `course-crawler-ui` – Frontend React/Vite servido via Nginx (porta 4201)

Frontends:

- API: `http://localhost:3601/health`
- UI: `http://localhost:4201/`
- Dashboard (iframe): `http://localhost:3103/#/course-crawler`

</TabItem>
  <TabItem value="local" label="Desenvolvimento local">

```bash
# API
cd backend/api/course-crawler
npm install
npm run init-db
npm run dev

# Worker (segundo terminal)
cd backend/api/course-crawler
npm run worker

# Frontend
cd frontend/course-crawler
npm install
npm run dev -- --port 4201
```

Garanta que `apps/course-crawler` foi compilado (`npm run build`) antes de iniciar o worker.
  </TabItem>
</Tabs>

## Configuração

### API/Worker (`backend/api/course-crawler`)

| Variável | Descrição |
|----------|-----------|
| `COURSE_CRAWLER_DATABASE_URL` | Conexão Postgres |
| `COURSE_CRAWLER_ENCRYPTION_KEY` | Chave ≥ 32 chars para criptografar senhas |
| `COURSE_CRAWLER_OUTPUT_BASE` | Diretório base dos artefatos (default `./outputs`) |
| `COURSE_CRAWLER_CLI_PATH` | Path para `apps/course-crawler/dist/index.js` |
| `COURSE_CRAWLER_API_PORT` | Porta do serviço HTTP (default `3601`) |

### CLI (`apps/course-crawler`)

| Variável | Função |
|----------|--------|
| `COURSE_CRAWLER_BASE_URL` | URL de login |
| `COURSE_CRAWLER_LOGIN_USERNAME` / `PASSWORD` | Credenciais |
| `COURSE_CRAWLER_TARGET_URLS` | CSV de URLs de cursos (opcional – filtra) |
| `COURSE_CRAWLER_OUTPUTS_DIR` | Diretório base para exports |
| `COURSE_CRAWLER_CONFIDENCE_THRESHOLD` | Limiar de confiança |
| `COURSE_CRAWLER_SELECTOR_FAILURE_THRESHOLD` | Falhas consecutivas antes de incidentes |
| `COURSE_CRAWLER_MAX_CLASSES_PER_MODULE` | Limite opcional por módulo (deixe vazio para profundidade total) |

> ✅ **Profundidade total**: quando estiver pronto para capturar todos os conteúdos, defina `COURSE_CRAWLER_MAX_CLASSES_PER_MODULE=` (valor vazio) no `.env` e reprovisione o compose.  
> ⚙️ **Safeguard durante tuning**: use um número baixo (ex.: `5`) enquanto ajusta seletores para evitar execuções longas.

### Validação do backend

1. **Rebuild** da stack: `docker compose -f tools/compose/docker-compose.course-crawler.yml up -d --build`
2. **Health check**: `curl http://localhost:3601/health`
3. **Agendar run**:
   ```bash
   COURSE_ID=<uuid>
   curl -X POST http://localhost:3601/courses/$COURSE_ID/runs
   ```
4. **Acompanhar status**: `curl http://localhost:3601/runs/<runId>`
5. **Ver artefatos**:
   ```bash
   curl http://localhost:3601/runs/<runId>/artifacts
   curl http://localhost:3601/runs/<runId>/artifacts/raw?path=run-report.json
   ```
6. **Confirmar Neon/Postgres** (opcional): `docker exec course-crawler-db psql -U postgres -d coursecrawler_cli -c "SELECT COUNT(*) FROM course_crawler.classes;"`.

Executando esse checklist com `COURSE_CRAWLER_MAX_CLASSES_PER_MODULE` vazio garantimos crawls completos (ex.: `run d8d9fcaa...` gerou 54 aulas, `run bb13fceb...` cobre a grade completa do Memberkit).

### Frontend (`frontend/course-crawler`)

| Variável | Função |
|----------|--------|
| `VITE_COURSE_CRAWLER_API_URL` | Endpoint usado pelo frontend para listar cursos/runs e baixar artefatos |
| `COURSE_CRAWLER_APP_PORT` | Porta exposta pelo serviço `course-crawler-ui` (default `4201`) |

O frontend lista cursos, agenda execuções (`POST /courses/:id/runs`) e consome os artefatos Markdown via `GET /runs/:id/artifacts` + `.../raw`. Cada clique já renderiza o Markdown no navegador, sem precisar baixar manualmente do volume `outputs/`.

## Fluxo de Uso

1. **Cadastrar curso** no frontend (nome, base URL, usuário, senha, URLs específicas)
2. **Agendar execução** (`POST /courses/:id/runs`)
3. Worker submete CLI com env deduzido
4. Artefatos disponíveis em `/runs/:id/artifacts`
5. Markdown/JSON renderizados no frontend (React Markdown)

## Testes

- API: `npm run test` (Vitest)
- CLI: `npm run build && node dist/index.js` (usar `.env` / variáveis)

## Referências

- Configuração base: `tools/openspec/changes/add-course-crawler-app`
- CLI: `apps/course-crawler`
- API/Worker: `backend/api/course-crawler`
- Frontend: `frontend/course-crawler`
- Compose stack: `tools/compose/docker-compose.course-crawler.yml`
