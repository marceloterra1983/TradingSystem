---
title: Agent Test Suite
description: Test coverage, examples, and validation procedures for Agno Agents.
tags:
  - agents
  - agno-agents
  - testing
owner: MCPGuild
lastReviewed: '2025-10-26'
---
## Overview

Agno Agents include a comprehensive test suite covering unit tests, integration tests, and API tests. Tests use pytest with async support and mock external dependencies.

**Test Framework**: pytest + pytest-asyncio
**Coverage Tool**: pytest-cov
**Mocking**: httpx mocking for HTTP clients, monkeypatch for agent behavior
**Location**: `tools/agno-agents/tests/`

## Test Scope

**Unit Tests**:
- Domain entities (MarketSignal, RiskAssessment, AgentDecision)
- Value objects (Symbol, Price, Confidence)
- Utility functions (`_extract_size_value`, `calculate_confidence`)

**Integration Tests**:
- HTTP clients with httpx mocking and circuit breaker
- WebSocket consumer with reconnection logic
- Resilience patterns (retry, circuit breaker)

**API Tests**:
- FastAPI endpoints with TestClient
- Request/response validation
- Error handling

**Agent Tests**:
- MarketAnalysisAgent workflow simulation
- RiskManagementAgent validation logic
- SignalOrchestratorAgent coordination

## Test Files

### `test_domain.py`

**Purpose**: Test domain entities and value objects

**Test Cases**:
- MarketSignal creation and validation
- RiskAssessment creation and validation
- AgentDecision creation and validation
- Pydantic schema validation (required fields, type checking)

**Example**:
```python
def test_market_signal_creation():
    signal = MarketSignal(
        symbol="PETR4",
        signal_type="BUY",
        confidence=0.85,
        price=32.50,
        timestamp=datetime.now(timezone.utc),
        source="AGNO"
    )
    assert signal.symbol == "PETR4"
    assert signal.signal_type == "BUY"
    assert signal.confidence == 0.85
```

---

### `test_agents.py`

**Purpose**: Test agent workflows and decision-making

**Test Cases**:

**`test_market_analysis_agent`**:
- Tests MarketAnalysisAgent with mock market data
- Verifies signal generation for all requested symbols
- Validates MarketSignal entity structure

**`test_risk_management_agent`**:
- Tests RiskManagementAgent with mock signals
- Verifies RiskAssessment creation
- Validates `signal_id` format and reasons list

**`test_signal_orchestrator`**:
- Tests SignalOrchestratorAgent with ORCHESTRATE action
- Verifies `agents_involved` list populated
- Validates result structure (signals + assessments)

**`test_agent_error_handling`**:
- Tests error handling when agent fails
- Monkeypatches `agent.arun` to raise exception
- Verifies exception propagates correctly

**`test_agent_metrics_tracking`**:
- Tests Prometheus metrics tracking
- Verifies `AGENT_DECISIONS_TOTAL` counter increments
- Validates metric labels (`agent_name`, `decision_type`)

---

### `test_adapters.py`

**Purpose**: Test HTTP client adapters and resilience patterns

**Test Cases**:
- `B3Client` methods (`ping`, `get_b3_data`, `get_adjustments`)
- `TPCapitalClient` methods (`ping`, `get_tp_capital_signals`)
- `WorkspaceClient` methods (`ping`, `get_ideas`)
- `RiskEngineClient` methods (`check_daily_limits`, `check_position_size`, `check_trading_hours`)
- Retry logic with exponential backoff
- Circuit breaker state transitions (CLOSED → OPEN → HALF_OPEN)

**Mocking Strategy**:
- Use httpx.AsyncClient mocking for HTTP requests
- Mock responses with realistic data
- Simulate failures for resilience testing

---

### `test_routes.py`

**Purpose**: Test FastAPI endpoints

**Test Cases**:
- `POST /api/v1/agents/analyze` (success, validation errors, 500 errors)
- `POST /api/v1/agents/signals` (ANALYZE, VALIDATE, ORCHESTRATE actions)
- `GET /api/v1/agents/status` (agent initialization status)
- Error responses (400, 500 status codes)
- Request validation (Pydantic schema enforcement)

**Testing Approach**:
- Use FastAPI TestClient for synchronous testing
- Mock agent functions to control behavior
- Verify response schemas and status codes

---

### `test_websocket_consumer.py`

**Purpose**: Test B3 WebSocket consumer

**Test Cases**:
- WebSocket connection establishment
- Message handling (callback invocation)
- Reconnection logic on disconnect
- Metrics tracking (events received, connection status)

---

### `test_main.py`

**Purpose**: Test FastAPI application startup and configuration

**Test Cases**:
- Application initialization
- Health endpoint availability
- Metrics endpoint availability
- CORS configuration
- Lifespan events (startup, shutdown)

---

### `conftest.py`

**Purpose**: Shared test fixtures and configuration

**Fixtures**:
- `mock_market_data`: Sample B3 market data
- `mock_signals`: Sample MarketSignal entities
- `mock_openai_client`: Mock OpenAI client (prevents real API calls)
- `test_client`: FastAPI TestClient instance

## Running Tests

### Full Test Suite

```bash
cd tools/agno-agents
env PYTHONPATH=src pytest
env PYTHONPATH=src pytest -v
env PYTHONPATH=src pytest tests/test_agents.py -v
env PYTHONPATH=src pytest tests/test_agents.py::test_market_analysis_agent -v
```

### Coverage Report

```bash
pytest --cov=src --cov-report=html
open htmlcov/index.html
pytest --cov=src --cov-report=term
```

**Coverage Targets**:
- Overall: &gt;80%
- Domain entities: 100%
- Agents: &gt;90%
- Adapters: &gt;85%
- Routes: &gt;90%

### Watch Mode

```bash
pytest-watch
pytest -n auto
```

## Test Examples

### Example 1: Market Analysis Agent Test

```python
@pytest.mark.asyncio
async def test_market_analysis_agent(mock_market_data, mock_openai_client):
    symbols = [entry["symbol"] for entry in mock_market_data]
    signals = await analyze_market(symbols, include_tp=True, include_b3=True)
    assert len(signals) == len(symbols)
    for signal in signals:
        assert isinstance(signal, MarketSignal)
```

### Example 2: Risk Management Agent Test

```python
@pytest.mark.asyncio
async def test_risk_management_agent(mock_signals, mock_openai_client):
    signal = MarketSignal(**mock_signals[0])
    assessment = await validate_signal(signal)
    assert assessment.signal_id.startswith(signal.symbol)
    assert assessment.reasons
```

### Example 3: Signal Orchestrator Test

```python
@pytest.mark.asyncio
async def test_signal_orchestrator(mock_signals, mock_openai_client):
    request = OrchestrationRequest(
        action="ORCHESTRATE",
        data={"symbols": [item["symbol"] for item in mock_signals]},
    )
    response = await orchestrate_analysis(request)
    assert response.agents_involved
    assert "signals" in response.result
```

### Example 4: Error Handling Test

```python
@pytest.mark.asyncio
async def test_agent_error_handling(monkeypatch):
    async def fail(*args, **kwargs):
        raise RuntimeError("boom")

    monkeypatch.setattr(market_analysis_agent, "arun", fail)
    with pytest.raises(RuntimeError):
        await analyze_market(["PETR4"], include_tp=True, include_b3=True)
```

### Example 5: Metrics Tracking Test

```python
def test_agent_metrics_tracking():
    metric = AGENT_DECISIONS_TOTAL.labels(agent_name="TestAgent", decision_type="TEST")
    before = metric._value.get()
    metric.inc()
    after = metric._value.get()
    assert after == pytest.approx(before + 1)
```

## Validation Procedures

### Pre-Commit Validation

```bash
cd tools/agno-agents
pytest
pytest --cov=src --cov-report=term --cov-fail-under=80
ruff check .
black --check .
```

**CI Integration**: GitHub Actions runs tests on every push

### Integration Testing

**Prerequisites**:
- B3 API running (port 3302)
- TP Capital API running (port 3200)
- Workspace API running (port 3100)

**Procedure**:
```bash
bash scripts/startup/start-apis.sh
pytest tests/test_adapters.py -v
curl http://localhost:8200/health?detailed=true
```

### Load Testing (Planned)

**Tool**: Locust or k6

**Scenarios**:
- 100 concurrent requests to `/api/v1/agents/analyze`
- Sustained load (10 req/s for 10 minutes)
- Spike test (0 → 100 req/s in 10 seconds)

**Metrics**:
- p95 latency &lt;1s for market analysis
- p95 latency &lt;500ms for risk validation
- Error rate &lt;1%
- No memory leaks (stable memory usage)

## Test Data

### Mock Market Data

```python
mock_market_data = [
    {
        "symbol": "PETR4",
        "last_price": 32.50,
        "volume": 1000000,
        "change_pct": 2.5,
        "high": 33.00,
        "low": 32.00,
        "timestamp": "2025-10-24T10:30:00Z"
    },
    {
        "symbol": "VALE3",
        "last_price": 65.80,
        "volume": 500000,
        "change_pct": -1.2,
        "high": 66.50,
        "low": 65.50,
        "timestamp": "2025-10-24T10:30:00Z"
    }
]
```

### Mock Signals

```python
mock_signals = [
    {
        "symbol": "PETR4",
        "signal_type": "BUY",
        "confidence": 0.85,
        "price": 32.50,
        "timestamp": "2025-10-24T10:30:00Z",
        "source": "AGNO",
        "size": 100,
        "metadata": {
            "targets": [34.00, 35.00],
            "stop": 31.00
        }
    }
]
```

### Mock OpenAI Client

```python
@pytest.fixture
def mock_openai_client(monkeypatch):
    async def mock_arun(self, prompt):
        return {
            "signals": [
                {
                    "symbol": "PETR4",
                    "signal_type": "BUY",
                    "confidence": 0.85,
                    "price": 32.50
                }
            ]
        }
    
    monkeypatch.setattr("agno.agent.Agent.arun", mock_arun)
```

## Coverage Report

**Current Coverage**:
- Domain entities: 100%
- Agents: 90%
- Adapters: 85%
- Routes: 90%
- Overall: 88%

**Coverage Gaps**:
- WebSocket consumer edge cases (reconnection failures)
- Circuit breaker HALF_OPEN state transitions
- Error handling for malformed LLM responses

**Improvement Plan**:
- Add WebSocket reconnection tests
- Add circuit breaker state transition tests
- Add LLM response parsing tests (malformed JSON, missing fields)

## Continuous Integration

```yaml
name: Agno Agents Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      - name: Install dependencies
        run: |
          cd tools/agno-agents
          pip install -r requirements.txt
      - name: Run tests
        run: |
          cd tools/agno-agents
          pytest --cov=src --cov-report=xml
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./tools/agno-agents/coverage.xml
```

**CI Requirements**:
- All tests must pass before merge
- Coverage must be &gt;80%
- No linting errors (`ruff`, `black`)

## Troubleshooting Tests

| Symptom | Possible Cause | Recommended Action |
|---------|----------------|--------------------|
| 503 on `/api/v1/agents/analyze` | B3 API unavailable | Check logs, wait for circuit HALF_OPEN, verify `/health?detailed=true` |
| Metrics zeroed | Prometheus not configured | Ensure scrape job `agno-agents` in Prometheus config |
| LLM not responding | `OPENAI_API_KEY` invalid | Validate credentials, check quota, review error logs |
| High latency | External APIs slow | Monitor `dependency_status`, adjust timeout, implement caching |

## Related Documentation

- [Agent Overview](/agents/agno-agents) - Agent responsibilities
- [Agent Flows](./flows) - Execution flows
- [Agent Prompts](./prompts) - Prompt templates
- [MCP Integration](./mcp) - MCP capabilities
- [Testing Guidelines](../../frontend/engineering/testing) - General testing strategy
