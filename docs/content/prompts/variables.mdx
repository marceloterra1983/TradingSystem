---
title: Prompt Variables
description: Variable catalog and context construction rules for prompts.
tags:
  - prompts
  - variables
  - llm
owner: DocsOps
lastReviewed: '2025-11-07'
---

# Prompt Variables

Centralized reference for environment variables that affect prompt construction across TradingSystem. Only the LlamaIndex + Ollama stack remains active; legacy multi-agent variables were removed.

---

## üîê Core API Credentials

| Variable | Description | Default | Required | Example |
|----------|-------------|---------|----------|---------|
| `OPENAI_API_KEY` | OpenAI API key for embeddings/Q&A | `-` | Yes | `sk-proj-...` |
| `OPENAI_BASE_URL` | Proxy base URL (optional) | `https://api.openai.com/v1` | No | Custom gateway |
| `OPENAI_MODEL` | Default OpenAI model | `gpt-4o-mini` | No | `gpt-4o` |
| `GEMINI_API_KEY` | Google Gemini key (fallback) | `-` | No | `AIza...` |
| `GEMINI_MODEL` | Gemini model identifier | `gemini-2.0-flash-exp` | No | `gemini-pro` |

‚úÖ **Security rules**: never log keys, rotate each 180 days, store only in the root `.env` (gitignored).

---

## üìö LlamaIndex Settings

| Variable | Description | Default |
|----------|-------------|---------|
| `LLAMAINDEX_QUERY_URL` | Query API base URL | `http://localhost:8202` |
| `LLAMAINDEX_INGESTION_URL` | Ingestion API base URL | `http://localhost:8201` |
| `LLAMAINDEX_JWT` | Optional JWT for direct calls | `dev-secret` |
| `COLLECTIONS_SERVICE_URL` | Metadata service | `http://localhost:3403` |
| `LLM_ENRICHMENT_ENABLED` | Enable LLM enrichment during ingest | `false` |

**Behavior**
- `LLM_ENRICHMENT_ENABLED=false`: deterministic chunk metadata only.
- `LLM_ENRICHMENT_ENABLED=true`: additional summary + title generated via Ollama/OpenAI.

---

## ü§ñ Ollama Runtime

| Variable | Description | Default |
|----------|-------------|---------|
| `OLLAMA_BASE_URL` | Ollama API endpoint | `http://localhost:11434` |
| `OLLAMA_MODEL` | Default generative model | `llama3.1` |
| `OLLAMA_EMBEDDING_MODEL` | Embedding model | `nomic-embed-text` |

Usage examples:
```bash
curl -s ${OLLAMA_BASE_URL}/api/tags | jq '.models[] .name'
ollama run ${OLLAMA_MODEL} "Explique a arquitetura TP Capital"
```

---

## üß± Collection Defaults

| Variable | Description | Default |
|----------|-------------|---------|
| `QDRANT_URL` | Vector store URL | `http://localhost:6333` |
| `DOCUMENTATION_API_PORT` | Docs API port (proxy) | `3401` |
| `RAG_COLLECTIONS_PORT` | Collections API port | `3403` |
| `FILE_WATCHER_ENABLED` | Enable auto ingestion | `true` |
| `FILE_WATCHER_DEBOUNCE_MS` | Debounce for watcher | `5000` |

---

## ‚úÖ Validation Checklist

- `OPENAI_API_KEY` present before running ingestion or query services.
- `LLAMAINDEX_QUERY_URL` and `LLAMAINDEX_INGESTION_URL` reachable (`/health`).
- Ollama models pulled locally (`ollama list`).
- Qdrant collections exist (`curl -s $QDRANT_URL/collections`).
- No leftover variables referencing deprecated services nos arquivos `.env`.
