# Proposal: Enhance RAG Services Architecture

**Change ID**: `enhance-rag-services-architecture`  
**Status**: Proposal  
**Created**: 2025-11-02  
**Author**: Claude Code Full-Stack Developer Agent  
**Priority**: High (Performance, Security, Reliability)  
**Effort**: 4-6 weeks  
**Reviewed**: Architecture Guild Review 2025-11-02

---

## Change Proposal

This proposal enhances the RAG Services architecture with **10 critical improvements** across resilience, security, testing, and scalability to achieve production-grade quality (A rating, 94/100).

---

## Why

### Problem: RAG Services Missing Critical Production Features

The RAG Services architecture received an **A- (88/100)** grade in the 2025-11-02 architecture review. While the current implementation is solid, it lacks critical production features that limit **resilience, security, and scalability**.

**Current State Analysis**:

#### âœ… What's Working Well
- **Architecture**: Clean microservices with clear boundaries (6 containers)
- **Performance**: < 10ms API response time (99.9% uptime)
- **Documentation**: 135+ pages with Docusaurus v3
- **Caching**: 80% cache hit rate (Redis + Memory L2)
- **Technology Stack**: Modern (React 18, Node.js 18, Python 3.11, FastAPI)

#### âŒ Critical Gaps Identified

**Gap Analysis** (Current vs. Required for Production):

| Category | Current State | Required for Production | Gap | Priority |
|----------|---------------|-------------------------|-----|----------|
| **Circuit Breakers** | None | Ollama + Qdrant protected | No fault tolerance | ðŸ”´ P1 |
| **Inter-Service Auth** | Trust-based | X-Service-Token validation | Security vulnerability | ðŸ”´ P1 |
| **Test Coverage** | 0% | 80% (unit + integration + E2E) | Quality risk | ðŸ”´ P1 |
| **API Versioning** | None | /api/v1, /api/v2 | Breaking changes impact | ðŸ”´ P1 |
| **Qdrant HA** | Single instance | 3-node cluster (read replicas) | Availability risk | ðŸŸ¡ P2 |
| **API Gateway** | Per-service auth | Kong/Traefik (centralized) | Ops complexity | ðŸŸ¡ P2 |
| **Code Splitting** | 800KB bundle | 300KB (-63%) | Slow initial load | ðŸŸ¡ P2 |
| **Database Schema** | JSON config | TimescaleDB schema | Data integrity | ðŸŸ¡ P2 |
| **Backups** | Manual | Automated daily (7-day retention) | Data loss risk | ðŸŸ¢ P3 |
| **Redis Persistence** | AOF only | AOF + RDB (hybrid) | Cache reliability | ðŸŸ¢ P3 |

---

## What Changes

This proposal introduces **10 enhancements** organized into 3 priorities (P1, P2, P3) addressing resilience, security, testing, and scalability.

### ðŸ”´ **Priority 1: Critical Fixes** (Week 1-2)

#### 1. Circuit Breaker Pattern
- **ADD**: Circuit breaker for Ollama and Qdrant calls
- **Library**: `circuitbreaker` (Python), `opossum` (Node.js)
- **Configuration**: failure_threshold=5, recovery_timeout=30s
- **Impact**: Prevents cascading failures, improves availability by 5-10%
- **Files**: 
  - `tools/llamaindex/query_service/circuit_breaker.py` (NEW)
  - `backend/api/documentation-api/src/middleware/circuitBreaker.js` (NEW)

#### 2. Inter-Service Authentication
- **ADD**: X-Service-Token header validation
- **Secret**: `INTER_SERVICE_SECRET` environment variable
- **Scope**: All internal endpoints (`/internal/*`)
- **Impact**: Prevents lateral movement, defense in depth
- **Files**:
  - `backend/shared/middleware/serviceAuth.js` (NEW)
  - All service servers (UPDATE to use middleware)

#### 3. Comprehensive Testing Suite
- **ADD**: Unit tests (Jest + Pytest)
- **ADD**: Integration tests (Supertest + FastAPI TestClient)
- **ADD**: E2E tests (Playwright)
- **ADD**: Load tests (K6)
- **Target Coverage**: 80% (backend), 70% (frontend)
- **Files**:
  - `backend/api/documentation-api/src/services/__tests__/` (NEW)
  - `tools/llamaindex/query_service/tests/` (NEW)
  - `tests/e2e/rag-workflow.spec.ts` (NEW)
  - `tests/performance/rag-api.k6.js` (NEW)

#### 4. API Versioning
- **ADD**: /api/v1 prefix to all endpoints
- **ADD**: /api/v2 namespace (future-proof)
- **ADD**: Deprecation warnings for legacy endpoints
- **Impact**: Backward compatibility, controlled migrations
- **Files**:
  - All API routers (UPDATE to add /api/v1 prefix)
  - `backend/api/documentation-api/src/routes/versioning.js` (NEW)

### ðŸŸ¡ **Priority 2: High-Impact Improvements** (Week 3-4)

#### 5. Qdrant High Availability
- **ADD**: 3-node Qdrant cluster (1 primary + 2 replicas)
- **Configuration**: Cluster mode with P2P replication
- **Impact**: Availability 99.9% â†’ 99.99%, read scaling
- **Files**:
  - `tools/compose/docker-compose.rag.yml` (UPDATE)
  - `docs/content/tools/rag/qdrant-ha-setup.mdx` (NEW)

#### 6. API Gateway (Kong)
- **ADD**: Kong API Gateway for centralized routing
- **Features**: JWT auth, rate limiting, CORS, SSL termination
- **Ports**: 8000 (HTTP), 8443 (HTTPS), 8001 (Admin)
- **Impact**: Centralized auth, ops visibility
- **Files**:
  - `tools/compose/docker-compose.kong.yml` (NEW)
  - `tools/kong/kong.yml` (NEW - declarative config)

#### 7. Frontend Code Splitting
- **ADD**: Route-based lazy loading (React.lazy)
- **Target**: Bundle 800KB â†’ 300KB (-63%)
- **Impact**: Initial load 1.2s â†’ 0.6s (-50%)
- **Files**:
  - `frontend/dashboard/src/App.tsx` (UPDATE with lazy imports)

#### 8. Database Schema Migration
- **ADD**: TimescaleDB schema for RAG metadata
- **Tables**: collections, documents, chunks, ingestion_jobs, query_logs, embedding_models
- **Impact**: Data integrity, analytics, audit trail
- **Files**:
  - `backend/data/timescaledb/rag/` (NEW - 7 SQL files)
  - Integration with RAG Collections Service

### ðŸŸ¢ **Priority 3: Operational Excellence** (Week 5-6)

#### 9. Automated Qdrant Backups
- **ADD**: Daily backup script (2 AM cron)
- **Retention**: 7 days
- **Scope**: All collections (documentation__nomic, documentation__mxbai, tradingsystem_v2)
- **Files**:
  - `scripts/backup/qdrant-backup.sh` (NEW)
  - Cron job configuration

#### 10. Redis Hybrid Persistence
- **UPDATE**: Redis config to use AOF + RDB
- **Configuration**: AOF (everysec) + RDB (900/1, 300/10, 60/10000)
- **Impact**: Faster restarts, corruption recovery
- **Files**:
  - `tools/compose/docker-compose.rag.yml` (UPDATE Redis command)

---

## Impact

### ðŸ”´ Breaking Changes

**NONE** - All changes are backward-compatible additions or opt-in features.

**Migration Path**:
- Circuit breakers: Graceful degradation (returns 503 when open)
- API versioning: /api/v1 replaces current paths, old paths deprecated (6-month support)
- Database schema: Runs parallel to JSON config (migration script provided)

### âœ… Affected Components

| Component | Type | Impact | Action Required |
|-----------|------|--------|-----------------|
| **LlamaIndex Query Service** | Code | Add circuit breakers | Implement circuitbreaker library |
| **Documentation API** | Code | Add service auth middleware | Implement X-Service-Token validation |
| **Frontend Dashboard** | Code | Add code splitting | Lazy load components |
| **Qdrant** | Infrastructure | Cluster setup | Deploy 3-node cluster |
| **Kong Gateway** | Infrastructure | New service | Deploy Kong + config |
| **TimescaleDB** | Schema | New rag schema | Run migration scripts |
| **Redis** | Configuration | Update persistence | Update docker-compose |
| **Testing** | New | Add test suite | Write unit/integration/E2E tests |

### ðŸ“Š Expected Benefits

#### ðŸŽ¯ Resilience
- **Circuit breakers**: Prevents cascading failures (availability +5-10%)
- **Qdrant HA**: 99.9% â†’ 99.99% uptime
- **Graceful degradation**: Services survive dependency outages

#### ðŸ”’ Security
- **Inter-service auth**: Prevents lateral movement
- **API Gateway**: Centralized auth + rate limiting
- **Defense in depth**: Multiple security layers

#### ðŸ§ª Quality
- **Test coverage**: 0% â†’ 80% (unit), 70% (frontend), 100% (key paths E2E)
- **Confidence**: Catch regressions before production
- **Documentation**: Living tests serve as examples

#### âš¡ Performance
- **Frontend bundle**: 800KB â†’ 300KB (-63%)
- **Initial load**: 1.2s â†’ 0.6s (-50%)
- **Database queries**: Indexed lookups < 5ms
- **Analytics**: Pre-computed aggregates (continuous)

#### ðŸ“ˆ Scalability
- **Qdrant**: Read replicas distribute query load
- **API Gateway**: Load balancing, SSL termination
- **Database**: Hypertables scale to millions of logs

### âš ï¸ Risks & Mitigations

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|-----------|
| **Circuit breaker false positives** | Low | Medium | Tune thresholds based on baseline metrics |
| **Kong config errors** | Medium | High | Test in staging first, have rollback plan |
| **Qdrant cluster split-brain** | Low | High | Use odd number of nodes (3), proper quorum config |
| **Test suite maintenance burden** | Medium | Low | Focus on critical paths, accept 80% not 100% coverage |
| **Migration downtime** | Low | Medium | Run migrations during maintenance window, test rollback |
| **Performance regression** | Low | Medium | Benchmark before/after, have kill switch |

---

## Comparison with Current State

### Database: Current (JSON) vs. Proposed (TimescaleDB)

#### Current State: JSON Config
```json
// tools/rag-services/collections-config.json
{
  "collections": [
    { "name": "documentation__nomic", "directory": "/data/docs/content", ... }
  ],
  "defaults": { "embeddingModel": "nomic-embed-text", ... }
}
```

**Limitations**:
- âŒ No query history
- âŒ No ingestion job tracking
- âŒ No analytics
- âŒ No audit trail
- âŒ Manual sync with Qdrant

#### Proposed State: TimescaleDB Schema
```sql
-- 6 tables with full metadata tracking
rag.collections          -- Collection configurations
rag.documents            -- Document metadata
rag.chunks               -- Chunks â†” Qdrant mapping
rag.ingestion_jobs       -- Job history (hypertable)
rag.query_logs           -- Query analytics (hypertable)
rag.embedding_models     -- Model catalog
```

**Advantages**:
- âœ… Full audit trail
- âœ… Query analytics (hourly/daily aggregates)
- âœ… Ingestion job tracking
- âœ… Orphan detection
- âœ… Change tracking (file hashes)
- âœ… ACID guarantees

**Migration**: Automated script to import JSON â†’ TimescaleDB

---

### Security: Current (Trust) vs. Proposed (Zero Trust)

#### Current State: Trust-Based
```javascript
// âŒ Services trust each other without verification
const response = await fetch(`${this.queryBaseUrl}/search`, {
  method: 'GET',
  headers: { Authorization: this._getBearerToken() }, // Only user auth
});
```

**Limitations**:
- âŒ No inter-service authentication
- âŒ Lateral movement possible
- âŒ No service identity validation

#### Proposed State: Service-to-Service Auth
```javascript
// âœ… X-Service-Token validation on internal endpoints
function verifyServiceAuth(req, res, next) {
  const serviceToken = req.headers['x-service-token'];
  if (serviceToken !== INTER_SERVICE_SECRET) {
    return res.status(403).json({ error: 'Forbidden: Invalid service token' });
  }
  next();
}

app.use('/internal/*', verifyServiceAuth);
```

**Advantages**:
- âœ… Defense in depth
- âœ… Service identity validation
- âœ… Audit trail (service-to-service calls)
- âœ… Prevents unauthorized access

---

### API: Current (Unversioned) vs. Proposed (Versioned)

#### Current State: No Versioning
```python
# âŒ Breaking changes affect all clients immediately
@app.get("/search")
@app.post("/query")
```

**Limitations**:
- âŒ Cannot introduce breaking changes safely
- âŒ No migration path for clients
- âŒ Difficult to maintain backward compatibility

#### Proposed State: URL-Based Versioning
```python
# âœ… Explicit version in URL
@app.get("/api/v1/search")
@app.post("/api/v1/query")

# Future v2 can coexist
@app.get("/api/v2/search")  # Breaking changes OK

# Legacy support with deprecation warning
@app.get("/search")
async def search_legacy(request: Request):
    logger.warning("Legacy /search used - deprecated, use /api/v1/search")
    return await search_v1(request)
```

**Advantages**:
- âœ… Backward compatibility
- âœ… Controlled migrations (6-month deprecation cycle)
- âœ… Multiple versions in parallel
- âœ… Clear API evolution

---

### Availability: Current (Single) vs. Proposed (HA Cluster)

#### Current State: Single Qdrant Instance
```yaml
# âŒ Single point of failure
services:
  qdrant:
    image: qdrant/qdrant:latest
    ports: ["6333:6333"]
    # No replication
```

**Limitations**:
- âŒ Single point of failure
- âŒ No read scaling
- âŒ Downtime during upgrades
- âŒ Availability: 99.9% (SLA miss risk)

#### Proposed State: 3-Node Cluster
```yaml
# âœ… High availability with read replicas
services:
  qdrant-primary:
    ports: ["6333:6333"]
    environment:
      - QDRANT__CLUSTER__ENABLED=true
      - QDRANT__CLUSTER__NODE_ID=primary
  
  qdrant-replica-1:
    ports: ["6334:6333"]
    environment:
      - QDRANT__CLUSTER__P2P__PEERS=qdrant-primary:6335
  
  qdrant-replica-2:
    ports: ["6335:6333"]
    environment:
      - QDRANT__CLUSTER__P2P__PEERS=qdrant-primary:6335
```

**Advantages**:
- âœ… High availability: 99.9% â†’ 99.99%
- âœ… Read scaling (distribute query load)
- âœ… Zero-downtime upgrades
- âœ… Automatic failover

---

## Impact Summary

### ðŸ“Š Scorecard Improvement (Before â†’ After)

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| **Overall Grade** | A- (88/100) | A (94/100) | +6 points |
| **Security** | B+ (85) | A (92) | +7 points |
| **Testing** | C+ (70) | A- (88) | +18 points |
| **Availability** | 99.9% | 99.99% | +0.09pp |
| **Bundle Size** | 800KB | 300KB | -63% |
| **Initial Load** | 1.2s | 0.6s | -50% |
| **Test Coverage** | 0% | 75% avg | +75pp |

### ðŸ’° Cost-Benefit Analysis

**Investment**:
- **Development**: 4-6 weeks (1-2 engineers)
- **Infrastructure**: +$50/month (additional containers)
- **Maintenance**: +2 hours/week (monitoring, tuning)

**Returns**:
- **Reduced incidents**: -50% (better fault tolerance)
- **Faster troubleshooting**: +60% (comprehensive logs, tests)
- **Improved UX**: Initial load -50% (code splitting)
- **Higher availability**: 99.9% â†’ 99.99% (-10x downtime)

**ROI**: Positive after 2-3 months

---

## Timeline

### Sprint 1 (Week 1-2): Critical Fixes - Priority 1

**Goal**: Address critical gaps in resilience and security

| Task | Effort | Owner | Status |
|------|--------|-------|--------|
| 1.1 Circuit Breaker (Python) | 1 day | Backend | â³ |
| 1.2 Circuit Breaker (Node.js) | 1 day | Backend | â³ |
| 1.3 Inter-Service Auth | 2 days | Security | â³ |
| 1.4 API Versioning | 1 day | Backend | â³ |
| 1.5 Unit Tests (Backend) | 3 days | Backend + QA | â³ |
| 1.6 Integration Tests | 2 days | Backend + QA | â³ |

**Deliverables**:
- âœ… Circuit breaker library integrated
- âœ… X-Service-Token validation middleware
- âœ… /api/v1 endpoints active
- âœ… 50% backend test coverage

**Success Criteria**:
- Circuit breaker opens after 5 failures
- Inter-service calls without token rejected (403)
- All tests pass in CI/CD
- Legacy endpoints show deprecation warnings

### Sprint 2 (Week 3-4): High Priority - Priority 2

**Goal**: Improve availability and observability

| Task | Effort | Owner | Status |
|------|--------|-------|--------|
| 2.1 Qdrant HA Setup (3 nodes) | 3 days | DevOps | â³ |
| 2.2 Frontend Code Splitting | 1 day | Frontend | â³ |
| 2.3 Database Schema Deployment | 1 day | Data Eng | â³ |
| 2.4 Migration Script (JSON â†’ DB) | 1 day | Backend | â³ |
| 2.5 API Gateway (Kong) Setup | 3 days | DevOps | â³ |
| 2.6 E2E Tests (Playwright) | 1 day | QA | â³ |

**Deliverables**:
- âœ… Qdrant cluster operational (3 nodes)
- âœ… Bundle size < 300KB
- âœ… Database schema deployed
- âœ… Kong gateway routing traffic
- âœ… E2E tests for critical paths

**Success Criteria**:
- Qdrant cluster passes health checks
- Frontend load time < 700ms
- All JSON collections migrated to DB
- Kong routes all traffic correctly

### Sprint 3 (Week 5-6): Operational Excellence - Priority 3

**Goal**: Enhance data protection and monitoring

| Task | Effort | Owner | Status |
|------|--------|-------|--------|
| 3.1 Automated Qdrant Backups | 1 day | DevOps | â³ |
| 3.2 Redis Hybrid Persistence | 0.5 day | DevOps | â³ |
| 3.3 Grafana Dashboards | 2 days | DevOps | â³ |
| 3.4 Load Testing (K6) | 1 day | QA | â³ |
| 3.5 Documentation Updates | 1 day | Docs | â³ |
| 3.6 Runbook Creation | 0.5 day | DevOps | â³ |

**Deliverables**:
- âœ… Daily backups (7-day retention)
- âœ… Redis with RDB snapshots
- âœ… Grafana dashboards for metrics
- âœ… Load tests in CI/CD
- âœ… Updated documentation

**Success Criteria**:
- Backups run daily, restore tested
- Redis survives crashes without data loss
- Dashboards show real-time metrics
- Load test passes (1000 RPS sustained)

---

## Success Metrics

### Key Performance Indicators (KPIs)

**After 6 Weeks**:

| Metric | Baseline | Target | Measurement |
|--------|----------|--------|-------------|
| **Overall Grade** | A- (88) | A (94) | Architecture review |
| **Availability** | 99.9% | 99.99% | Uptime monitoring |
| **Test Coverage (Backend)** | 0% | 80% | Jest/Pytest reports |
| **Test Coverage (Frontend)** | 0% | 70% | Vitest reports |
| **Bundle Size** | 800KB | 300KB | Build artifacts |
| **Initial Load Time** | 1.2s | 0.6s | Lighthouse |
| **Circuit Breaker Activations** | N/A | < 5/day | Logs |
| **Unauthorized Service Calls** | N/A | 0/day | Security logs |
| **Query Log Retention** | 0 days | 90 days | Database |
| **Backup Success Rate** | 0% | 100% | Cron logs |

### Acceptance Criteria

**Must Have** (Blockers for "Done"):
- âœ… All P1 tasks completed (circuit breaker, auth, tests, versioning)
- âœ… Backend test coverage â‰¥ 80%
- âœ… E2E tests pass for critical paths (search, query, ingestion)
- âœ… Qdrant cluster operational with 3 nodes
- âœ… Kong gateway routing all traffic
- âœ… Database schema deployed and integrated
- âœ… No regressions (all existing features work)

**Nice to Have** (Can defer to Phase 2):
- Frontend test coverage â‰¥ 70%
- Grafana dashboards complete
- Load tests in CI/CD
- Automated backups operational

---

## Open Questions

### Q1: Should we implement all P1 + P2 + P3, or phase incrementally?

**Options**:
- **All at once** (6 weeks, big bang deployment)
- **Incremental** (P1 â†’ deploy â†’ P2 â†’ deploy â†’ P3 â†’ deploy)
- **Hybrid** (P1+P2 together, P3 later)

**Recommendation**: **Hybrid approach** - Deploy P1+P2 after 4 weeks (critical + high impact), defer P3 to maintenance window.

**Rationale**: P1+P2 address critical gaps (security, availability). P3 is operational polish (can wait).

---

### Q2: Should Kong replace individual service auth, or run in parallel?

**Options**:
- **Replace** - Kong handles all auth, services trust Kong
- **Parallel** - Kong + service-level auth (defense in depth)
- **Gradual** - Start parallel, migrate to Kong-only

**Recommendation**: **Parallel (defense in depth)** - Keep service-level auth as fallback.

**Rationale**: If Kong fails, services can still validate requests. Security-first approach.

---

### Q3: Should we migrate ALL collections to TimescaleDB, or hybrid JSON+DB?

**Options**:
- **Full migration** - Deprecate JSON config entirely
- **Hybrid** - Support both (JSON for simple, DB for complex)
- **Gradual** - Start with DB, migrate JSON over 3 months

**Recommendation**: **Gradual migration** - New collections in DB, existing in JSON (for now).

**Rationale**: Reduces risk, allows testing, no forced downtime.

---

## References

### Architecture Review
- **[Full-Stack Review 2025-11-02](../../../docs/governance/reviews/architecture-2025-11-02-fullstack-review.mdx)** - Source of recommendations

### Database Design
- **[RAG Database Schema](../../../backend/data/timescaledb/rag/README.md)** - Complete schema
- **[ER Diagram](../../../docs/content/diagrams/rag-services-er-diagram.puml)** - Visual schema

### API Design
- **[OpenAPI Spec](../../../backend/api/documentation-api/openapi/rag-services-v1.yaml)** - REST API spec
- **[API Documentation](../../../docs/content/api/rag-services.mdx)** - Developer guide
- **[Code Examples](../../../backend/api/documentation-api/openapi/examples/rag-api-examples.md)** - Multi-language examples

### Existing Code
- **LlamaIndex Query**: `tools/llamaindex/query_service/main.py`
- **RAG Proxy Service**: `backend/api/documentation-api/src/services/RagProxyService.js`
- **RAG Collections Service**: `tools/rag-services/src/server.ts`
- **Frontend Client**: `frontend/dashboard/src/services/llamaIndexService.ts`

### Related Changes
- **optimize-frontend-backend-performance**: Overlaps with code splitting
- **optimize-docker-security-performance**: Overlaps with Kong gateway

---

## Approval Requirements

### Stakeholders

| Role | Name | Approval | Comments |
|------|------|----------|----------|
| **Architecture Guild** | Lead Architect | â³ Pending | Review design decisions |
| **Backend Team** | Tech Lead | â³ Pending | Assess implementation effort |
| **DevOps Team** | SRE Lead | â³ Pending | Review infrastructure changes |
| **Security Team** | Security Lead | â³ Pending | Review auth strategy |
| **QA Team** | QA Lead | â³ Pending | Review testing approach |

### Approval Checklist

- [ ] Architecture review approved
- [ ] Implementation plan reviewed
- [ ] Timeline realistic and agreed
- [ ] Resources allocated (engineers, infrastructure)
- [ ] Risk mitigation strategies accepted
- [ ] Success criteria clear and measurable

---

**Status**: ðŸŸ¡ **Proposal Stage** (awaiting stakeholder approval)  
**Next Steps**: Present to Architecture Guild â†’ Gather feedback â†’ Revise if needed â†’ Approve â†’ Begin Sprint 1  
**Estimated Start Date**: 2025-11-05 (pending approval)  
**Estimated Completion**: 2025-12-20 (6 weeks)

