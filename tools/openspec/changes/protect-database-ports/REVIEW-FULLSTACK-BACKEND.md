# Technical Review: Database Port Protection

**Reviewers**: fullstack-developer + backend-architect agents  
**Change ID**: `protect-database-ports`  
**Date**: 2025-11-03  
**Status**: ‚úÖ **APPROVED WITH ENHANCEMENTS**  

---

## üéØ Executive Summary

**Overall Grade**: **A (92/100)**

The proposal is **technically sound and well-structured** with comprehensive planning. It addresses a real operational pain point (port conflicts) with a pragmatic solution (dedicated port range 7000-7999).

**Recommendation**: ‚úÖ **APPROVE with minor enhancements**

---

## üë®‚Äçüíª Full-Stack Developer Review

### Strengths ‚úÖ

1. **End-to-End Approach**
   - ‚úÖ Considers entire stack (database ‚Üí backend ‚Üí frontend)
   - ‚úÖ Centralized .env configuration (best practice)
   - ‚úÖ Type-safe config loading with environment variables
   - ‚úÖ Comprehensive testing strategy

2. **Developer Experience**
   - ‚úÖ Clear migration path with automation
   - ‚úÖ Excellent documentation (10+ files)
   - ‚úÖ Rollback procedure well-defined
   - ‚úÖ Claude agent integration (DX improvement)

3. **Data Protection**
   - ‚úÖ Named volumes already implemented
   - ‚úÖ Backup strategy comprehensive
   - ‚úÖ Zero data loss guarantee

4. **Tooling Integration**
   - ‚úÖ MCP servers leveraged
   - ‚úÖ Custom commands created
   - ‚úÖ Scripts automated

### Areas for Enhancement ‚ö†Ô∏è

#### 1. Application Configuration Loading

**Current**:
```javascript
const dbPort = process.env.TIMESCALEDB_PORT || 7000;
```

**Enhancement**: Add validation layer
```typescript
// backend/shared/config/database.config.ts
import { z } from 'zod';

const DatabaseConfigSchema = z.object({
  host: z.string().default('localhost'),
  port: z.number().min(7000).max(7999).default(7000),
  user: z.string().min(1),
  password: z.string().min(1),
  database: z.string().min(1),
  ssl: z.boolean().default(false),
  pool: z.object({
    max: z.number().default(10),
    idleTimeoutMillis: z.number().default(30000),
  }),
});

export function loadDatabaseConfig() {
  const config = {
    host: process.env.TIMESCALEDB_HOST,
    port: parseInt(process.env.TIMESCALEDB_PORT || '7000'),
    user: process.env.TIMESCALEDB_USER,
    password: process.env.TIMESCALEDB_PASSWORD,
    database: process.env.TIMESCALEDB_DATABASE,
    ssl: process.env.TIMESCALEDB_SSL === 'true',
    pool: {
      max: parseInt(process.env.TIMESCALEDB_POOL_MAX || '10'),
      idleTimeoutMillis: parseInt(process.env.TIMESCALEDB_POOL_IDLE || '30000'),
    },
  };

  return DatabaseConfigSchema.parse(config); // Throws if invalid
}
```

**Benefit**: Catches configuration errors at startup, not at runtime

#### 2. Frontend Environment Variables

**Gap**: Proposal doesn't mention frontend .env handling

**Enhancement**: Add to tasks.md
```markdown
- [ ] 5.8 Update frontend/.env.example with new database UI ports:
  - VITE_PGADMIN_URL=http://localhost:7100
  - VITE_ADMINER_URL=http://localhost:7101
  - VITE_QDRANT_URL=http://localhost:7020
```

#### 3. Hot Reload Consideration

**Issue**: Changing .env requires service restart

**Enhancement**: Add to design.md
```markdown
### Hot Reload Strategy
- Node.js services: Restart required
- Docker containers: Recreate required
- Frontend (Vite): Auto-reload on .env change

**Recommendation**: Use `docker compose restart` instead of `down` + `up` to minimize downtime.
```

#### 4. TypeScript Type Safety

**Enhancement**: Generate TypeScript types from .env
```typescript
// backend/shared/types/env.d.ts
declare global {
  namespace NodeJS {
    interface ProcessEnv {
      // Database Ports (7000-7099)
      TIMESCALEDB_PORT: string;
      TIMESCALEDB_BACKUP_PORT: string;
      POSTGRES_LANGGRAPH_PORT: string;
      KONG_DB_PORT: string;
      QUESTDB_HTTP_PORT: string;
      QDRANT_HTTP_PORT: string;
      REDIS_PORT: string;
      
      // Database UI Ports (7100-7199)
      PGADMIN_PORT: string;
      ADMINER_PORT: string;
      PGWEB_PORT: string;
    }
  }
}

export {};
```

**Benefit**: Compile-time safety for environment variables

### Recommendations

1. **Add**: Configuration validation layer (Zod schema)
2. **Add**: Frontend .env updates to tasks
3. **Add**: Hot reload strategy to design
4. **Add**: TypeScript env types
5. **Consider**: Connection pool validation after migration

**Impact**: +8 hours implementation time, +5 points quality

---

## üèóÔ∏è Backend Architect Review

### Strengths ‚úÖ

1. **Service Boundary Design**
   - ‚úÖ Clear separation: databases vs apps vs monitoring
   - ‚úÖ Port ranges enforce boundary discipline
   - ‚úÖ Microservices can scale independently

2. **Database Architecture**
   - ‚úÖ Named volumes ensure data persistence
   - ‚úÖ Multiple database types (TimescaleDB, QuestDB, Qdrant, Redis)
   - ‚úÖ Proper separation of concerns

3. **Scalability Planning**
   - ‚úÖ 1000-port range allows for growth
   - ‚úÖ Sub-ranges organized by purpose
   - ‚úÖ Future-proof design

4. **Performance Considerations**
   - ‚úÖ Port changes have zero performance impact
   - ‚úÖ Connection pooling unchanged
   - ‚úÖ No query degradation

### Areas for Enhancement ‚ö†Ô∏è

#### 1. Connection String Abstraction

**Current**: Each app constructs connection manually

**Enhancement**: Create connection factory
```typescript
// backend/shared/db/connectionFactory.ts
import pg from 'pg';
import { loadDatabaseConfig } from '../config/database.config';

export class DatabaseConnectionFactory {
  private static pools = new Map<string, pg.Pool>();

  static getTimescalePool(): pg.Pool {
    if (!this.pools.has('timescale')) {
      const config = loadDatabaseConfig();
      this.pools.set('timescale', new pg.Pool({
        host: config.host,
        port: config.port,
        user: config.user,
        password: config.password,
        database: config.database,
        max: config.pool.max,
        idleTimeoutMillis: config.pool.idleTimeoutMillis,
      }));
    }
    return this.pools.get('timescale')!;
  }

  static async healthCheck(): Promise<boolean> {
    try {
      const pool = this.getTimescalePool();
      const client = await pool.connect();
      await client.query('SELECT 1');
      client.release();
      return true;
    } catch (error) {
      return false;
    }
  }

  static async closeAll(): Promise<void> {
    for (const [name, pool] of this.pools) {
      await pool.end();
      console.log(`Closed connection pool: ${name}`);
    }
    this.pools.clear();
  }
}

// Usage in apps
import { DatabaseConnectionFactory } from '@shared/db/connectionFactory';

const pool = DatabaseConnectionFactory.getTimescalePool();
const result = await pool.query('SELECT * FROM workspace_items');
```

**Benefits**:
- Single point of configuration
- Connection pool reuse
- Easier testing (mock factory)
- Consistent error handling

#### 2. Database Health Monitoring

**Gap**: No structured health check schema

**Enhancement**: Implement health check interface
```typescript
// backend/shared/types/health.ts
export interface DatabaseHealth {
  name: string;
  status: 'healthy' | 'degraded' | 'down';
  port: number;
  responseTime: number;
  connections: {
    active: number;
    idle: number;
    max: number;
  };
  metrics: {
    queryCount: number;
    errorCount: number;
    avgQueryTime: number;
  };
  lastChecked: string;
}

export interface SystemHealth {
  overall: 'healthy' | 'degraded' | 'down';
  databases: DatabaseHealth[];
  timestamp: string;
}
```

**Implementation**:
```typescript
// backend/shared/services/healthService.ts
export class HealthService {
  static async checkDatabase(name: string, port: number): Promise<DatabaseHealth> {
    const startTime = Date.now();
    
    try {
      const pool = DatabaseConnectionFactory.getPool(name);
      const client = await pool.connect();
      
      const stats = await client.query(`
        SELECT 
          count(*) FILTER (WHERE state = 'active') as active,
          count(*) FILTER (WHERE state = 'idle') as idle
        FROM pg_stat_activity
        WHERE datname = current_database()
      `);
      
      client.release();
      
      return {
        name,
        status: 'healthy',
        port,
        responseTime: Date.now() - startTime,
        connections: {
          active: parseInt(stats.rows[0].active),
          idle: parseInt(stats.rows[0].idle),
          max: pool.options.max,
        },
        metrics: {
          queryCount: 0, // TODO: Implement query counter
          errorCount: 0,
          avgQueryTime: 0,
        },
        lastChecked: new Date().toISOString(),
      };
    } catch (error) {
      return {
        name,
        status: 'down',
        port,
        responseTime: Date.now() - startTime,
        connections: { active: 0, idle: 0, max: 0 },
        metrics: { queryCount: 0, errorCount: 1, avgQueryTime: 0 },
        lastChecked: new Date().toISOString(),
      };
    }
  }

  static async getSystemHealth(): Promise<SystemHealth> {
    const databases = await Promise.all([
      this.checkDatabase('timescale', 7000),
      this.checkDatabase('questdb', 7010),
      this.checkDatabase('qdrant', 7020),
      this.checkDatabase('redis', 7030),
    ]);

    const overall = databases.every(db => db.status === 'healthy')
      ? 'healthy'
      : databases.some(db => db.status === 'down')
      ? 'down'
      : 'degraded';

    return {
      overall,
      databases,
      timestamp: new Date().toISOString(),
    };
  }
}
```

#### 3. Inter-Service Communication

**Current**: Direct database connections

**Enhancement**: Consider adding service layer
```typescript
// backend/shared/services/databaseService.ts
export class DatabaseService {
  private pool: pg.Pool;

  constructor(dbName: string) {
    this.pool = DatabaseConnectionFactory.getPool(dbName);
  }

  async query<T = any>(sql: string, params?: any[]): Promise<T[]> {
    const client = await this.pool.connect();
    try {
      const result = await client.query(sql, params);
      return result.rows;
    } catch (error) {
      logger.error('Database query failed', { sql, error });
      throw new DatabaseError('Query failed', { cause: error });
    } finally {
      client.release();
    }
  }

  async transaction<T>(callback: (client: pg.PoolClient) => Promise<T>): Promise<T> {
    const client = await this.pool.connect();
    try {
      await client.query('BEGIN');
      const result = await callback(client);
      await client.query('COMMIT');
      return result;
    } catch (error) {
      await client.query('ROLLBACK');
      throw error;
    } finally {
      client.release();
    }
  }
}
```

**Benefit**: Abstraction layer for better error handling and transaction management

#### 4. API Versioning for Port Changes

**Gap**: No API versioning strategy mentioned

**Enhancement**: Add to proposal.md
```markdown
### API Versioning Strategy

Since database connection URLs are changing, applications SHOULD:
1. Use environment variables (already planned ‚úÖ)
2. Implement connection retry logic with exponential backoff
3. Log connection attempts for debugging

**No API version bump needed** because:
- Internal configuration change only
- External APIs unchanged
- Connection strings via .env (transparent to consumers)
```

#### 5. Database Migration Pattern

**Current**: Databases assumed to exist

**Enhancement**: Add initialization check
```typescript
// backend/shared/db/initialization.ts
export class DatabaseInitializer {
  static async ensureDatabase(name: string): Promise<void> {
    const adminPool = new pg.Pool({
      host: 'localhost',
      port: 7000,
      user: 'timescale',
      password: process.env.TIMESCALEDB_PASSWORD,
      database: 'postgres', // Connect to default DB
    });

    try {
      // Check if database exists
      const result = await adminPool.query(
        'SELECT 1 FROM pg_database WHERE datname = $1',
        [name]
      );

      if (result.rows.length === 0) {
        // Create database
        await adminPool.query(`CREATE DATABASE "${name}"`);
        console.log(`‚úÖ Database created: ${name}`);
        
        // Enable TimescaleDB extension
        const dbPool = new pg.Pool({
          ...adminPool.options,
          database: name,
        });
        await dbPool.query('CREATE EXTENSION IF NOT EXISTS timescaledb CASCADE');
        await dbPool.end();
      } else {
        console.log(`‚úÖ Database exists: ${name}`);
      }
    } finally {
      await adminPool.end();
    }
  }

  static async initializeAll(): Promise<void> {
    const databases = [
      'APPS-WORKSPACE',
      'APPS-TPCAPITAL',
      'tradingsystem',
      'telegram_messages',
    ];

    for (const db of databases) {
      await this.ensureDatabase(db);
    }
  }
}

// Usage in server startup
import { DatabaseInitializer } from '@shared/db/initialization';

async function startServer() {
  await DatabaseInitializer.initializeAll();
  // ... start Express server
}
```

**Benefit**: Idempotent initialization, prevents "database does not exist" errors

#### 6. Connection Pool Monitoring

**Enhancement**: Add pool metrics endpoint
```typescript
// backend/api/workspace/src/routes/admin.ts
router.get('/admin/db-stats', async (req, res) => {
  const pool = DatabaseConnectionFactory.getTimescalePool();
  
  res.json({
    pool: {
      totalCount: pool.totalCount,
      idleCount: pool.idleCount,
      waitingCount: pool.waitingCount,
    },
    config: {
      max: pool.options.max,
      port: pool.options.port,
    },
  });
});
```

**Benefit**: Real-time visibility into connection health

### Full-Stack Developer Score: **A- (90/100)**

**Deductions**:
- -5: Missing config validation layer (Zod)
- -3: No frontend .env handling mentioned
- -2: Connection factory abstraction recommended

**Additions Needed**:
1. Config validation with Zod (2 hours)
2. Frontend .env updates (1 hour)
3. Connection factory (3 hours)
4. Database initialization (2 hours)

**Total Additional Effort**: +8 hours

---

## üèóÔ∏è Backend Architect Review

### Strengths ‚úÖ

1. **Architecture Clarity**
   - ‚úÖ Clear service boundaries enforced by port ranges
   - ‚úÖ Separation of concerns (databases, UIs, exporters)
   - ‚úÖ Scalability path defined (1000 ports reserved)

2. **Database Design**
   - ‚úÖ Multiple database types for different use cases
   - ‚úÖ Named volumes for persistence
   - ‚úÖ Proper indexing mentioned

3. **Performance**
   - ‚úÖ Zero performance impact from port changes
   - ‚úÖ Connection pooling preserved
   - ‚úÖ No query degradation

4. **Operational Excellence**
   - ‚úÖ Comprehensive backup strategy
   - ‚úÖ Rollback procedure defined
   - ‚úÖ Monitoring integration

### Areas for Enhancement ‚ö†Ô∏è

#### 1. High Availability Consideration

**Current**: Single database instances

**Enhancement**: Add HA roadmap to design.md
```markdown
### Future: High Availability Architecture

**Phase 1** (Current): Single-node databases
- TimescaleDB: Single instance on port 7000
- Qdrant: Single instance on port 7020
- Redis: Single instance on port 7030

**Phase 2** (Future): Read Replicas
- TimescaleDB Primary: 7000
- TimescaleDB Read Replica: 7001 (currently backup)
- Qdrant Cluster: 7020, 7022, 7023 (3-node)
- Redis Sentinel: 7030, 7031, 7032

**Port Range Supports**:
- Up to 99 database instances (7000-7099)
- Enough for 10 services with 9 replicas each
```

#### 2. Connection Pooling Best Practices

**Enhancement**: Document pool sizing strategy
```markdown
### Connection Pool Sizing

**Formula**: `max_connections = (core_count * 2) + effective_spindle_count`

**Per Service**:
- Workspace API: max: 10 (low traffic)
- TP Capital API: max: 20 (medium traffic)
- Docs API: max: 15 (with caching)
- Telegram API: max: 10 (sporadic usage)

**TimescaleDB Total**: max_connections = 100
- Reserved: 55 for apps
- Available: 45 for admin, backups, monitoring

**Validation**:
```sql
-- Check current connections
SELECT 
  datname, 
  count(*) as connections,
  max_conn
FROM pg_stat_database 
JOIN (SELECT setting::int as max_conn FROM pg_settings WHERE name = 'max_connections') s ON true
GROUP BY datname, max_conn;
```
```

#### 3. Read/Write Splitting

**Future Enhancement**: Document read scaling path
```markdown
### Read Scaling Strategy

**Current**: All queries to primary (7000)

**Future** (when needed):
```typescript
// Routing logic
const dbPort = isWriteQuery(query) 
  ? 7000  // Primary (writes)
  : 7001  // Read replica

const pool = new pg.Pool({ port: dbPort, ... });
```

**Trigger**: When read queries > 1000/min
```

#### 4. Database Sharding Consideration

**Enhancement**: Reserve ports for sharding
```markdown
### Sharding Port Allocation

If future growth requires horizontal sharding:

**Shard 0** (Primary): 7000
**Shard 1**: 7010
**Shard 2**: 7020
**Shard N**: 7000 + (N * 10)

**Routing**:
```typescript
function getShardPort(userId: string): number {
  const hash = hashCode(userId);
  const shardId = hash % TOTAL_SHARDS;
  return 7000 + (shardId * 10);
}
```
```

#### 5. Cross-Region Database Replication

**Current**: Single-region (localhost)

**Enhancement**: Document multi-region pattern
```markdown
### Multi-Region Pattern (Future)

**Region 1** (Local): 7000-7099
**Region 2** (Remote): 17000-17099 (port offset +10000)

**Replication**:
- Primary ‚Üí Replica via pglogical or native streaming
- Read queries routed to nearest region
- Writes always to primary
```

#### 6. Database-Specific Optimizations

**TimescaleDB**: Add compression and retention policies
```sql
-- After migration, optimize hypertables
ALTER TABLE workspace_items SET (
  timescaledb.compress,
  timescaledb.compress_orderby = 'created_at DESC'
);

-- Auto-compression for data older than 30 days
SELECT add_compression_policy('workspace_items', INTERVAL '30 days');

-- Retention policy (optional)
SELECT add_retention_policy('workspace_items', INTERVAL '1 year');
```

**QuestDB**: Partition strategy
```sql
-- Partition by day for time-series data
-- Already handled by QuestDB's native partitioning
```

**Qdrant**: Collection sizing
```yaml
# Ensure vector collections have proper sizing
collections:
  docs_index:
    vectors:
      size: 384
      distance: Cosine
    on_disk_payload: true  # For large datasets
    optimizers_config:
      memmap_threshold: 20000
```

### Backend Architect Score: **A- (94/100)**

**Deductions**:
- -3: Missing connection factory pattern
- -2: No connection pool sizing guidance
- -1: Future scaling path not documented

**Additions Needed**:
1. Connection factory (3 hours)
2. Health monitoring interface (2 hours)
3. Pool sizing documentation (1 hour)
4. HA roadmap (1 hour)

**Total Additional Effort**: +7 hours

---

## üéØ COMBINED RECOMMENDATIONS

### Critical (Must Have) ‚≠ê‚≠ê‚≠ê

1. **Config Validation** (Zod schema)
   - Prevents runtime errors
   - Catches misconfigurations early
   - Effort: 2 hours

2. **Connection Factory**
   - Centralizes database logic
   - Improves testability
   - Effort: 3 hours

3. **Database Initialization**
   - Ensures databases exist before migration
   - Idempotent operation
   - Effort: 2 hours

4. **Frontend .env Updates**
   - Complete the end-to-end config story
   - Effort: 1 hour

**Subtotal**: +8 hours (Worth it!)

### Important (Should Have) ‚≠ê‚≠ê

5. **TypeScript Env Types**
   - Compile-time safety
   - Effort: 1 hour

6. **Health Monitoring Interface**
   - Structured health reporting
   - Effort: 2 hours

7. **Pool Sizing Documentation**
   - Prevent connection exhaustion
   - Effort: 1 hour

**Subtotal**: +4 hours

### Nice to Have (Could Have) ‚≠ê

8. **HA Roadmap** - Document future scaling (1 hour)
9. **Read/Write Splitting** - Document pattern (1 hour)
10. **Compression Policies** - Optimize TimescaleDB (2 hours)

**Subtotal**: +4 hours

---

## üìä REVISED EFFORT ESTIMATE

### Original Estimate
- Active Work: 8 hours (1 day)
- Monitoring: 7 days

### With Enhancements
- **Critical**: +8 hours ‚Üí **Total: 16 hours (2 days)**
- **Important**: +4 hours ‚Üí **Total: 20 hours (2.5 days)**
- **Nice to Have**: +4 hours ‚Üí **Total: 24 hours (3 days)**

**Recommendation**: Implement **Critical** enhancements (16 hours total)

---

## ‚úÖ APPROVAL DECISION

### Overall Grade: **A (92/100)**

| Aspect | Score | Notes |
|--------|-------|-------|
| **Problem Definition** | 95/100 | Clear, user-driven |
| **Solution Design** | 90/100 | Solid, needs minor enhancements |
| **Implementation Plan** | 95/100 | Comprehensive tasks |
| **Risk Mitigation** | 95/100 | Excellent backup/rollback |
| **Documentation** | 100/100 | Outstanding |
| **Tooling** | 90/100 | Good, could add validation |
| **Testing** | 85/100 | Basic coverage, needs more |
| **Scalability** | 90/100 | Future-proof, document HA path |

**Average**: **92.5/100**

### Decision: ‚úÖ **APPROVED**

**Conditions**:
1. Add **config validation** (Zod) - 2 hours
2. Add **connection factory** - 3 hours
3. Add **database initialization** - 2 hours
4. Add **frontend .env handling** - 1 hour

**Total Additional Effort**: +8 hours (Worth the quality improvement!)

---

## üìù UPDATED TASKS (ADDITIONS)

### Add to Phase 1: Preparation

```markdown
- [ ] 1.8 Create config validation schema (Zod)
- [ ] 1.9 Implement DatabaseConnectionFactory
- [ ] 1.10 Create DatabaseInitializer for idempotent setup
```

### Add to Phase 5: Application Updates

```markdown
- [ ] 5.9 Implement connection factory in all apps
- [ ] 5.10 Add config validation at startup
- [ ] 5.11 Update frontend .env.example with UI ports
- [ ] 5.12 Generate TypeScript env types
```

### Add to Phase 6: Monitoring

```markdown
- [ ] 6.4 Implement HealthService with DatabaseHealth interface
- [ ] 6.5 Add /admin/db-stats endpoint to all apps
- [ ] 6.6 Document connection pool sizing strategy
```

### Add to Phase 9: Testing

```markdown
- [ ] 9.8 Test config validation (invalid .env should fail fast)
- [ ] 9.9 Test connection factory (pool reuse, error handling)
- [ ] 9.10 Test database initialization (idempotency)
```

---

## üöÄ IMPLEMENTATION SEQUENCE

### Recommended Approach

1. **Phase 1**: Preparation + Critical Enhancements (4 hours)
   - Backups
   - Config validation
   - Connection factory
   - Database initialization

2. **Phase 2**: Migration Execution (1 hour)
   - Port updates
   - Container restart
   - Validation

3. **Phase 3**: Application Updates (4 hours)
   - Update all apps
   - Deploy connection factory
   - Test connections

4. **Phase 4**: Monitoring & Documentation (3 hours)
   - Health interface
   - Dashboards
   - Documentation

**Total**: 12 hours (1.5 days) with enhancements

---

## üéä FINAL VERDICT

### ‚úÖ **APPROVED FOR IMPLEMENTATION**

**Proposal Quality**: Excellent  
**Technical Soundness**: Strong  
**Risk Management**: Comprehensive  
**Documentation**: Outstanding  

**With Recommended Enhancements**:
- Config validation (Zod)
- Connection factory pattern
- Database initialization
- Frontend .env handling

**Timeline**: 1.5 days active work + 7 days monitoring

**Next Steps**:
1. Implement critical enhancements
2. Update tasks.md with additions
3. Execute migration in local dev
4. Validate, then proceed to staging

---

## üìö REFERENCES

**Best Practices Applied**:
- [12-Factor App](https://12factor.net/) - Config in environment ‚úÖ
- [PostgreSQL Connection Pooling](https://node-postgres.com/features/pooling) ‚úÖ
- [Docker Volumes](https://docs.docker.com/storage/volumes/) ‚úÖ

**TradingSystem Standards**:
- Centralized .env (CLAUDE.md) ‚úÖ
- Clean Architecture ‚úÖ
- Microservices pattern ‚úÖ

---

**Review Completed**: 2025-11-03  
**Reviewers**: fullstack-developer, backend-architect  
**Recommendation**: ‚úÖ APPROVE (with enhancements)  
**Grade**: **A (92/100)**  

