#
# AnythingLLM - RAG System Alternative
# 
# Interface visual para RAG com suporte a m√∫ltiplos LLMs
# https://docs.anythingllm.com
#

services:
  anythingllm:
    image: mintplexlabs/anythingllm:latest
    container_name: anythingllm
    restart: unless-stopped
    
    ports:
      - "3001:3001"
    
    environment:
      # Storage configuration
      - STORAGE_DIR=/app/server/storage
      
      # Server configuration
      - SERVER_PORT=3001
      
      # Optional: LLM Provider (configurar via UI)
      # - LLM_PROVIDER=ollama
      # - OLLAMA_BASE_PATH=http://rag-ollama:11434
      
      # Optional: Embedding Provider (configurar via UI)
      # - EMBEDDING_PROVIDER=ollama
      # - OLLAMA_EMBEDDING_MODEL=nomic-embed-text
      
      # Optional: Vector Database (configurar via UI)
      # - VECTOR_DB=qdrant
      # - QDRANT_ENDPOINT=http://data-qdrant:6333
    
    volumes:
      # Persistent storage for documents, embeddings, and database
      - ../../backend/data/anythingllm:/app/server/storage
      
      # Project documentation (read-only, auto-sync)
      - ../../docs/content:/workspace/docs:ro
      
      # Full project root (read-only, for flexible access)
      - ../..:/workspace/tradingsystem:ro
    
    networks:
      - anythingllm
      - tradingsystem_backend  # Connect to backend network for Ollama/Qdrant access
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/api/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    labels:
      - "com.tradingsystem.service=anythingllm"
      - "com.tradingsystem.category=ai-tools"

networks:
  anythingllm:
    name: anythingllm
    driver: bridge
  
  tradingsystem_backend:
    external: true
